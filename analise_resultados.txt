========================================================
      ANÁLISE AUTOMÁTICA DE ARTIGOS CIENTÍFICOS
========================================================

--- ARTIGO: articles/3D Medical Imaging by using Point Cloud Generation.pdf ---

1. TOP 10 TERMOS:
    - point          : 26
    - ct             : 23
    - cloud          : 22
    - method         : 16
    - images         : 15
    - dimensional    : 13
    - reconstruction : 13
    - model          : 13
    - c              : 13
    - contrast       : 12

2. REFERÊNCIAS EXTRAÍDAS (10 total):
    [1] [1] t. f. chen-yoshikawa, “evolution of three-dimensional computed to- mography imaging in
thoracic surgery,” cancers , vol. 16, no. 11, p. 2161, 2024.
    [2] [2] e. rocha-júnior and p. m. pêgo-fernandes, “three-dimensional com- puted tomography
reconstruction in the era of digital personalized medicine,” sao paulo medical journal ,
vol. 141, no. 1, pp. 1–3, 2023.
    [3] [3] s. nakazawa, t. nagashima, n. kawatani, p. c. gedeon, a. k. desi- mone, h. igai, t.
kosaka, and k. shirabe, “anatomy of the lung revisited by 3d-ct imaging,” video assist
thorac surg , vol. 8, 2023.
    [4] [4] k. rathore, m. teh, and m. newman, “deep intramural left anterior descending or large
septal artery?” annals of thoracic surgery , vol. 111, no. 4, p. 1409, 2021.
    [5] [5] l. abdulmajid, h. el addouli, b. paelinck, and d. de bock, “natural growth of left
atrial myxoma,” annals of thoracic surgery , vol. 111, no. 4, pp. e275–e277, 2021.
    [6] [6] s. nakazawa, r. hanawa, t. nagashima, k. shimizu, t. yajima, and k. shirabe,
“segmentectomy guided by 3-dimensional images recon- structed from nonenhanced computed
tomographic data,” the annals of thoracic surgery , vol. 111, no. 3, pp. e301–e304, 2021.
    [7] [7] c. dinesh, g. cheung, and i. v . baji ´c, “3d point cloud super-resolution via graph
total variation on surface normals,” 2019 ieee international conference on image
processing (icip) , pp. 4390–4394, 2019.
    [8] [8] l. wenju, s. liye, j. qianqian, and c. liu, “a lightweight point cloud analysis
network based on graph walking,” in 2023 8th international conference on intelligent
informatics and biomedical sciences (ici- ibms) , 2023, pp. 45–48.
    [9] [9] f. c. belém, s. j. f. guimarães, and a. x. falcão, “superpixel segmentation using
dynamic and iterative spanning forest,” ieee signal processing letters , vol. 27, pp.
1440–1444, 2020.
    [10] [10] m. kazhdan, m. bolitho, and h. hoppe, “poisson surface reconstruc- tion,” in
eurographics symposium on geometry processing , pp. 1–10.

3. PARÁGRAFOS RELEVANTES (TOP-1):
  > OBJETIVO:
    Score: 3.001
        3d medical imaging by using point cloud generation luiza loures∗, zenilton kleber g. do patrocínio jr., silvio jamil f. guimarães
        ∗undergraduate student in computer science laboratory of image and multimedia data science (imscience) pontifícia universidade
        católica de minas gerais - minas gerais, brazil 30535-901 louresluiza6776@gmail.com, zenilton@pucminas.br, sjamil@pucminas.br
        abstract —three-dimensional (3d) reconstruction of anatom- ical structures from medical images represents a significant
        advancement in the healthcare field—a topic already explored in various studies. traditional methods often rely on contrast-
        enhanced computed tomography (ct), which is contraindicated for certain patients. to address this limitation, this work pro- poses
        a new methodology for 3d lung modeling. the method consists in generating a unified point cloud from segmented ct slices, followed
        by the construction of a polygonal mesh using poisson surface reconstruction. to enhance result visualization, a graphical user
        interface was developed to simultaneously display the reconstructed 3d model and the original dicom slices. the results of this
        new approach confirm the feasibility of the project, establishing an alternative method for the 3d representation of lungs. index
        terms —3d representation, computed tomography, point clouds, polygonal mesh. i. i ntroduction the three-dimensional (3d)
        reconstruction of anatomical structures from medical images represents a significant ad- vancement in the field of healthcare. it
        is fundamental for tumor and nodule detection, as well as for improving anatom- ical understanding during complex surgical
        procedures [1]. following wilhelm conrad roentgen’s discovery of x-rays in 1895, researchers have continuously developed
        non-invasive methods for examining the human body. in this context, computed tomography (ct), introduced in 1972 by cormack and
        hounsfield, has been largely responsible for the these methods. unlike ultrasound images, ct scans can be stored and analyzed by
        multiple specialists, making them particularly valuable for clinical diagnosis [2]. despite its benefits, the two-dimensional and
        monochro- matic nature of conventional ct images limits their inter- pretability. initial efforts to generate 3d renderings of
        tomo- graphic data began in the 1970s, but technological constraints delayed progress. with recent advances in computing power, 3d
        reconstruction techniques have evolved significantly. nev- ertheless, accurately isolating individual anatomical structures
        remains a challenging task. to address this issue, this work proposes a novel method for 3d reconstruction from ct scans. the
        proposed approach gen- erates a unified point cloud from all segmented tomographic slices. this cloud is then converted into a
        polygonal mesh,in which its points serve as the vertices of a graph used to model the surface of anatomical structures. the
        resulting model enables precise visualization and facilitates in-depth analysis by medical professionals. this paper is organized
        as follows: section ii reviews exist- ing 3d reconstruction methods for medical imaging. section iii details the proposed
        methodology, including point cloud generation and mesh construction. section iv presents the reconstruction outcomes. finally,
        section v concludes the study and outlines directions for future research. ii. r elated work three-dimensional visualization of
        medical images is an indispensable tool in modern medicine, especially in thoracic surgeries. computed tomography (ct) stands out
        as the pri- mary modality for data acquisition, enabling detailed internal visualization of the human body and the 3d
        reconstruction of complex anatomical structures [3]. ct’s ability to generate suitable data for 3d reconstruction has been widely
        leveraged in various clinical applications. for example, multislice computed tomography angiography (ctca) with 3d reconstruction
        is employed in evaluation of coronary artery anomalies, proving crucial for surgical planning and recognized as the most accurate
        modality for identifying anomalous vascular courses [4]. additionally, ct plays a fundamental role in the identification and
        monitoring of tumor growth, such as cardiac myxomas [5], as well as in the diagnosis and follow-up of aortic dissections. however,
        3d reconstruction is typically performed using contrast-enhanced ct scans, which require the administration of injectable or
        ingested contrast agents – usually iodine-based – to highlight specific anatomical structures. this dependency presents a
        significant limitation for patients with contrast allergies or impaired renal function, for whom contrast agents are con-
        traindicated [6]. in this context, the method proposed in this work seeks to address the challenge of working with
        non-contrast-enhanced ct images. the approach involves generating a unified point cloud from all segmented slices, followed by the
        construction of a polygonal mesh to enhance visualization and facilitate analysis. the importance of generating polygonal meshes
        from point clouds for creating solid 3d models is supported by (a) (b) (c) figure 1: computed tomography slices of the thorax from
        the same patient. other studies. dinesh [7] describes a technique for constructing triangular meshes from low-resolution point
        clouds to achieve super-resolution, inserting new points at the centroids of local triangles. similarly, wenju et al. [8] proposes
        a lightweight network based on “graph walking” for 3d point cloud analysis, which extracts long-range features and geometric
        structure from the point cloud by using graph-based connections to filter and relate neighboring points based on their
        similarities. iii. 3d m edical imaging the proposed method is structured around the main pillars of the tree, which are detailed
        in this section: processing and segmentation, polygonal mesh construction of point cloud generation. to illustrate each step of
        the process, we use a real ct scan as an example; three representative slices are shown in figure 1. a. preprocessing and
        segmentation computed tomography (ct) scans, as illustrated in figure 1, display various shades of gray. in these images, the
        intensity of the gray tone is directly related to tissue density: the lighter the shade, the denser the represented tissue. in a
        chest ct scan, such as the one shown in the figure, the brighter areas correspond to the spinal column and muscles, while the
        darker region, surrounded by the lighter structure, represents the lungs — the region of interest in this project. the similarity
        between shades of gray can hinder segmenta- tion, as the contrast between different structures is not always clear, as can be
        observed in figures 2(a) and 2(b). to mitigate this issue, contrast enhancement is applied as a preprocessing step to increase the
        visibility of specific structures. imple- mented using the imageenhance.contrast function from the pil (pillow) library, this
        method performs a transformation on the image histogram. this transformation expands the dynamic range of pixel intensity values,
        amplifying the differences between light and dark areas, shown in figures 2(c) and 2(d). as a result, this process facilitates
        both the identification and subsequent processing of the information contained in the image. with the transformed image, the next
        step is segmentation, aimed at isolating the region of interest in the ct scanwhile discarding irrelevant areas. for this purpose,
        the disf (dynamic and iterative spanning forest) algorithm [9] is applied to each slice of the image. disf operates based on
        user-defined parameters, including the number of initial seeds, the number of iterations, and the number of objects to be
        segmented. starting from these initial seeds, the algorithm iteratively groups pixels with similar intensity characteristics until
        it converges to the desired number of superpixels, the method is bounded by the complexity o(nlogn), where n is the number of
        pixels. following the initial segmentation generated by disf, the resulting mask undergoes a refinement process. first, the
        regions labeled as background by disf are excluded. then, to remove potential isolated components and refine the contours of the
        segmented areas, a binary morphological erosion oper- ation is applied to the mask. finally, a post-processing step selectively
        sets the highest-intensity pixels in the segmented image to zero. this approach ensures the preservation of high- density
        structures essential for analysis—such as pulmonary blood vessels—which, while dense, do not reach the maximum intensity values in
        the spectrum, thus remaining visible for three-dimensional reconstruction, obtaining as a final result figures 2(e) and 2(f). b.
        point clouds point clouds are collections of 3d coordinates that represent discrete geometric samples of an object’s 2d surfaces
        [7]. although they are defined as a 3d data structure that accu- rately reflects the real world, processing point clouds presents
        significant challenges due to their disorganized, sparse, and unstructured nature [8]. to improve the analysis of such irregular
        data, the use of graph-based approaches has been increasingly applied to point cloud processing. after preprocessing and
        segmentation, each tomographic slice is projected into 3d space. during this transformation, the z-axis dimension is adjusted to
        eliminate the artificial thick- ness that would otherwise be introduced by the point cloud, resulting in a “paper-thin” effect.
        each of these “sheets” are then stacked sequentially to form create a unified point cloud. although this cloud represents the 3d
        structure of the object from the ct scan, it still consists of sparse voxels, which (a) (b) (c) (d) (e) (f) figure 2: segmentation
        phases for point cloud creation. ex- ample 1: (a, c, e); example 2: (b, d, f). rows correspond to: real histogram slice, slice
        with histogram transformation, and final region of interest. is suboptimal for the precise analyses required in medical contexts,
        as illustrated in figure 3. therefore, covering the point cloud with a polygonal mesh becomes an essential step. c. polygonal mesh
        one of the most well-known algorithms for surface re- construction from points in computer graphics is the poisson method. it
        creates smooth surfaces and is minimally affected by noise in the data. this is possible because the method is a global solution,
        considering all points at once, without relying on heuristic partitioning, which reduces the solution to a sparse and
        well-conditioned linear system, according to [10]. this is the method that will be used to transform the point cloud into a robust
        3d model. however, before applying the poisson method, clustering is performed using the k-means algorithm. this step is crucial
        for separate the right and left sides of (a) (b) (c) (d) figure 3: partial results of key stages of the method. example 1: (a, c);
        example 2: (b, d). rows correspond to: point cloud and simplified point cloud. the lung from the bronchus, making them more
        manageable and avoiding possible shape distortions that could occur due to the short distance between these parts. after
        clustering, the poisson method is applied to each of the regions separately. in the end, we obtain a structure similar to a graph.
        in this model, the voxels from the point cloud are used as vertices. the oriented normals function as implicit edges, ultimately
        forming the 3d model shown in figure 4. (a) example 1 (b) example 2 figure 4: 3d lung model formed by a point cloud enclosed by a
        polygonal mesh. iv. r esults the results obtained confirmed the initial expectations, demonstrating the feasibility of a new
        approach to the three- dimensional representation of organs. although the generated model is an early prototype compared to more
        complex ex- isting 3d representations, this work establishes an alternative method for modeling anatomical structures from ct scan
        data. figure 5: graphical interface for viewing lung representations. to optimize visualization and facilitate comparison between
        the reconstructed 3d model and the original ct slices, a graphical user interface was developed. it allows simultaneous viewing of
        both lung representations, as illustrated in figure 5. on the left side is the three-dimensional image, and on the right side, the
        original dicom images are displayed, which—due to their specific format—typically require heavy software for viewing. below the ct
        images is a scrollbar that allows users to nav- igate through the slices sequentially and at their desired speed. this dynamic
        scrolling of images was designed to resemble the frame-by-frame progression of a film, as this approach helps users perceive
        spatial continuity and depth—features that are not easily observed when images are simply displayed side by side. this aids the
        user in understanding how the two- dimensional images were used to construct the final three- dimensional model. v. c onclusion
        and future works in conclusion, the initial objective of this work was fully achieved: to successfully demonstrate a new
        methodology for three-dimensional lung modeling. unlike some existing approaches that rely on contrast-enhanced images, the method
        is capable of analyzing ct data without the need for iodinated contrast agents. this feature represents a key advantage of the
        project, as contrast-enhanced ct scans are contraindicated for patients with certain conditions, such as allergies or impaired
        kidney function. as a next step, the goal is to improve the integration between dicom images and the reconstructed 3d model. to
        this end, an interactive feature is proposed, in which clicking on a specific area of a tomographic slice will automatically
        highlight the corresponding part of the 3d model. the implementation of this feature aims to further improve the visualization of
        the lung model, creating a way for anyuser, including non-specialists, to clearly understand what is happening inside their own
        body. this aligns with the central goal of the proposed method: to facilitate understanding and increase the educational value of
        3d representation in health- care. after the completion of this last feature, the next step is to perform validation with
        healthcare professionals and a usability study with patients and potential system users. for future versions, it’s possible to
        consider integrating other imaging modalities, such as magnetic resonance imaging, in addition to conducting tests with ct scans
        of other human organs, such as the brain. acknowledgment the authors thank the pontifícia universidade católica de minas gerais –
        puc-minas, coordenação de aperfeiçoa- mento de pessoal de nível superior – capes – (capes stic-amsud 88887.878869/2023-00,
        23-stic-10 and fi- nance code 001), the conselho nacional de desenvolvimento científico e tecnológico – cnpq (grants
        407242/2021-0, 306573/2022-9, 442950/2023-3) and fundação de apoio à pesquisa do estado de minas gerais – fapemig (grant apq-
        01079-23, apq-05058-23 and pce-00301-25). references [1] t. f. chen-yoshikawa, “evolution of three-dimensional computed to-
        mography imaging in thoracic surgery,” cancers , vol. 16, no. 11, p. 2161, 2024. [2] e. rocha-júnior and p. m. pêgo-fernandes,
        “three-dimensional com- puted tomography reconstruction in the era of digital personalized medicine,” sao paulo medical journal ,
        vol. 141, no. 1, pp. 1–3, 2023. [3] s. nakazawa, t. nagashima, n. kawatani, p. c. gedeon, a. k. desi- mone, h. igai, t. kosaka,
        and k. shirabe, “anatomy of the lung revisited by 3d-ct imaging,” video assist thorac surg , vol. 8, 2023. [4] k. rathore, m. teh,
        and m. newman, “deep intramural left anterior descending or large septal artery?” annals of thoracic surgery , vol. 111, no. 4, p.
        1409, 2021. [5] l. abdulmajid, h. el addouli, b. paelinck, and d. de bock, “natural growth of left atrial myxoma,” annals of
        thoracic surgery , vol. 111, no. 4, pp. e275–e277, 2021. [6] s. nakazawa, r. hanawa, t. nagashima, k. shimizu, t. yajima, and k.
        shirabe, “segmentectomy guided by 3-dimensional images recon- structed from nonenhanced computed tomographic data,” the annals of
        thoracic surgery , vol. 111, no. 3, pp. e301–e304, 2021. [7] c. dinesh, g. cheung, and i. v . baji ´c, “3d point cloud
        super-resolution via graph total variation on surface normals,” 2019 ieee international conference on image processing (icip) ,
        pp. 4390–4394, 2019. [8] l. wenju, s. liye, j. qianqian, and c. liu, “a lightweight point cloud analysis network based on graph
        walking,” in 2023 8th international conference on intelligent informatics and biomedical sciences (ici- ibms) , 2023, pp. 45–48.
        [9] f. c. belém, s. j. f. guimarães, and a. x. falcão, “superpixel segmentation using dynamic and iterative spanning forest,” ieee
        signal processing letters , vol. 27, pp. 1440–1444, 2020. [10] m. kazhdan, m. bolitho, and h. hoppe, “poisson surface reconstruc-
        tion,” in eurographics symposium on geometry processing , pp. 1–10.
  > PALAVRAS-CHAVES:
    Não encontrado.
  > PROBLEMA:
    Score: 2.001
        3d medical imaging by using point cloud generation luiza loures∗, zenilton kleber g. do patrocínio jr., silvio jamil f. guimarães
        ∗undergraduate student in computer science laboratory of image and multimedia data science (imscience) pontifícia universidade
        católica de minas gerais - minas gerais, brazil 30535-901 louresluiza6776@gmail.com, zenilton@pucminas.br, sjamil@pucminas.br
        abstract —three-dimensional (3d) reconstruction of anatom- ical structures from medical images represents a significant
        advancement in the healthcare field—a topic already explored in various studies. traditional methods often rely on contrast-
        enhanced computed tomography (ct), which is contraindicated for certain patients. to address this limitation, this work pro- poses
        a new methodology for 3d lung modeling. the method consists in generating a unified point cloud from segmented ct slices, followed
        by the construction of a polygonal mesh using poisson surface reconstruction. to enhance result visualization, a graphical user
        interface was developed to simultaneously display the reconstructed 3d model and the original dicom slices. the results of this
        new approach confirm the feasibility of the project, establishing an alternative method for the 3d representation of lungs. index
        terms —3d representation, computed tomography, point clouds, polygonal mesh. i. i ntroduction the three-dimensional (3d)
        reconstruction of anatomical structures from medical images represents a significant ad- vancement in the field of healthcare. it
        is fundamental for tumor and nodule detection, as well as for improving anatom- ical understanding during complex surgical
        procedures [1]. following wilhelm conrad roentgen’s discovery of x-rays in 1895, researchers have continuously developed
        non-invasive methods for examining the human body. in this context, computed tomography (ct), introduced in 1972 by cormack and
        hounsfield, has been largely responsible for the these methods. unlike ultrasound images, ct scans can be stored and analyzed by
        multiple specialists, making them particularly valuable for clinical diagnosis [2]. despite its benefits, the two-dimensional and
        monochro- matic nature of conventional ct images limits their inter- pretability. initial efforts to generate 3d renderings of
        tomo- graphic data began in the 1970s, but technological constraints delayed progress. with recent advances in computing power, 3d
        reconstruction techniques have evolved significantly. nev- ertheless, accurately isolating individual anatomical structures
        remains a challenging task. to address this issue, this work proposes a novel method for 3d reconstruction from ct scans. the
        proposed approach gen- erates a unified point cloud from all segmented tomographic slices. this cloud is then converted into a
        polygonal mesh,in which its points serve as the vertices of a graph used to model the surface of anatomical structures. the
        resulting model enables precise visualization and facilitates in-depth analysis by medical professionals. this paper is organized
        as follows: section ii reviews exist- ing 3d reconstruction methods for medical imaging. section iii details the proposed
        methodology, including point cloud generation and mesh construction. section iv presents the reconstruction outcomes. finally,
        section v concludes the study and outlines directions for future research. ii. r elated work three-dimensional visualization of
        medical images is an indispensable tool in modern medicine, especially in thoracic surgeries. computed tomography (ct) stands out
        as the pri- mary modality for data acquisition, enabling detailed internal visualization of the human body and the 3d
        reconstruction of complex anatomical structures [3]. ct’s ability to generate suitable data for 3d reconstruction has been widely
        leveraged in various clinical applications. for example, multislice computed tomography angiography (ctca) with 3d reconstruction
        is employed in evaluation of coronary artery anomalies, proving crucial for surgical planning and recognized as the most accurate
        modality for identifying anomalous vascular courses [4]. additionally, ct plays a fundamental role in the identification and
        monitoring of tumor growth, such as cardiac myxomas [5], as well as in the diagnosis and follow-up of aortic dissections. however,
        3d reconstruction is typically performed using contrast-enhanced ct scans, which require the administration of injectable or
        ingested contrast agents – usually iodine-based – to highlight specific anatomical structures. this dependency presents a
        significant limitation for patients with contrast allergies or impaired renal function, for whom contrast agents are con-
        traindicated [6]. in this context, the method proposed in this work seeks to address the challenge of working with
        non-contrast-enhanced ct images. the approach involves generating a unified point cloud from all segmented slices, followed by the
        construction of a polygonal mesh to enhance visualization and facilitate analysis. the importance of generating polygonal meshes
        from point clouds for creating solid 3d models is supported by (a) (b) (c) figure 1: computed tomography slices of the thorax from
        the same patient. other studies. dinesh [7] describes a technique for constructing triangular meshes from low-resolution point
        clouds to achieve super-resolution, inserting new points at the centroids of local triangles. similarly, wenju et al. [8] proposes
        a lightweight network based on “graph walking” for 3d point cloud analysis, which extracts long-range features and geometric
        structure from the point cloud by using graph-based connections to filter and relate neighboring points based on their
        similarities. iii. 3d m edical imaging the proposed method is structured around the main pillars of the tree, which are detailed
        in this section: processing and segmentation, polygonal mesh construction of point cloud generation. to illustrate each step of
        the process, we use a real ct scan as an example; three representative slices are shown in figure 1. a. preprocessing and
        segmentation computed tomography (ct) scans, as illustrated in figure 1, display various shades of gray. in these images, the
        intensity of the gray tone is directly related to tissue density: the lighter the shade, the denser the represented tissue. in a
        chest ct scan, such as the one shown in the figure, the brighter areas correspond to the spinal column and muscles, while the
        darker region, surrounded by the lighter structure, represents the lungs — the region of interest in this project. the similarity
        between shades of gray can hinder segmenta- tion, as the contrast between different structures is not always clear, as can be
        observed in figures 2(a) and 2(b). to mitigate this issue, contrast enhancement is applied as a preprocessing step to increase the
        visibility of specific structures. imple- mented using the imageenhance.contrast function from the pil (pillow) library, this
        method performs a transformation on the image histogram. this transformation expands the dynamic range of pixel intensity values,
        amplifying the differences between light and dark areas, shown in figures 2(c) and 2(d). as a result, this process facilitates
        both the identification and subsequent processing of the information contained in the image. with the transformed image, the next
        step is segmentation, aimed at isolating the region of interest in the ct scanwhile discarding irrelevant areas. for this purpose,
        the disf (dynamic and iterative spanning forest) algorithm [9] is applied to each slice of the image. disf operates based on
        user-defined parameters, including the number of initial seeds, the number of iterations, and the number of objects to be
        segmented. starting from these initial seeds, the algorithm iteratively groups pixels with similar intensity characteristics until
        it converges to the desired number of superpixels, the method is bounded by the complexity o(nlogn), where n is the number of
        pixels. following the initial segmentation generated by disf, the resulting mask undergoes a refinement process. first, the
        regions labeled as background by disf are excluded. then, to remove potential isolated components and refine the contours of the
        segmented areas, a binary morphological erosion oper- ation is applied to the mask. finally, a post-processing step selectively
        sets the highest-intensity pixels in the segmented image to zero. this approach ensures the preservation of high- density
        structures essential for analysis—such as pulmonary blood vessels—which, while dense, do not reach the maximum intensity values in
        the spectrum, thus remaining visible for three-dimensional reconstruction, obtaining as a final result figures 2(e) and 2(f). b.
        point clouds point clouds are collections of 3d coordinates that represent discrete geometric samples of an object’s 2d surfaces
        [7]. although they are defined as a 3d data structure that accu- rately reflects the real world, processing point clouds presents
        significant challenges due to their disorganized, sparse, and unstructured nature [8]. to improve the analysis of such irregular
        data, the use of graph-based approaches has been increasingly applied to point cloud processing. after preprocessing and
        segmentation, each tomographic slice is projected into 3d space. during this transformation, the z-axis dimension is adjusted to
        eliminate the artificial thick- ness that would otherwise be introduced by the point cloud, resulting in a “paper-thin” effect.
        each of these “sheets” are then stacked sequentially to form create a unified point cloud. although this cloud represents the 3d
        structure of the object from the ct scan, it still consists of sparse voxels, which (a) (b) (c) (d) (e) (f) figure 2: segmentation
        phases for point cloud creation. ex- ample 1: (a, c, e); example 2: (b, d, f). rows correspond to: real histogram slice, slice
        with histogram transformation, and final region of interest. is suboptimal for the precise analyses required in medical contexts,
        as illustrated in figure 3. therefore, covering the point cloud with a polygonal mesh becomes an essential step. c. polygonal mesh
        one of the most well-known algorithms for surface re- construction from points in computer graphics is the poisson method. it
        creates smooth surfaces and is minimally affected by noise in the data. this is possible because the method is a global solution,
        considering all points at once, without relying on heuristic partitioning, which reduces the solution to a sparse and
        well-conditioned linear system, according to [10]. this is the method that will be used to transform the point cloud into a robust
        3d model. however, before applying the poisson method, clustering is performed using the k-means algorithm. this step is crucial
        for separate the right and left sides of (a) (b) (c) (d) figure 3: partial results of key stages of the method. example 1: (a, c);
        example 2: (b, d). rows correspond to: point cloud and simplified point cloud. the lung from the bronchus, making them more
        manageable and avoiding possible shape distortions that could occur due to the short distance between these parts. after
        clustering, the poisson method is applied to each of the regions separately. in the end, we obtain a structure similar to a graph.
        in this model, the voxels from the point cloud are used as vertices. the oriented normals function as implicit edges, ultimately
        forming the 3d model shown in figure 4. (a) example 1 (b) example 2 figure 4: 3d lung model formed by a point cloud enclosed by a
        polygonal mesh. iv. r esults the results obtained confirmed the initial expectations, demonstrating the feasibility of a new
        approach to the three- dimensional representation of organs. although the generated model is an early prototype compared to more
        complex ex- isting 3d representations, this work establishes an alternative method for modeling anatomical structures from ct scan
        data. figure 5: graphical interface for viewing lung representations. to optimize visualization and facilitate comparison between
        the reconstructed 3d model and the original ct slices, a graphical user interface was developed. it allows simultaneous viewing of
        both lung representations, as illustrated in figure 5. on the left side is the three-dimensional image, and on the right side, the
        original dicom images are displayed, which—due to their specific format—typically require heavy software for viewing. below the ct
        images is a scrollbar that allows users to nav- igate through the slices sequentially and at their desired speed. this dynamic
        scrolling of images was designed to resemble the frame-by-frame progression of a film, as this approach helps users perceive
        spatial continuity and depth—features that are not easily observed when images are simply displayed side by side. this aids the
        user in understanding how the two- dimensional images were used to construct the final three- dimensional model. v. c onclusion
        and future works in conclusion, the initial objective of this work was fully achieved: to successfully demonstrate a new
        methodology for three-dimensional lung modeling. unlike some existing approaches that rely on contrast-enhanced images, the method
        is capable of analyzing ct data without the need for iodinated contrast agents. this feature represents a key advantage of the
        project, as contrast-enhanced ct scans are contraindicated for patients with certain conditions, such as allergies or impaired
        kidney function. as a next step, the goal is to improve the integration between dicom images and the reconstructed 3d model. to
        this end, an interactive feature is proposed, in which clicking on a specific area of a tomographic slice will automatically
        highlight the corresponding part of the 3d model. the implementation of this feature aims to further improve the visualization of
        the lung model, creating a way for anyuser, including non-specialists, to clearly understand what is happening inside their own
        body. this aligns with the central goal of the proposed method: to facilitate understanding and increase the educational value of
        3d representation in health- care. after the completion of this last feature, the next step is to perform validation with
        healthcare professionals and a usability study with patients and potential system users. for future versions, it’s possible to
        consider integrating other imaging modalities, such as magnetic resonance imaging, in addition to conducting tests with ct scans
        of other human organs, such as the brain. acknowledgment the authors thank the pontifícia universidade católica de minas gerais –
        puc-minas, coordenação de aperfeiçoa- mento de pessoal de nível superior – capes – (capes stic-amsud 88887.878869/2023-00,
        23-stic-10 and fi- nance code 001), the conselho nacional de desenvolvimento científico e tecnológico – cnpq (grants
        407242/2021-0, 306573/2022-9, 442950/2023-3) and fundação de apoio à pesquisa do estado de minas gerais – fapemig (grant apq-
        01079-23, apq-05058-23 and pce-00301-25). references [1] t. f. chen-yoshikawa, “evolution of three-dimensional computed to-
        mography imaging in thoracic surgery,” cancers , vol. 16, no. 11, p. 2161, 2024. [2] e. rocha-júnior and p. m. pêgo-fernandes,
        “three-dimensional com- puted tomography reconstruction in the era of digital personalized medicine,” sao paulo medical journal ,
        vol. 141, no. 1, pp. 1–3, 2023. [3] s. nakazawa, t. nagashima, n. kawatani, p. c. gedeon, a. k. desi- mone, h. igai, t. kosaka,
        and k. shirabe, “anatomy of the lung revisited by 3d-ct imaging,” video assist thorac surg , vol. 8, 2023. [4] k. rathore, m. teh,
        and m. newman, “deep intramural left anterior descending or large septal artery?” annals of thoracic surgery , vol. 111, no. 4, p.
        1409, 2021. [5] l. abdulmajid, h. el addouli, b. paelinck, and d. de bock, “natural growth of left atrial myxoma,” annals of
        thoracic surgery , vol. 111, no. 4, pp. e275–e277, 2021. [6] s. nakazawa, r. hanawa, t. nagashima, k. shimizu, t. yajima, and k.
        shirabe, “segmentectomy guided by 3-dimensional images recon- structed from nonenhanced computed tomographic data,” the annals of
        thoracic surgery , vol. 111, no. 3, pp. e301–e304, 2021. [7] c. dinesh, g. cheung, and i. v . baji ´c, “3d point cloud
        super-resolution via graph total variation on surface normals,” 2019 ieee international conference on image processing (icip) ,
        pp. 4390–4394, 2019. [8] l. wenju, s. liye, j. qianqian, and c. liu, “a lightweight point cloud analysis network based on graph
        walking,” in 2023 8th international conference on intelligent informatics and biomedical sciences (ici- ibms) , 2023, pp. 45–48.
        [9] f. c. belém, s. j. f. guimarães, and a. x. falcão, “superpixel segmentation using dynamic and iterative spanning forest,” ieee
        signal processing letters , vol. 27, pp. 1440–1444, 2020. [10] m. kazhdan, m. bolitho, and h. hoppe, “poisson surface reconstruc-
        tion,” in eurographics symposium on geometry processing , pp. 1–10.
  > CONTRIBUIÇÃO:
    Não encontrado.

4. RESUMO GERAL:
    the results of this new approach confirm the feasibility of the project,
    establishing an alternative method for the 3d representation of lungs. in these
    images, the intensity of the gray tone is directly related to tissue density:
    the lighter the shade, the denser the represented tissue. in a chest ct scan,
    such as the one shown in the figure, the brighter areas correspond to the spinal
    column and muscles, while the darker region, surrounded by the lighter
    structure, represents the lungs — the region of interest in this project.
    starting from these initial seeds, the algorithm iteratively groups pixels with
    similar intensity characteristics until it converges to the desired number of
    superpixels, the method is bounded by the complexity o(nlogn), where n is the
    number of pixels. r esults the results obtained confirmed the initial
    expectations, demonstrating the feasibility of a new approach to the three-
    dimensional representation of organs. it allows simultaneous viewing of both
    lung representations, as illustrated in figure 5. on the left side is the
    three-dimensional image, and on the right side, the original dicom images are
    displayed, which—due to their specific format—typically require heavy software
    for viewing.

==================================================

--- ARTIGO: articles/A Gated Review Attention Framework for Topics in Graph-Based Recommenders.pdf ---

1. TOP 10 TERMOS:
    - user           : 80
    - reviews        : 55
    - model          : 51
    - based          : 50
    - item           : 50
    - topic          : 49
    - items          : 49
    - graft          : 47
    - review         : 45
    - attention      : 44

2. REFERÊNCIAS EXTRAÍDAS (39 total):
    [1] [12] defines recommender system (rs) as automated software tools that leverage machine
∗both authors contributed equally to this research. in: proceedings of the brazilian
symposium on multimedia and the web (webme- dia’2025). rio de janeiro, brazil. porto
alegre: brazilian computer society, 2025. ©2025 sbc – brazilian computing society. issn
2966-2753learning and statistical models to suggest items, such as products, movies,
books, or music, tailored to individual user preferences. these systems have become
pervasive in modern digital experi- ences, driving key functions across e-commerce,
entertainment, and social media. by offering personalized suggestions, they en- hance user
satisfaction, reduce decision-making effort, and generate substantial business value
through increased engagement and sales. additionally, pires et al .
    [2] [17] , raza and ding
    [3] [18] emphasizes the importance of rs due to their ability to deliver relevant and person-
alized content. while practical algorithms are essential, the core challenge involves
accurately understanding and modeling user preferences [ 24]. rs must identify complex
relationships within data, uncovering patterns and connections that are often not imme-
diately apparent. in this context, online reviews can enhance this process by offering
rich, user-generated data that captures nuanced experiences and preferences. these reviews
help describe the com- plex interactions between users and items, providing contextual
signals that go beyond structured data such as ratings or clicks. online reviews, which
users generate based on their personal ex- periences, have become a central channel for
sharing opinions in digital environments. unlike traditional advertising, users often
perceive these reviews as more authentic and persuasive, which can influence their
decisions. favorable evaluations can boost con- fidence, while negative reviews usually
deter potential interactions [5, 14, 21]. beyond their credibility, reviews shape consumer
behavior through emotional and social dynamics. the sentiments that consumers express can
create emotional connections that reinforce user en- gagement. star ratings and consensus
opinions serve as social proof, guiding consumers to align with the majority view. this
influence arises from a desire for accurate information and social belonging. consumers
may follow group opinions to gain approval or avoid criticism, even when the choice is not
the optimal one. moreover, reviews serve as a feedback mechanism for businesses, helping
identify strengths and areas for improvement, and fostering loyalty through user
engagement [5, 21]. user reviews offer nuanced opinions beyond simple numerical ratings,
enabling rs to build more detailed user and item profiles
    [4] [4]. although this data is unstructured, advancements in natural language processing (nlp)
facilitate the extraction of key informa- tion, such as topics and sentiments, a strategy
proven to improve19 webmedia’2025, rio de janeiro, brazil ferreira et al. recommendation
models [ 8]. in this context, the integration of tex- tual insights into rs directly
addresses fundamental challenges. rich review content helps mitigate data sparsity and
cold-start problems by uncovering user preferences even when explicit rat- ings are
missing [ 26]. moreover, by anchoring recommendations in detailed user feedback, the
resulting models offer greater trans- parency and interpretability [ 13]. we hypothesize
that integrating semantic information from reviews into the user-item graph can help the
model learn more expressive representations for both users and items. to explore this, we
propose the gated review attention frame- work for topics (graft), a graph-based
recommender that incorpo- rates topic extraction from user reviews to enrich these
interactions. graft models user-item relationships as a bipartite graph, where nodes
represent users and items, and edges reflect their interactions. we integrate topic-based
representations of reviews as additional signals into this structure. we apply a gated
attention mechanism to balance the contribution of review-based information with user and
item embeddings, allowing the model to select the most informative features adaptively.
this approach enhances the representation of complex user-item relationships by combining
collaborative signals with content derived from reviews. our work highlights several key
differences from existing liter- ature. firstly, the reviews undergo pre-processing in a
prior task. this approach enables a detailed analysis of each dataset and fa- cilitates
the search for the optimal configuration, allowing for an examination of potential human
understanding. secondly, we pro- posed a double attention-gated mechanism that provides
two levels of decision-making regarding the selection of embeddings or the distribution of
topics in the training process. the model operates at the node level, considering the
internal relationships within the graph, and at the structural level, where we assign each
node a greater weight to adjust the overall weights more effectively. the main
contributions of this work are as follows. (1)we introduce a method to incorporate
topic-based represen- tations of user reviews into a recommendation model, utiliz- ing a
gated attention mechanism to balance the contributions of textual content and user-item
embeddings dynamically. (2)we present an analysis that examines the alignment between
review-based topics in the ground-truth list and those in the generated recommendations,
offering a qualitative perspec- tive on the semantic consistency of the recommendations.
this paper is structured as follows. section 2 presents the related works. section 3
introduces the background and supporting tech- niques. section 4 presents the proposed
graft framework, de- tailing its architecture and integration of review topics into the
recommendation process. section 5 describes the experimental setup, including datasets,
baselines, and evaluation metrics. sec- tion 6 provides an in-depth analysis of graft’s
recommendation behavior, with emphasis on the composition of the ranked lists. finally,
section 7 concludes the paper and outlines directions for future work. 2 related works
several early models utilized review texts to address data sparsity and enrich user-item
representations. deepconn [ 25] introducedparallel cnn-based networks for users and items
to share a layer for rating estimation. it treated reviews as rich user feedback; how-
ever, cnn’s inability to model long-range dependencies limited its effectiveness.
similarly, narre [ 3] utilized cnns for text encoding and incorporated an attention
mechanism to weight informative reviews, thereby enhancing prediction and explainability.
however, neither model incorporated structured semantic representations nor handled
variations in review quality over time. other models incorporated topic or aspect-based
representa- tions to model fine-grained preferences. musto et al .
    [5] [16] extracted entities and sentiment scores from reviews to construct multi- dimensional
user profiles, which we then used in a multi-criteria col- laborative filtering setting.
cheng et al .
    [6] [6] proposed 3ncf, which also focused on capturing aspect-level signals, employing a
topic- guided attention mechanism to align user interests with item charac- teristics.
these approaches emphasized matching user preferences with interpretable features derived
from text but did not leverage graph-based relational structures. more recent models have
combined deep language representa- tions and attention mechanisms to capture contextual
information more effectively. li et al .
    [7] [14] used bigru and attention refine roberta embeddings to emphasize salient review
segments, inte- grating them into an attentional factorization machine (afm) to capture
nuanced user-item interactions while reducing the impact of noise. a separate line of work
explores graph-based methods that integrate review information with user-item interaction
structures. yang and cai
    [8] [22] presented erri, which models both semantic relations between review words through a
review text graph and collaborative signals through a user-item interaction graph. we fuse
these two sources to inform rating predictions. he et al .
    [9] [10] introduced rdrec, a diffusion-based approach that simulates user interest evolution
by corrupting and reconstructing review-based features using a transformer. shang et al .
    [10] [19] further explored sentiment-aware representations by applying hierarchical atten- tion
to review texts, capturing emotional nuance and integrating it into a neural collaborative
filtering model. graft differs from these works by unifying topic modeling and graph
attention in a gated framework. rather than relying solely on word- or review-level
attention, graft encodes topical informa- tion as part of node features. it employs graph
attention layers with gating mechanisms that regulate the propagation of semantic and
relational signals throughout the network. this design enables more interpretable and
adaptive representation learning, particularly in cases where interaction patterns are
sparse or heterogeneous. 3 background this work integrates three complementary techniques
to enhance recommendation performance based on graph and textual data. we employ bertopic
[ 9] to extract high-level semantic information from user reviews by combining
transformer-based embeddings with clustering techniques. this method enables the
identification of coherent topics across reviews, which we can integrate into the model to
enhance interpretability and user preference modeling. second, graph attention networks
(gat) [ 20] provide a powerful mechanism for learning on graph-structured data. lastly,
inspired by gated units in recurrent neural networks [ 7], we incorporate a20 a gated
review attention framework for topics in graph-based recommenders webmedia’2025, rio de
janeiro, brazil gating mechanism that regulates the contribution of distinct infor- mation
sources, such as user/item embeddings and topic features. 3.1 topic modeling with bertopic
bertopic is a neural topic modeling technique that leverages transformer- based embeddings
and clustering to extract coherent topics from textual data. it begins by encoding
documents using pre-trained lan- guage models, preserving semantic relationships in a
high-dimensional vector space. we then project these embeddings into a lower-dimensional
space and group them into semantically consistent clusters with a non-supervised
algorithm. to construct interpretable topics from these clusters, bertopic employs a
class-based variant of term frequency-inverse document frequency (tf-idf), which
identifies words most representative of each cluster. this pipeline enables the discovery
of latent themes in reviews, which we integrate into the recommendation framework as
interpretable and context-rich signals
    [11] [9]. 3.2 graph attention networks veličković et al .
    [12] [20] proposed graph attention networks (gat), which are a neural architecture that
operates on graph-structured data, allowing nodes to attend to their neighbors during
represen- tation learning dynamically. unlike traditional graph convolutional networks,
which uniformly aggregate information from neighbors, gat employs a self-attention
mechanism to assign distinct impor- tance weights to each neighbor, thereby making the
aggregation process more expressive and adaptive. this is particularly suitable for
recommendation tasks, as it naturally captures the collaborative filtering principle by
prioritizing informative neighbor interactions during the learning process. by leveraging
multi-head attention, gat not only enhances model capacity and robustness but also retains
interpretability through the learned attention weights. 3.3 gated units and feature
control inspired by cho et al .
    [13] [7] gated mechanisms in recurrent neural networks (rnns), such as the gated recurrent unit
(gru), we in- corporate a gating strategy to regulate the contribution of distinct data
sources in our model. in rnns, gates control how much past information should be retained
or forgotten when computing the next hidden state. drawing from this intuition, our model
adapts a similar mechanism to balance between user/item embeddings and topical features
derived from textual reviews. the gate outputs a continuous value that determines the
extent to which each rep- resentation, semantic or structural, contributes to the final
fused representation, thus enabling a more flexible and context-aware integration during
training. 4 proposal 4.1 topic extraction from reviews the first step of topic extraction
was the pre-processing and clean- ing phase. the approach adopted preserves the full set
of reviews, removing only non-informative elements such as html tags, ex- cessive
punctuation, and dataset-specific textual artifacts. for ex- ample, in the amazon movies
and tv dataset, item descriptions embedded within some reviews were removed. emojis and
shortreviews were retained to preserve the original characteristics of the data. in
sequence, we use bertopic to generate topics by utilizing transformer-based models to
convert each document into a dense vector, thereby placing similar documents closer
together in a high- dimensional space. we generate the embedding representation from the
sentence transformers library all-mpnet-base-v21addition- ally, to enable clustering of
high-dimensional embeddings, we apply dimensionality reduction using uniform manifold
approximation and projection (umap). the model is configured through hyper- parameters,
including the number of components, distance metric, number of neighbors, and minimum
distance. after reduction, the k-means clustering algorithm is used to identify clusters.
this is particularly important, as not all documents are associated with a well-defined
topic. the topic representation chosen in bertopic utilizes the main keywords associated
with each topic. for topic labeling, we used the keybert-inspired representation model.
this model selects representative terms for each topic by aligning them with the em-
bedded documents in each cluster. domain-specific stopwords (e.g., “movie,” “film,” “dvd,”
“disc”) were also removed to eliminate terms with low discriminative value. additionally,
the number of features was defined, and n-gram representations (unigrams, bigrams, and
trigrams) were included to enhance the expressiveness and clarity of the extracted topics.
the overall bertopic pipeline involved: (1) embedding reviews. (2) reducing embedding
dimensions. (3) identifying topics with the clusterization method. (4) representing topics
using keybert-derived keywords. (5)using a custom stopword list to remove
domain-irrelevant terms and trigrams for richer features. 4.2 gated review attention
framework for topics (graft) to integrate topics derived from reviews into a graph-based
collabo- rative filtering architecture, graft2employs a graph neural archi- tecture that
jointly leverages rating interactions and review topics through gated fusion mechanisms
and attention-based message passing. this analysis revisits our initial hypothesis that
incorporat- ing semantic information from reviews into the user-item graph can enhance the
expressiveness of learned representations and improve the quality of recommendations. to
implement this, the model be- gins by assigning each user 𝑢and item𝑖a learnable embedding
vector e𝑢,e𝑖∈r𝑑, where𝑑is the base embedding dimension. we then project these initial
representations into a structural space of size𝑑′to align with the multi-head attention
mechanism, as defined by: ℎ𝑢=𝑅𝑒𝐿𝑈(𝑊𝑝𝑟𝑜𝑗.𝑒𝑢), ℎ𝑖=𝑅𝑒𝐿𝑈(𝑊𝑝𝑟𝑜𝑗.𝑒𝑖),(1) where theℎ𝑢andℎ𝑖are the
projected embeddings of the user and items, after applying a linear transformation by a
relu activation, and𝑊𝑝𝑟𝑜𝑗∈r𝑑′×𝑑is the projection matrix used to transform the initial
embeddings in the structural space used in graph attention network (gat) layers.
1available in: https://huggingface.co/sentence-transformers/all-mpnet-base-v2 2available
at: https://github.com/ferreira-eduardo/graft.git21 webmedia’2025, rio de janeiro, brazil
ferreira et al. the model interactions are the multiple layers of the gatv2conv operator.
each layer propagates and aggregates neighbor informa- tion using edge features as
attention biases, ℎ′ 𝑣=gatv2conv(ℎ𝑣,ℎn(𝑣),𝑒𝑢𝑣), (2) where𝑒𝑢𝑣∈r𝑘is the topic distribution
and 𝑘the dimensionality, on the edge from node 𝑢to node𝑣. additionally, to define the
gated mechanism, a transformation is applied to a vector of representation e𝑢, which
represents a user embedding within the model’s context. to control the flow of semantic
information, the model employs a learned gating mechanism that regulates how much of each
trans- formed embedding dimension is retained. the gate vector for user 𝑢is defined as:
g𝑢=𝜎/√︁a√︂enleftbigw𝑢 𝑔e𝑢+b𝑢 𝑔/√︁a√︂en√︂ightbig∈ [0,1]𝑘, (3) where𝜎(·)is the element-wise
sigmoid function, w𝑢𝑔∈r𝑘×𝑑is a learned projection matrix, and b𝑢𝑔is the corresponding
bias. the dimensionality 𝑘corresponds to the topic space. in parallel, a linear
transformation is applied to map the original user embedding into the same topic-aligned
space: ˜e𝑢=w𝑢 𝑝e𝑢+b𝑢 𝑝∈r𝑘, (4) where w𝑢𝑝∈r𝑘×𝑑and b𝑢𝑝are also learnable parameters. this
transformed embedding ˜e𝑢is then modulated by the gate g𝑢, which selectively filters or
amplifies individual components of the repre- sentation. this gated linear unit allows the
model to dynamically control feature fusion, learning which aspects of the semantic trans-
formation are most relevant for each user. on the structural level, it involves blending
two representations of a user or an item. we define a gated fusion mechanism that combines
a topic-based vector t𝑥and a transformed embedding ˜e𝑥, modulated by a learned gate vector
g𝑥. the fusion is given by ˆt𝑢=g𝑢⊙t𝑢+/√︁a√︂enleftbig1−g𝑢/√︁a√︂en√︂ightbig⊙˜e𝑢, (5)
where⊙denotes element-wise product. this operation performs a dimension-wise blend between
semantic and structural features. for each dimension 𝑗, the fusion can be expressed as
ˆ𝑡𝑥,𝑗=𝑔𝑥,𝑗𝑡𝑥,𝑗+(1−𝑔𝑥,𝑗)˜𝑒𝑥,𝑗, (6) where𝑔𝑥,𝑗∈ [0,1]controls the relative influence of the
topic and structural components. when 𝑔𝑥,𝑗≈1, the model prioritizes the topic signal,
whereas when 𝑔𝑥,𝑗≈0, it favors the projected embedding. this formulation enables adaptive
feature integration, allowing the model to learn per-dimension preferences for each node
type. finally, the model produces a prediction by combining the gated structural and
topic-aware representations of the user and item. let ˆt𝑢andˆt𝑖denote the fused
representations obtained after the final gating step. these vectors are concatenated and
passed through a fully connected layer: x=fc/b√︂acketleftbig
e𝑢∥a𝑢∥ˆt𝑢∥e𝑖∥a𝑖∥ˆt𝑖/b√︂acket√︂ightbig , (7) where a𝑢,a𝑖are the outputs of the attention
fusion submodules and∥denotes concatenation. this attention-gated fusion enables the model
to learn when to trust latent embeddings versus topical signals on a per-dimension basis.
the concatenated vector xis passed through a fully connected layer with dropout, followed
by a scaled activation to constrain the output to the rating range thatdefines the width
of the rating scale. the final output is a scalar prediction of the user’s rating for the
item. 5 experimental setup 5.1 datasets we select three distinct datasets: amazon movies
and tv3, imdb4, and rotten tomatoes5. these sources offer a comprehensive view by
integrating user-generated reviews with audience ratings and metadata across diverse
platforms. table 1 presents key statistics for each dataset before and after
preprocessing. we began by removing invalid or incomplete entries from all datasets to
ensure data quality. as a general criterion, we selected users with at least 10
interactions to focus on active profiles and reduce sparsity. we then further processed
each dataset according to its specific characteristics. due to its large scale, the amazon
dataset required additional filtering: we also retained only items with at least 100
interactions to ensure meaningful representation. the rotten tomatoes dataset posed a
unique challenge, as it in- cludes non-numeric rating formats such as “a”, “b”, “f”, and
“a-”. to ensure consistency and comparability, we retained only entries with normalized
fractional or numeric ratings (e.g., 1/5, 2/4, 10/10), aligning all scores to a standard
1–5 scale. notably, the imdb dataset experienced a substantial reduction in size after
filtering, reflecting its initially sparse distribution of user-item interactions. table
1: impact of preprocessing, removal of incomplete en- tries, retention of users with
≥interactions (and items with ≥100 interactions for amazon), and rating normalization for
rotten tomatoes, on dataset size (reviews, users, items), reviews per user/item, and
overall sparsity across the ama- zon movies & tv, imdb, and rotten tomatoes datasets.
amazon movies and tv imdb rotten tomatoes metric raw processed raw processed raw processed
reviews 17.3m 1.4m 932.4k 264.9k 1.1m 543.5k users 6.5m 76k 427k 7k 11k 2.6k items 747.7k
27.3k 1.1k 1.1k 17.7k 17.4k reviews/user 2.664 19.12 3.28 37.07 100.06 208.17 reviews/item
23.173 53.18 12.28 230.40 63.77 31.13 sparsity 99.99% 99.93% 99.81% 96.77% 99.42% 98.80%
5.2 baselines for comparison, we evaluate our approach against three baseline algorithms:
singular value decomposition (svd)6, deepconn [ 25], and kann [ 15]. svd is a classical
and widely adopted collaborative filtering technique that factorizes the user-item
interaction matrix into lower-dimensional latent spaces. by capturing hidden patterns in
user preferences and item characteristics, svd has demonstrated strong performance in
various recommendation scenarios. deep- conn enhances collaborative filtering by
incorporating textual reviews from both users and items. it employs two parallel convolu-
tional neural networks to learn user and item representations from 3available at:
https://amazon-reviews-2023.github.io/ 4available at:
https://ieee-dataport.org/open-access/imdb-movie-reviews-dataset 5available at:
https://www.kaggle.com/datasets/stefanoleone992/rotten-tomatoes-
movies-and-critic-reviews-dataset 6available in:
https://surprise.readthedocs.io/en/stable/matrix_factorization.html22 a gated review
attention framework for topics in graph-based recommenders webmedia’2025, rio de janeiro,
brazil review text, thereby improving rating prediction. kann builds upon this concept by
integrating review content with external knowledge through a knowledge-aware attention
mechanism. this enables the model to generate more accurate recommendations while also
providing interpretable explanations. 5.3 hyperparameter tuning for graft, we adopted an
empirical approach to select hyper- parameters, concentrating on those that significantly
influenced model performance. initially, we conducted randomized sampling over the
following search space: embedding dimensions 32, 64, 128; number of layers 2, 3, 4; number
of attention heads 2, 4, 8; leaky relu negative slope ( 𝛼) 0.2, 0.3, 0.4, 0.5; dropout
rates 0.2, 0.3, 0.4, 0.5; and learning rates 0.1, 0.001, 0.0001. from this search, we
iden- tified the best-performing hyperparameter configuration for each dataset. for the
imdb dataset, the optimal model parameters in- cluded an embedding dimension of 128, two
layers, four attention heads,𝛼=0.2, a learning rate of 0.001, and a dropout rate of 0.2.
for the amazon dataset, the ideal configuration featured an em- bedding dimension of 32,
two layers, four attention heads, 𝛼=0.4, a learning rate of 0.001, and a dropout rate of
0.5. the best setup for rotten tomatoes was identical to that of imdb, with an embed- ding
dimension of 128, two layers, four attention heads, 𝛼=0.2, a learning rate of 0.001, and a
dropout rate of 0.2. all configurations utilized concat=false . for the baseline methods,
kann [ 15], we followed the hyper- parameter configurations suggested in their original
papers. the model weights were optimized using the adam optimizer with 𝛽1=0.9,𝛽2=0.98,
and𝜖=1.0×10−9. the learning rate was set as 0.0001, and the batch size was fixed at 128.
both the knowledge embedding and latent embedding dimensions were set to 50, result- ing
in a total dimension 𝑑=100after concatenating the context entity with the entity itself.
all hidden layers were configured with a size of 1024, and the number of attention spaces
𝐻was set to 4. to manage input length, we retained the portion of reviews that covered 90%
of users and items in terms of length, and 80% in terms of quantity. for the svd, we
utilized the implementation provided by the surprise library [ 11] and conducted a grid
search to determine the optimal hyperparameter configuration. the search space included
the number of latent factors {32, 64, 128, 256}, number of training epochs {20, 30, 40},
learning rate {0.01, 0.001, 0.005, 0.0001}, and regularization term {0.5, 0.05}. we used
the biased svd variant and selected the best configuration based on validation rmse. the
final model was trained with svd(n_factors=256, n_epochs=20, biased=true, lr_all=0.005,
reg_all=0.05) . for the deepconn [ 25], we adopted the hyperparameter config- uration
described in the original paper. the length of each review document was fixed at 1000
tokens. word embeddings were ini- tialized with a dimension of 64. the convolutional layer
contained 100 neurons with a kernel window size of 3. the latent dimension for the final
user-item interaction layer was set to 10. we used a learning rate of 0.002, a dropout
rate of 0.1, and a batch size of 128 throughout the training process.5.4 metrics
recommender systems are evaluated using both rating accuracy and ranking quality. offline
evaluation based on historical data is commonly used [ 1,23]. standard metrics include
root mean squared error (rmse) for prediction error, and normalized dis- counted
cumulative gain (ndcg), mean average precision (map), mean reciprocal rank (mrr), and
recall for ranking performance. to assess aspects beyond accuracy, novelty and serendipity
are also considered. below, we define each metric used in this study. rmse quantifies the
deviation between predicted and true rat- ings: rmse
=/√︂adicalt√︁/√︂adicalve√︂tex/√︂adicalbt 1 𝑁𝑁∑︁ 𝑖=1(ˆ𝑟𝑖−𝑟𝑖)2 (8) map combines ranking and
relevance: map =1 𝑁𝑁∑︁ 𝑖=1ap𝑖, ap𝑖=1 𝑚𝑖𝐾∑︁ 𝑘=1p@𝑘·rel𝑘 (9) recall@k is the proportion of
relevant items retrieved in the top- 𝐾 recommendations: recall@𝐾=|rel𝐾| |rel|. (10) mrr
measures how early the first relevant item appears in the ranked list: mrr =1 |𝑄||𝑄|∑︁
𝑖=11 rank𝑖, (11) where rank 𝑖is the position of the first relevant item for user 𝑖. ndcg
evaluates ranking quality by emphasizing higher-ranked relevant items: ndcg@𝐾=dcg@𝐾
idcg@𝐾, (12) dcg@𝐾=𝐾∑︁ 𝑖=1𝑟𝑖 log2(𝑖+1),idcg@𝐾=|𝑅𝐸𝐿|∑︁ 𝑖=11 log2(𝑖+1),(13) where,𝑟𝑖is the
binary relevance score, and |𝑅𝐸𝐿|is the number of relevant items up to rank 𝐾. novelty
measures how uncommon recommended items are, based on item popularity in the training
data. novelty@k =1 𝐾∑︁ 𝑖∈𝑅𝐾𝑢−log2𝑃(𝑖). (14) the final novelty score is the average across
all recommended items in the list. serendipity captures how surprisingly relevant items
are, relative to the user’s interaction history. it is based on the dissimilarity (1 minus
cosine similarity) between a recommended relevant item and the set of previously
interacted items: serendipity@ 𝐾=1 |rel𝐾|∑︁ 𝑖∈rel𝐾/√︁a√︂enleftig
1−cos(v𝑖,vhistory)/√︁a√︂en√︂ightig (15) where v𝑖is the embedding of item 𝑖, and vhistory
is the average embedding of items in the user’s history.23 webmedia’2025, rio de janeiro,
brazil ferreira et al. 5.5 methodology we conducted our experiments using a 5-fold
cross-validation pro- tocol to ensure robust results. additionally, we guarantee that
every user-item interaction is part of the test set in exactly one fold. for the graft, we
implemented an early-stopping mechanism based on the validation set’s rmse to prevent
overfitting, with training limited to a maximum of 30 epochs for each dataset. the final
reported metrics are the average of the test set results from the best-performing run of
each fold, where “best” is defined as the run that achieved the lowest validation rmse.
for fairness and reproducibility, we recorded the data partitioning and maintained
consistency across all baseline comparisons. additionally, to isolate the impact of model
architecture, we initialized graft, kann, and deepconn with identical review embedding
representations. we derived these features from the all-mpnet-base-v2 sentence trans-
former model. we kept these embeddings frozen during training to ensure a fair and direct
comparison of the models’ capabilities. to assess performance beyond observed
interactions, we applied ranking metrics over a recommendation list constructed for each
user. this list consisted of the ground-truth items, defined as those rated above 70%,
ratings greater than 7.0 for imdb, and 3.5 for ama- zon and rotten tomatoes, combined with
100 randomly sampled negative items. we drew these negative items from the global item
pool, excluding those the user had previously interacted with. this setup enables
evaluation of the model’s ability to distinguish rele- vant items from non-relevant ones
in a realistic recommendation scenario. 6 results and analysis this section presents the
results and analysis of graft, which we propose, as well as the baseline models, including
the rmse and ranking metrics. it encompasses an exploratory study of the results of the
topic extraction. additionally, we conduct a qualitative analysis that aims to explore
aspects beyond traditional metrics, with a focus on the quality of the rankings that we
recommend. 6.1 topics extraction we applied bertopic to extract latent topics from review
datasets, using contextualized embeddings and dimensionality reduction to cluster
semantically similar documents. we characterized each topic by its most representative
terms and associated reviews. to enhance topic quality, we conducted a qualitative
inspection of the extracted topics. we found that certain high-frequency but semantically
weak terms (e.g., “movie,” “series, ” “watching”) reduced the distinctiveness of the
topics. as a result, we refined the countvectorizer step by extending the stopword list to
exclude such domain-specific, non- informative words, leading to more coherent and
meaningful topic representations. we derived the extracted topics from frequent word
groupings and reflect recurring themes and sentiments across the reviews. through a
curated process of analysis, we observed that many top- ics capture narrative elements
such as “story line” and “character de- velopment, ” expressions of evaluation including
dissatisfaction (e.g., “bad quality”) or recommendation (e.g., “recommend,” “worth”), as
well as associations with specific genres and cultural references (e.g., “documentary,”
“downton abbey,” “star wars,” “pixar”).for the amazon dataset, topics revealed both
positive and nega- tive sentiment toward content and quality. topic 0 captures dissatis-
faction with plot and character development, while topic 1 centers on complaints about
poor quality and overall disappointment. top- ics 2 and 3 highlight user opinions about
comedic elements and characters. topics 4 and 5 focus on special effects, adaptations, and
mixed responses to storylines. topic 6 reflects positive opinions on documentaries and
informative material, whereas topics 7 and 8 emphasize entertaining storylines and
favorite selections. topic 9 highlights praise for the downton abbey series, and topic 10
high- lights references to science fiction franchises such as terminator andstar wars . in
the imdb dataset, topics are more genre-driven. topic 0 re- flects appreciation for
compelling storytelling. topics 1 and 2 cap- ture emotional connections with themes of
love, music, and super- hero characters, respectively. topics 3 and 4 represent an
interest in action-oriented content, with topic 4 specifically aligning with the style of
tarantino. topic 5 covers animated disney films, while topic 6 focuses on war narratives.
topic 7 reflects interest in horror, especially zombie-related content. topics 8 and 9
express general praise for well-told stories and fan-favorite franchises such as harry
potter andpirates of the caribbean . therotten tomatoes dataset presents a mix of
technical and emotional feedback. topic 0 discusses characters, plot, and the struc- ture
of action. topic 1 highlights directorial quality, performance, and soundtrack. topics 2
and 7 reflect entertainment value and comedic content, while topics 3 and 4 focus on
documentaries and strong acting performances. topic 5 is associated with horror and
thriller genres, and topic 6 revolves around romantic and comedic themes. topic 8 includes
family-friendly animated content, particu- larly disney-related films. topics 9 and 10
refer to sequels, remakes, and nostalgic action icons like james bond and clint eastwood.
lastly, topic 11 includes spanish-language reviews, some of which reference director
francis ford coppola. 6.2 recommendation models table 2 presents the performance
comparison across the baselines on the datasets, where the best results are in bold. the
proposed graft algorithm demonstrates competitive and stable perfor- mance, especially in
terms of rating prediction (rmse). on the amazon dataset, graft achieves the lowest rmse
(1.0413), indicating superior accuracy in rating prediction compared to svd (1.0525),
deepconn (1.0792), and kann (1.2297). however, svd outperforms graft in all ranking-based
metrics (ndcg@10, recall@10, mrr@10, and map@10), suggesting that traditional latent
factor models may still be more effective at producing top- ranked item lists under sparse
conditions. for the imdb dataset, graft again records the lowest rmse (2.0337),
demonstrating its robustness in rating prediction even under increased sparsity.
nonetheless, svd leads in all ranking metrics here as well. graft remains competitive in
mrr and map, demonstrating that while it may not produce the most relevant items as
effectively as svd, it consistently learns to rank moderately relevant items. on the
rotten tomatoes dataset, graft achieves the best rmse (0.7652), reaf- firming its strength
in accurate rating prediction. in contrast, svd again outperforms all models in ndcg@10,
recall@10, mrr@10,24 a gated review attention framework for topics in graph-based
recommenders webmedia’2025, rio de janeiro, brazil table 2: performance on amazon movies &
tv, reported as mean ±standard deviation (sd) over 5-fold cross-validation. algorithm
dataset rmse ndcg@10 recall@10 mrr@10 map@10 graft amazon movies and tv 1.0413±0.0312
0.0400±0.0014 0.0884±0.0019 0.0256±0.0012 0.0256±0.0012 svd amazon movies and tv 1.0525
±0.0315 0.0663±0.0056 0.1475±0.0115 0.0418±0.0038 0.0419±0.0038 deepconn amazon movies and
tv 1.0792 ±0.0317 0.0444±0.0174 0.0951±0.0353 0.0289±0.0119 0.0289±0.0119 kann amazon
movies and tv 1.2297 ±0.0338 0.0491±0.0028 0.1069±0.0057 0.0317±0.0020 0.0317±0.0020 graft
imdb 2.0337±0.0354 0.0606±0.0070 0.1189±0.0110 0.0377±0.0046 0.0383±0.0047 svd imdb 2.0451
±0.0391 0.0797±0.0031 0.1511±0.0054 0.0520±0.0023 0.0527±0.0024 deepconn imdb 2.0712
±0.0344 0.0405±0.0032 0.0844±0.0067 0.0235±0.0017 0.0239±0.0017 kann imdb 2.4935 ±0.0560
0.0447±0.0059 0.0908±0.0127 0.0272±0.0039 0.0276±0.0039 graft rotten tomatoes
0.7652±0.0084 0.0894±0.0041 0.2026±0.0074 0.0555±0.0039 0.0556±0.0039 svd rotten tomatoes
0.7770 ±0.0086 0.1457±0.0051 0.3017±0.0080 0.0980±0.0054 0.0981±0.0053 deepconn rotten
tomatoes 0.7789 ±0.0097 0.0295±0.0024 0.0645±0.0037 0.0190±0.0020 0.0190±0.0020 kann
rotten tomatoes 1.0161 ±0.0074 0.0478±0.0098 0.1022±0.0171 0.0311±0.0074 0.0312±0.0074 and
map@10. this consistent gap in ranking metrics suggests that graft’s current architecture
favors precision in rating regression over high-ranking item retrieval. paired t-tests
were conducted to evaluate the performance of the proposed graft model against the
strongest baseline, svd, using rmse and ranking-based metrics (ndcg@10, recall@10, mrr@10,
and map@10). results indicate that graft significantly outperformed svd in terms of rmse
across all datasets: amazon (𝑡(4)=−10.24,𝑝=0.0005 ),imdb (𝑡(4)=−3.14,𝑝=0.0349 ), and
rotten tomatoes (𝑡(4)=−3.78,𝑝=0.0194 ), confirming its advantage in rating prediction
accuracy. despite svd obtaining higher absolute scores on ranking metrics, graft
consistently showed statistically significant differences in all cases. for ndcg@10, graft
was significantly lower than svd on amazon (𝑡(4)=−11.88,𝑝=0.0003 ),imdb (𝑡(4)=−6.88,
𝑝=0.0023 ), and rotten tomatoes (𝑡(4)=−14.81,𝑝=0.0001 ). the same trend held for recall@10
( amazon :𝑡(4)=−12.30,𝑝=0.0003; imdb :𝑡(4)=−8.50,𝑝=0.0011;rotten tomatoes :𝑡(4)=−15.65,𝑝=
0.0001), mrr@10 ( amazon :𝑡(4)=−11.37,𝑝=0.0003;imdb :𝑡(4)= −6.83,𝑝=0.0024;rotten tomatoes
:𝑡(4)=−12.53,𝑝=0.0002), and map@10 ( amazon :𝑡(4)=−11.38,𝑝=0.0003;imdb :𝑡(4)=−6.82,
𝑝=0.0024;rotten tomatoes :𝑡(4)=−12.65,𝑝=0.0002). table 3 presents the novelty and
serendipity metrics for the graft, svd, deepconn, and kann models across the datasets.
graft demonstrates a consistently balanced performance, achiev- ing high novelty scores
(e.g., 15.03±0.03onamazon ) and moderate but stable serendipity, particularly excelling on
rotten tomatoes (0.1818±0.0073). this indicates that graft is capable of offering di-
verse recommendations while maintaining relevance and surprise, aligning well with user
interests. table 3 presents the novelty and serendipity metrics for the graft, svd,
deepconn, and kann models across the amazon , imdb , and rotten tomatoes datasets. graft
demonstrates a consis- tent and balanced behavior, achieving moderate novelty scores
(e.g., 15.03±0.03onamazon , which are slightly lower than other models) but notably higher
serendipity than deepconn and kann, espe- cially on rotten tomatoes (0.1818±0.0073). this
indicates graft’s strength in recommending items that are not necessarily the mosttable 3:
novelty and serendipity metrics (mean ±sd) for each model on the amazon, imdb, and rotten
tomatoes datasets, calculated over 5-fold cross-validation. model dataset novelty
serendipity graft amazon 15.0317 ±0.0335 0.0550±0.0009 svd amazon 14.9348 ±0.0157
0.1583±0.0091 deepconn amazon 15.5111±0.1929 0.0079±0.0069 kann amazon 15.4146 ±0.0175
0.0309±0.0111 graft imdb 9.9088 ±0.0238 0.0958±0.0086 svd imdb 10.0486 ±0.0095
0.1487±0.0040 deepconn imdb 10.0539 ±0.0520 0.0844±0.0068 kann imdb 10.5072±0.0014
0.0085±0.0037 graft rotten tomatoes 13.8079 ±0.0272 0.1818±0.0073 svd rotten tomatoes
13.6807 ±0.0153 0.2994±0.0126 deepconn rotten tomatoes 15.2170±0.0965 0.0645±0.0038 kann
rotten tomatoes 15.0869 ±0.0021 0.0195±0.0122 obscure but are still diverse and
contextually relevant, often result- ing in pleasant user surprise. svd stands out with
the highest serendipity values across all datasets, reaching 0.2988±0.0081 onrotten
tomatoes . still, it does so at the expense of novelty, especially on imdb , where its
novelty drops to 10.51±0.0026 . this suggests that svd favors more con- ventional or
popular items that may occasionally be unexpected but are less exploratory. deepconn, in
contrast, demonstrates the highest novelty values in most scenarios (e.g.,
15.51±0.19onamazon ) but suffers from extremely low serendipity on that same dataset (
0.0079±0.0069). this imbalance suggests that deepconn often recommends rare or
lesser-known items, but these may not effectively surprise or satisfy the user, indicating
weaker personalization. kann performs close to svd in novelty (e.g., 15.41±0.02onama-
zon). still, its serendipity is substantially lower across all datasets, particularly on
imdb (0.0085±0.0037) and rotten tomatoes (0.0195± 0.0122 ). this suggests that while kann
is capable of suggesting25 webmedia’2025, rio de janeiro, brazil ferreira et al.
012345678910 t op-10 items with similarity > 0.7020004000600080001000012000number of users
(a) amazon movies and tv 012345678910 t op-10 items with similarity >
0.7050010001500200025003000number of users (b) imdb 0 1 2 3 4 5 6 7 8 t op-10 items with
similarity > 0.70100200300400500number of users (c) rotten tomatoes figure 1: distribution
of high-similarity items (>0.7) in top-10 ranked recommendations across datasets. each
subplot shows the number of users who received a given count of high-similarity items in
their recommendation list. novel items, it struggles to make those recommendations
contextu- ally surprising or relevant to users. 6.3 discussion and the graft analysis
these results confirm that although graft does not achieve the best top-𝑘ranking metrics,
the differences with svd are statisti- cally significant. the consistent improvement in
rmse, paired with competitive performance in ranking metrics, underscores graft’s unique
capacity to capture nuanced user-item relationships through review-driven graph modeling,
even if those advantages do not directly translate into higher rank-based scores. overall,
graft demonstrates clear advantages in rating accuracy across all datasets. while it does
not surpass svd in ranking metrics, its strength lies in combining review-derived semantic
signals with structural graph information to more accurately estimate rating values. this
balance underscores the model’s effectiveness in learning user and item representations
from sparse, semantically rich data. nonetheless, this design centers on direct user–item
interactions and may underutilize richer, higher-order graph structures that contribute to
ranking efficacy. while the gated attention mecha- nism effectively integrates review
semantics to refine user and item representations, yielding superior accuracy in rating
prediction, it primarily operates within explicit user–item relations. this direct
modeling can limit the propagation of signals across the graph, thereby reducing the
model’s ability to infer transitive preferences, which are crucial for ranking tasks.
moreover, the fusion gate may attenuate weaker collaborative signals in favor of stronger
textual cues, which benefits regression objectives but can hinder relative ranking
performance. overall, the results highlight a trade-off be- tween semantic precision and
generalization in ranking, which is intrinsic to graft’s design. to complement the
quantitative evaluation of the recommenda- tion model, we implement a qualitative analysis
that aims to inter- pret the model’s decision-making process. by examining the align- ment
between predicted item rankings and ground-truth relevance, we strive to understand how
well the model captures meaningful relationships beyond conventional metrics. the analysis
evaluates the distribution and proportion of high-similarity recommenda- tions (>0.7)
within the top-10 ranked items across the datasets. the goal is to evaluate the model’s
ability to rank highly similar items within the recommendation list consistently.the
figure 1 presents a general histogram showing the similarity between the ground truth list
and the top-10 ranked recommenda- tion list for each dataset. in amazon, 54.21% of the
recommended items exhibit similarity above the threshold. moreover, 84.04% of users
receive at least three items above this threshold. the figure 1a reflects this
distribution, with a concentration of users receiving between 5 and 9 high-similarity
items. for imdb, surprisingly, the behavior is even more pronounced in contrast to the
general results from the models, where this dataset presents the most challeng- ing
ratings to predict. the overall proportion of high-similarity items reaches 90.31%, and
99.01% of users are served with three or more such items. figure 1b confirms this, showing
that most users receive between 8 and 10 high-similarity items. rotten tomatoes presents a
contrasting behavior. only 24.05% of the top-10 items exceed the similarity threshold, and
just 45.41% of users receive three or more despite the similarity proportions being
relatively balanced across the top-k positions (ranging from 21.96% to 25.45%). figure 1c
shows a marked decline in the number of users with more than 7 high-similarity items. the
absence of values for ranks 9 and 10 is not a visualization artifact, but rather reflects
that no users received 9 or more items with similarity above 0.7. nevertheless, the
corresponding proportions in top-9 and top-10 indicate that these ranks still contain
relevant items across users, although not concentrated within individual recommendation
lists. overall, the model demonstrates strong alignment in the imdb dataset, moderate
performance in amazon, and lower alignment in rotten tomatoes. these trends highlight the
variation in user-item similarity structure across datasets and emphasize the importance
of analyzing both visual and quantitative aspects when evaluating recommender system
behavior. 6.4 limitations and points of improvement this work presents certain limitations
that define the scope of the current proposal. first, the model does not account for
temporal aspects. all reviews are treated equally, regardless of when they were written,
even though more recent reviews often carry more weight in influencing user behavior and
item perception. second, like many text-based recommenders, graft relies on a sufficient
volume of explicit reviews to extract reliable topics and gating signals; in cold-start
scenarios, where new users or items have few or no reviews, its performance may degrade.
lastly, while the use of topic information allows for some level of semantic
abstraction,26 a gated review attention framework for topics in graph-based recommenders
webmedia’2025, rio de janeiro, brazil the model does not incorporate sentiment analysis in
the review processing pipeline. as a result, explicit emotional tone or polarity expressed
in the text is not directly captured or modeled. these aspects define the current
boundaries of the approach and indicate areas where the methodology could be strengthened.
7 conclusion and future remarks in this work, we proposed graft: a gated review attention
frame- work for topics in graph-based recommenders. our approach in- tegrates topic
representations extracted from user reviews into a graph attention architecture, enabling
more nuanced modeling of user preferences and item characteristics. by incorporating a
gating mechanism inspired by recurrent neural networks, the model learns to dynamically
control the influence of review-derived topics along- side traditional latent embeddings.
experimental results across multiple datasets demonstrate that graft consistently enhances
predictive performance and recommendation quality, particularly when textual context
contributes significantly to item differentia- tion. these findings reinforce our
hypothesis that incorporating semantic information from reviews enhances the model’s
ability to generate more expressive user and item representations. both quan- titative
results and similarity-based qualitative analysis confirm that the model retrieves
contextually coherent recommendations aligned with user preferences. despite these
promising results, several limitations point to fu- ture directions. first, temporal
aspects of reviews, such as recency and evolving user interests, were not considered,
although they may affect the weight or relevance of extracted topics. second, the model’s
attention and gating layers increase dimensionality and computational cost in proportion
to the number of attention heads and layers, raising concerns about scalability. efficient
neighbor sampling strategies and dimensionality reduction techniques could help mitigate
this. moreover, adapting the model for constrained or edge environments remains an open
challenge that necessitates further exploration. acknowledgments we want to thank the
coordenação de aperfeiçoamento de pessoal de nível superior (capes – brazil) for funding
this research under grant code 001. this research was also supported in part by the fapesb
incite pie0002/2022 grant and fapesb ppf0001/2021grant. references
    [14] [1]charu c. aggarwal. 2016. recommender systems: the textbook (1st ed.). springer
publishing company, incorporated.
    [15] [2]pablo castells and dietmar jannach. 2023. recommender systems: a primer.
arxiv:2302.02579 [cs.ir]
    [16] [3]chong chen, min zhang, yiqun liu, and shaoping ma. 2018. neural attentional rating
regression with review-level explanations. in proceedings of the 2018 world wide web
conference (lyon, france) (www ’18) . international world wide web conferences steering
committee, republic and canton of geneva, che, 1583–1592.
https://doi.org/10.1145/3178876.3186070
    [17] [4]li chen, guanliang chen, and feng wang. 2015. recommender systems based on user
reviews: the state of the art. user modeling and user-adapted interaction 25, 2 (june
2015), 99–154. https://doi.org/10.1007/s11257-015-9155-5
    [18] [5]tao chen, premaratne samaranayake, xiongying cen, meng qi, and yi-chen lan. 2022. the
impact of online reviews on consumers’ purchasing decisions: evidence from an eye-tracking
study. frontiers in psychology volume 13 - 2022 (2022).
https://doi.org/10.3389/fpsyg.2022.865702
    [19] [6]zhiyong cheng, ying ding, xiangnan he, lei zhu, xuemeng song, and mo- han kankanhalli.
2018. a3ncf: an adaptive aspect attention model for ratingprediction. in proceedings of
the 27th international joint conference on artificial intelligence (stockholm, sweden)
(ijcai’18) . aaai press, 3748–3754.
    [20] [7]kyunghyun cho, bart van merrienboer, caglar gulcehre, dzmitry bahdanau, fethi bougares,
holger schwenk, and yoshua bengio. 2014. learning phrase representations using rnn
encoder-decoder for statistical machine translation. arxiv:1406.1078 [cs.cl]
https://arxiv.org/abs/1406.1078
    [21] [8]shivangi gheewala, shuxiang xu, soonja yeom, and sumbal maqsood. 2024. ex- ploiting
deep transformer models in textual review based recommender systems. expert systems with
applications 235 (2024), 121120. https://doi.org/10.1016/j. eswa.2023.121120
    [22] [9]maarten grootendorst. 2022. bertopic: neural topic modeling with a class-based tf-idf
procedure. arxiv:2203.05794 [cs.cl] https://arxiv.org/abs/2203.05794
    [23] [10] xiangfu he, qiyao peng, minglai shao, and yueheng sun. 2024. diffusion review- based
recommendation. in knowledge science, engineering and management , cungeng cao, huajun
chen, liang zhao, junaid arshad, taufiq asyhari, and yonghao wang (eds.). springer nature
singapore, singapore, 255–269.
    [24] [11] nicolas hug. 2020. surprise: a python library for recommender systems. journal of
open source software 5, 52 (2020), 2174. https://doi.org/10.21105/joss.02174
    [25] [12] dietmar jannach, markus zanker, alexander felfernig, and gerhard friedrich. 2010.
recommender systems: an introduction (1st ed.). cambridge university press, usa.
    [26] [13] n. zafar ali khan and r. mahalakshmi. 2023. a novel user review-based contextual
recommender system. international journal of modeling, simula- tion, and scientific
computing 14, 01 (2023), 2341002. https://doi.org/10.1142/ s1793962323410027
arxiv:https://doi.org/10.1142/s1793962323410027
    [27] [14] zheng li, di jin, and ke yuan. 2023. attentional factorization machine with
review-based user–item interaction for recommendation. scientific reports 13, 1 (2023),
1–17. https://doi.org/10.1038/s41598-023-40633-4
    [28] [15] yun liu and jun miyazaki. 2022. knowledge-aware attentional neural network for
review-based movie recommendation with explanations. neural comput. appl. 35, 3 (sep
2022), 2717–2735. https://doi.org/10.1007/s00521-022-07689-1
    [29] [16] cataldo musto, marco de gemmis, giovanni semeraro, and pasquale lops. 2017. a
multi-criteria recommender system exploiting aspect-based sentiment analysis of users’
reviews. in proceedings of the eleventh acm conference on recommender systems (como,
italy) (recsys ’17) . association for computing machinery, new york, ny, usa, 321–325.
https://doi.org/10.1145/3109859.3109905
    [30] [17] pedro pires, bruno rizzi, and tiago almeida. 2024. why ignore content? a guideline
for intrinsic evaluation of item embeddings for collaborative filtering. inproceedings of
the 30th brazilian symposium on multimedia and the web (juiz de fora/mg). sbc, porto
alegre, rs, brasil, 345–354. https://doi.org/10.5753/ webmedia.2024.243199
    [31] [18] shaina raza and chen ding. 2022. news recommender system: a review of recent
progress, challenges, and opportunities. artif. intell. rev. 55, 1 (jan. 2022), 749–800.
https://doi.org/10.1007/s10462-021-10043-x
    [32] [19] fu shang, jiatu shi, yadong shi, and shuwen zhou. 2024. enhancing e-commerce
recommendation systems with deep learning-based sentiment analysis of user reviews.
international journal of engineering and management research 14, 4 (aug 2024).
https://doi.org/10.5281/zenodo.13221409
    [33] [20] petar veličković, arantxa casanova, pietro liò, guillem cucurull, adriana romero, and
yoshua bengio. 2018. graph attention networks. 6th international conference on learning
representations, iclr 2018 - conference track proceedings (2018), 1–12.
https://doi.org/10.1007/978-3-031-01587-8_7 arxiv:1710.10903
    [34] [21] qiang wang, wen zhang, jian li, feng mai, and zhenzhong ma. 2022. effect of online
review sentiment on product sales: the moderating role of review credibility perception.
computers in human behavior 133 (2022), 107272. https: //doi.org/10.1016/j.chb.2022.107272
    [35] [22] shuang yang and xuesong cai. 2023. an enhanced recommendation model based on review
text graph and interaction graph. ieee access 11 (2023), 88234–88244.
https://doi.org/10.1109/access.2023.3305954
    [36] [23] eva zangerle and christine bauer. 2022. evaluating recommender systems: survey and
framework. acm comput. surv. 55, 8, article 170 (dec. 2022), 38 pages.
https://doi.org/10.1145/3556536
    [37] [24] andré zanon, leonardo rocha, and marcelo manzato. 2024. o impacto de estratégias de
embeddings de grafos na explicabilidade de sistemas de re- comendação. in proceedings of
the 30th brazilian symposium on multimedia and the web (juiz de fora/mg). sbc, porto
alegre, rs, brasil, 231–239. https: //doi.org/10.5753/webmedia.2024.241857
    [38] [25] lei zheng, vahid noroozi, and philip s. yu. 2017. joint deep modeling of users and
items using reviews for recommendation. in proceedings of the tenth acm international
conference on web search and data mining (cambridge, united kingdom) (wsdm ’17) .
association for computing machinery, new york, ny, usa, 425–434.
https://doi.org/10.1145/3018661.3018665
    [39] [26] yuanyuan zhuang and jaekyeong kim. 2021. a bert-based multi-criteria recommender
system for hotel promotion management. sustainability 13, 14 (2021).
https://doi.org/10.3390/su1314803927

3. PARÁGRAFOS RELEVANTES (TOP-1):
  > OBJETIVO:
    Não encontrado.
  > PALAVRAS-CHAVES:
    Não encontrado.
  > PROBLEMA:
    Não encontrado.
  > CONTRIBUIÇÃO:
    Score: 4.001
        a gated review attention framework for topics in graph-based recommenders eduardo ferreira da silva∗ eduardoferreira@ufba.br
        instituto de computação, ufba salvador, bahiajoel pires joelpires@ufba.br instituto de computação, ufba salvador, bahiadenis
        robson dantas boaventura denis.boaventura@ufba.br instituto de computação, ufba salvador, bahia mayki dos santos oliveira
        maykioliveira@ufba.br instituto de computação, ufba salvador, bahiafrederico araujo durão fdurao@ufba.br instituto de computação,
        ufba salvador, bahia abstract recommender systems significantly reduce information overload by curating personalized content on
        digital platforms, thereby en- hancing user experience. traditional models often rely on sparse rating data, overlooking the rich
        semantic signals embedded in user reviews. to address this, we propose the gated review attention framework for topics, a novel
        graph-based recommender system that integrates review-derived topic information with user-item interactions. our approach
        leverages bertopic to extract inter- pretable semantic topics from textual reviews and then embeds them into a graph attention
        network architecture. a gating mecha- nism dynamically regulates the influence of these topic representa- tions relative to latent
        user and item embeddings, enabling adaptive feature fusion. we evaluate graft on three benchmark datasets: amazon movies and tv,
        imdb, and rotten tomatoes. comparing it against classical and neural baselines, including svd, deepconn, and kann. experimental
        results demonstrate that graft con- sistently achieves the lowest rmse across all datasets, indicating superior rating prediction
        accuracy. although traditional models perform better on ranking metrics, graft achieves superior ac- curacy (lower rmse), and our
        qualitative analysis demonstrates more substantial semantic alignment. keywords collaborative filtering, review-based
        recommendations, topic-extraction recommendation. 1 introduction recommender systems have emerged as a robust solution to address
        the exponential growth of products, services, and online informa- tion, acting as information filters. these systems provide
        personal- ized recommendations to users based on their preferences, needs, and past behaviors [ 2]. jannach et al . [12] defines
        recommender system (rs) as automated software tools that leverage machine ∗both authors contributed equally to this research. in:
        proceedings of the brazilian symposium on multimedia and the web (webme- dia’2025). rio de janeiro, brazil. porto alegre:
        brazilian computer society, 2025. ©2025 sbc – brazilian computing society. issn 2966-2753learning and statistical models to
        suggest items, such as products, movies, books, or music, tailored to individual user preferences. these systems have become
        pervasive in modern digital experi- ences, driving key functions across e-commerce, entertainment, and social media. by offering
        personalized suggestions, they en- hance user satisfaction, reduce decision-making effort, and generate substantial business value
        through increased engagement and sales. additionally, pires et al . [17] , raza and ding [18] emphasizes the importance of rs due
        to their ability to deliver relevant and person- alized content. while practical algorithms are essential, the core challenge
        involves accurately understanding and modeling user preferences [ 24]. rs must identify complex relationships within data,
        uncovering patterns and connections that are often not imme- diately apparent. in this context, online reviews can enhance this
        process by offering rich, user-generated data that captures nuanced experiences and preferences. these reviews help describe the
        com- plex interactions between users and items, providing contextual signals that go beyond structured data such as ratings or
        clicks. online reviews, which users generate based on their personal ex- periences, have become a central channel for sharing
        opinions in digital environments. unlike traditional advertising, users often perceive these reviews as more authentic and
        persuasive, which can influence their decisions. favorable evaluations can boost con- fidence, while negative reviews usually
        deter potential interactions [5, 14, 21]. beyond their credibility, reviews shape consumer behavior through emotional and social
        dynamics. the sentiments that consumers express can create emotional connections that reinforce user en- gagement. star ratings
        and consensus opinions serve as social proof, guiding consumers to align with the majority view. this influence arises from a
        desire for accurate information and social belonging. consumers may follow group opinions to gain approval or avoid criticism,
        even when the choice is not the optimal one. moreover, reviews serve as a feedback mechanism for businesses, helping identify
        strengths and areas for improvement, and fostering loyalty through user engagement [5, 21]. user reviews offer nuanced opinions
        beyond simple numerical ratings, enabling rs to build more detailed user and item profiles [4]. although this data is
        unstructured, advancements in natural language processing (nlp) facilitate the extraction of key informa- tion, such as topics and
        sentiments, a strategy proven to improve19 webmedia’2025, rio de janeiro, brazil ferreira et al. recommendation models [ 8]. in
        this context, the integration of tex- tual insights into rs directly addresses fundamental challenges. rich review content helps
        mitigate data sparsity and cold-start problems by uncovering user preferences even when explicit rat- ings are missing [ 26].
        moreover, by anchoring recommendations in detailed user feedback, the resulting models offer greater trans- parency and
        interpretability [ 13]. we hypothesize that integrating semantic information from reviews into the user-item graph can help the
        model learn more expressive representations for both users and items. to explore this, we propose the gated review attention
        frame- work for topics (graft), a graph-based recommender that incorpo- rates topic extraction from user reviews to enrich these
        interactions. graft models user-item relationships as a bipartite graph, where nodes represent users and items, and edges reflect
        their interactions. we integrate topic-based representations of reviews as additional signals into this structure. we apply a
        gated attention mechanism to balance the contribution of review-based information with user and item embeddings, allowing the
        model to select the most informative features adaptively. this approach enhances the representation of complex user-item
        relationships by combining collaborative signals with content derived from reviews. our work highlights several key differences
        from existing liter- ature. firstly, the reviews undergo pre-processing in a prior task. this approach enables a detailed analysis
        of each dataset and fa- cilitates the search for the optimal configuration, allowing for an examination of potential human
        understanding. secondly, we pro- posed a double attention-gated mechanism that provides two levels of decision-making regarding
        the selection of embeddings or the distribution of topics in the training process. the model operates at the node level,
        considering the internal relationships within the graph, and at the structural level, where we assign each node a greater weight
        to adjust the overall weights more effectively. the main contributions of this work are as follows. (1)we introduce a method to
        incorporate topic-based represen- tations of user reviews into a recommendation model, utiliz- ing a gated attention mechanism to
        balance the contributions of textual content and user-item embeddings dynamically. (2)we present an analysis that examines the
        alignment between review-based topics in the ground-truth list and those in the generated recommendations, offering a qualitative
        perspec- tive on the semantic consistency of the recommendations. this paper is structured as follows. section 2 presents the
        related works. section 3 introduces the background and supporting tech- niques. section 4 presents the proposed graft framework,
        de- tailing its architecture and integration of review topics into the recommendation process. section 5 describes the
        experimental setup, including datasets, baselines, and evaluation metrics. sec- tion 6 provides an in-depth analysis of graft’s
        recommendation behavior, with emphasis on the composition of the ranked lists. finally, section 7 concludes the paper and outlines
        directions for future work. 2 related works several early models utilized review texts to address data sparsity and enrich
        user-item representations. deepconn [ 25] introducedparallel cnn-based networks for users and items to share a layer for rating
        estimation. it treated reviews as rich user feedback; how- ever, cnn’s inability to model long-range dependencies limited its
        effectiveness. similarly, narre [ 3] utilized cnns for text encoding and incorporated an attention mechanism to weight informative
        reviews, thereby enhancing prediction and explainability. however, neither model incorporated structured semantic representations
        nor handled variations in review quality over time. other models incorporated topic or aspect-based representa- tions to model
        fine-grained preferences. musto et al . [16] extracted entities and sentiment scores from reviews to construct multi- dimensional
        user profiles, which we then used in a multi-criteria col- laborative filtering setting. cheng et al . [6] proposed 3ncf, which
        also focused on capturing aspect-level signals, employing a topic- guided attention mechanism to align user interests with item
        charac- teristics. these approaches emphasized matching user preferences with interpretable features derived from text but did not
        leverage graph-based relational structures. more recent models have combined deep language representa- tions and attention
        mechanisms to capture contextual information more effectively. li et al . [14] used bigru and attention refine roberta embeddings
        to emphasize salient review segments, inte- grating them into an attentional factorization machine (afm) to capture nuanced
        user-item interactions while reducing the impact of noise. a separate line of work explores graph-based methods that integrate
        review information with user-item interaction structures. yang and cai [22] presented erri, which models both semantic relations
        between review words through a review text graph and collaborative signals through a user-item interaction graph. we fuse these
        two sources to inform rating predictions. he et al . [10] introduced rdrec, a diffusion-based approach that simulates user
        interest evolution by corrupting and reconstructing review-based features using a transformer. shang et al . [19] further explored
        sentiment-aware representations by applying hierarchical atten- tion to review texts, capturing emotional nuance and integrating
        it into a neural collaborative filtering model. graft differs from these works by unifying topic modeling and graph attention in a
        gated framework. rather than relying solely on word- or review-level attention, graft encodes topical informa- tion as part of
        node features. it employs graph attention layers with gating mechanisms that regulate the propagation of semantic and relational
        signals throughout the network. this design enables more interpretable and adaptive representation learning, particularly in cases
        where interaction patterns are sparse or heterogeneous. 3 background this work integrates three complementary techniques to
        enhance recommendation performance based on graph and textual data. we employ bertopic [ 9] to extract high-level semantic
        information from user reviews by combining transformer-based embeddings with clustering techniques. this method enables the
        identification of coherent topics across reviews, which we can integrate into the model to enhance interpretability and user
        preference modeling. second, graph attention networks (gat) [ 20] provide a powerful mechanism for learning on graph-structured
        data. lastly, inspired by gated units in recurrent neural networks [ 7], we incorporate a20 a gated review attention framework for
        topics in graph-based recommenders webmedia’2025, rio de janeiro, brazil gating mechanism that regulates the contribution of
        distinct infor- mation sources, such as user/item embeddings and topic features. 3.1 topic modeling with bertopic bertopic is a
        neural topic modeling technique that leverages transformer- based embeddings and clustering to extract coherent topics from
        textual data. it begins by encoding documents using pre-trained lan- guage models, preserving semantic relationships in a
        high-dimensional vector space. we then project these embeddings into a lower-dimensional space and group them into semantically
        consistent clusters with a non-supervised algorithm. to construct interpretable topics from these clusters, bertopic employs a
        class-based variant of term frequency-inverse document frequency (tf-idf), which identifies words most representative of each
        cluster. this pipeline enables the discovery of latent themes in reviews, which we integrate into the recommendation framework as
        interpretable and context-rich signals [9]. 3.2 graph attention networks veličković et al . [20] proposed graph attention networks
        (gat), which are a neural architecture that operates on graph-structured data, allowing nodes to attend to their neighbors during
        represen- tation learning dynamically. unlike traditional graph convolutional networks, which uniformly aggregate information from
        neighbors, gat employs a self-attention mechanism to assign distinct impor- tance weights to each neighbor, thereby making the
        aggregation process more expressive and adaptive. this is particularly suitable for recommendation tasks, as it naturally captures
        the collaborative filtering principle by prioritizing informative neighbor interactions during the learning process. by leveraging
        multi-head attention, gat not only enhances model capacity and robustness but also retains interpretability through the learned
        attention weights. 3.3 gated units and feature control inspired by cho et al . [7] gated mechanisms in recurrent neural networks
        (rnns), such as the gated recurrent unit (gru), we in- corporate a gating strategy to regulate the contribution of distinct data
        sources in our model. in rnns, gates control how much past information should be retained or forgotten when computing the next
        hidden state. drawing from this intuition, our model adapts a similar mechanism to balance between user/item embeddings and
        topical features derived from textual reviews. the gate outputs a continuous value that determines the extent to which each rep-
        resentation, semantic or structural, contributes to the final fused representation, thus enabling a more flexible and
        context-aware integration during training. 4 proposal 4.1 topic extraction from reviews the first step of topic extraction was the
        pre-processing and clean- ing phase. the approach adopted preserves the full set of reviews, removing only non-informative
        elements such as html tags, ex- cessive punctuation, and dataset-specific textual artifacts. for ex- ample, in the amazon movies
        and tv dataset, item descriptions embedded within some reviews were removed. emojis and shortreviews were retained to preserve the
        original characteristics of the data. in sequence, we use bertopic to generate topics by utilizing transformer-based models to
        convert each document into a dense vector, thereby placing similar documents closer together in a high- dimensional space. we
        generate the embedding representation from the sentence transformers library all-mpnet-base-v21addition- ally, to enable
        clustering of high-dimensional embeddings, we apply dimensionality reduction using uniform manifold approximation and projection
        (umap). the model is configured through hyper- parameters, including the number of components, distance metric, number of
        neighbors, and minimum distance. after reduction, the k-means clustering algorithm is used to identify clusters. this is
        particularly important, as not all documents are associated with a well-defined topic. the topic representation chosen in bertopic
        utilizes the main keywords associated with each topic. for topic labeling, we used the keybert-inspired representation model. this
        model selects representative terms for each topic by aligning them with the em- bedded documents in each cluster. domain-specific
        stopwords (e.g., “movie,” “film,” “dvd,” “disc”) were also removed to eliminate terms with low discriminative value. additionally,
        the number of features was defined, and n-gram representations (unigrams, bigrams, and trigrams) were included to enhance the
        expressiveness and clarity of the extracted topics. the overall bertopic pipeline involved: (1) embedding reviews. (2) reducing
        embedding dimensions. (3) identifying topics with the clusterization method. (4) representing topics using keybert-derived
        keywords. (5)using a custom stopword list to remove domain-irrelevant terms and trigrams for richer features. 4.2 gated review
        attention framework for topics (graft) to integrate topics derived from reviews into a graph-based collabo- rative filtering
        architecture, graft2employs a graph neural archi- tecture that jointly leverages rating interactions and review topics through
        gated fusion mechanisms and attention-based message passing. this analysis revisits our initial hypothesis that incorporat- ing
        semantic information from reviews into the user-item graph can enhance the expressiveness of learned representations and improve
        the quality of recommendations. to implement this, the model be- gins by assigning each user 𝑢and item𝑖a learnable embedding
        vector e𝑢,e𝑖∈r𝑑, where𝑑is the base embedding dimension. we then project these initial representations into a structural space of
        size𝑑′to align with the multi-head attention mechanism, as defined by: ℎ𝑢=𝑅𝑒𝐿𝑈(𝑊𝑝𝑟𝑜𝑗.𝑒𝑢), ℎ𝑖=𝑅𝑒𝐿𝑈(𝑊𝑝𝑟𝑜𝑗.𝑒𝑖),(1) where
        theℎ𝑢andℎ𝑖are the projected embeddings of the user and items, after applying a linear transformation by a relu activation,
        and𝑊𝑝𝑟𝑜𝑗∈r𝑑′×𝑑is the projection matrix used to transform the initial embeddings in the structural space used in graph attention
        network (gat) layers. 1available in: https://huggingface.co/sentence-transformers/all-mpnet-base-v2 2available at:
        https://github.com/ferreira-eduardo/graft.git21 webmedia’2025, rio de janeiro, brazil ferreira et al. the model interactions are
        the multiple layers of the gatv2conv operator. each layer propagates and aggregates neighbor informa- tion using edge features as
        attention biases, ℎ′ 𝑣=gatv2conv(ℎ𝑣,ℎn(𝑣),𝑒𝑢𝑣), (2) where𝑒𝑢𝑣∈r𝑘is the topic distribution and 𝑘the dimensionality, on the edge from
        node 𝑢to node𝑣. additionally, to define the gated mechanism, a transformation is applied to a vector of representation e𝑢, which
        represents a user embedding within the model’s context. to control the flow of semantic information, the model employs a learned
        gating mechanism that regulates how much of each trans- formed embedding dimension is retained. the gate vector for user 𝑢is
        defined as: g𝑢=𝜎/√︁a√︂enleftbigw𝑢 𝑔e𝑢+b𝑢 𝑔/√︁a√︂en√︂ightbig∈ [0,1]𝑘, (3) where𝜎(·)is the element-wise sigmoid function, w𝑢𝑔∈r𝑘×𝑑is
        a learned projection matrix, and b𝑢𝑔is the corresponding bias. the dimensionality 𝑘corresponds to the topic space. in parallel, a
        linear transformation is applied to map the original user embedding into the same topic-aligned space: ˜e𝑢=w𝑢 𝑝e𝑢+b𝑢 𝑝∈r𝑘, (4)
        where w𝑢𝑝∈r𝑘×𝑑and b𝑢𝑝are also learnable parameters. this transformed embedding ˜e𝑢is then modulated by the gate g𝑢, which
        selectively filters or amplifies individual components of the repre- sentation. this gated linear unit allows the model to
        dynamically control feature fusion, learning which aspects of the semantic trans- formation are most relevant for each user. on
        the structural level, it involves blending two representations of a user or an item. we define a gated fusion mechanism that
        combines a topic-based vector t𝑥and a transformed embedding ˜e𝑥, modulated by a learned gate vector g𝑥. the fusion is given by
        ˆt𝑢=g𝑢⊙t𝑢+/√︁a√︂enleftbig1−g𝑢/√︁a√︂en√︂ightbig⊙˜e𝑢, (5) where⊙denotes element-wise product. this operation performs a
        dimension-wise blend between semantic and structural features. for each dimension 𝑗, the fusion can be expressed as
        ˆ𝑡𝑥,𝑗=𝑔𝑥,𝑗𝑡𝑥,𝑗+(1−𝑔𝑥,𝑗)˜𝑒𝑥,𝑗, (6) where𝑔𝑥,𝑗∈ [0,1]controls the relative influence of the topic and structural components. when
        𝑔𝑥,𝑗≈1, the model prioritizes the topic signal, whereas when 𝑔𝑥,𝑗≈0, it favors the projected embedding. this formulation enables
        adaptive feature integration, allowing the model to learn per-dimension preferences for each node type. finally, the model
        produces a prediction by combining the gated structural and topic-aware representations of the user and item. let ˆt𝑢andˆt𝑖denote
        the fused representations obtained after the final gating step. these vectors are concatenated and passed through a fully
        connected layer: x=fc/b√︂acketleftbig e𝑢∥a𝑢∥ˆt𝑢∥e𝑖∥a𝑖∥ˆt𝑖/b√︂acket√︂ightbig , (7) where a𝑢,a𝑖are the outputs of the attention
        fusion submodules and∥denotes concatenation. this attention-gated fusion enables the model to learn when to trust latent
        embeddings versus topical signals on a per-dimension basis. the concatenated vector xis passed through a fully connected layer
        with dropout, followed by a scaled activation to constrain the output to the rating range thatdefines the width of the rating
        scale. the final output is a scalar prediction of the user’s rating for the item. 5 experimental setup 5.1 datasets we select
        three distinct datasets: amazon movies and tv3, imdb4, and rotten tomatoes5. these sources offer a comprehensive view by
        integrating user-generated reviews with audience ratings and metadata across diverse platforms. table 1 presents key statistics
        for each dataset before and after preprocessing. we began by removing invalid or incomplete entries from all datasets to ensure
        data quality. as a general criterion, we selected users with at least 10 interactions to focus on active profiles and reduce
        sparsity. we then further processed each dataset according to its specific characteristics. due to its large scale, the amazon
        dataset required additional filtering: we also retained only items with at least 100 interactions to ensure meaningful
        representation. the rotten tomatoes dataset posed a unique challenge, as it in- cludes non-numeric rating formats such as “a”,
        “b”, “f”, and “a-”. to ensure consistency and comparability, we retained only entries with normalized fractional or numeric
        ratings (e.g., 1/5, 2/4, 10/10), aligning all scores to a standard 1–5 scale. notably, the imdb dataset experienced a substantial
        reduction in size after filtering, reflecting its initially sparse distribution of user-item interactions. table 1: impact of
        preprocessing, removal of incomplete en- tries, retention of users with ≥interactions (and items with ≥100 interactions for
        amazon), and rating normalization for rotten tomatoes, on dataset size (reviews, users, items), reviews per user/item, and overall
        sparsity across the ama- zon movies & tv, imdb, and rotten tomatoes datasets. amazon movies and tv imdb rotten tomatoes metric raw
        processed raw processed raw processed reviews 17.3m 1.4m 932.4k 264.9k 1.1m 543.5k users 6.5m 76k 427k 7k 11k 2.6k items 747.7k
        27.3k 1.1k 1.1k 17.7k 17.4k reviews/user 2.664 19.12 3.28 37.07 100.06 208.17 reviews/item 23.173 53.18 12.28 230.40 63.77 31.13
        sparsity 99.99% 99.93% 99.81% 96.77% 99.42% 98.80% 5.2 baselines for comparison, we evaluate our approach against three baseline
        algorithms: singular value decomposition (svd)6, deepconn [ 25], and kann [ 15]. svd is a classical and widely adopted
        collaborative filtering technique that factorizes the user-item interaction matrix into lower-dimensional latent spaces. by
        capturing hidden patterns in user preferences and item characteristics, svd has demonstrated strong performance in various
        recommendation scenarios. deep- conn enhances collaborative filtering by incorporating textual reviews from both users and items.
        it employs two parallel convolu- tional neural networks to learn user and item representations from 3available at:
        https://amazon-reviews-2023.github.io/ 4available at: https://ieee-dataport.org/open-access/imdb-movie-reviews-dataset 5available
        at: https://www.kaggle.com/datasets/stefanoleone992/rotten-tomatoes- movies-and-critic-reviews-dataset 6available in:
        https://surprise.readthedocs.io/en/stable/matrix_factorization.html22 a gated review attention framework for topics in graph-based
        recommenders webmedia’2025, rio de janeiro, brazil review text, thereby improving rating prediction. kann builds upon this concept
        by integrating review content with external knowledge through a knowledge-aware attention mechanism. this enables the model to
        generate more accurate recommendations while also providing interpretable explanations. 5.3 hyperparameter tuning for graft, we
        adopted an empirical approach to select hyper- parameters, concentrating on those that significantly influenced model performance.
        initially, we conducted randomized sampling over the following search space: embedding dimensions 32, 64, 128; number of layers 2,
        3, 4; number of attention heads 2, 4, 8; leaky relu negative slope ( 𝛼) 0.2, 0.3, 0.4, 0.5; dropout rates 0.2, 0.3, 0.4, 0.5; and
        learning rates 0.1, 0.001, 0.0001. from this search, we iden- tified the best-performing hyperparameter configuration for each
        dataset. for the imdb dataset, the optimal model parameters in- cluded an embedding dimension of 128, two layers, four attention
        heads,𝛼=0.2, a learning rate of 0.001, and a dropout rate of 0.2. for the amazon dataset, the ideal configuration featured an em-
        bedding dimension of 32, two layers, four attention heads, 𝛼=0.4, a learning rate of 0.001, and a dropout rate of 0.5. the best
        setup for rotten tomatoes was identical to that of imdb, with an embed- ding dimension of 128, two layers, four attention heads,
        𝛼=0.2, a learning rate of 0.001, and a dropout rate of 0.2. all configurations utilized concat=false . for the baseline methods,
        kann [ 15], we followed the hyper- parameter configurations suggested in their original papers. the model weights were optimized
        using the adam optimizer with 𝛽1=0.9,𝛽2=0.98, and𝜖=1.0×10−9. the learning rate was set as 0.0001, and the batch size was fixed at
        128. both the knowledge embedding and latent embedding dimensions were set to 50, result- ing in a total dimension 𝑑=100after
        concatenating the context entity with the entity itself. all hidden layers were configured with a size of 1024, and the number of
        attention spaces 𝐻was set to 4. to manage input length, we retained the portion of reviews that covered 90% of users and items in
        terms of length, and 80% in terms of quantity. for the svd, we utilized the implementation provided by the surprise library [ 11]
        and conducted a grid search to determine the optimal hyperparameter configuration. the search space included the number of latent
        factors {32, 64, 128, 256}, number of training epochs {20, 30, 40}, learning rate {0.01, 0.001, 0.005, 0.0001}, and regularization
        term {0.5, 0.05}. we used the biased svd variant and selected the best configuration based on validation rmse. the final model was
        trained with svd(n_factors=256, n_epochs=20, biased=true, lr_all=0.005, reg_all=0.05) . for the deepconn [ 25], we adopted the
        hyperparameter config- uration described in the original paper. the length of each review document was fixed at 1000 tokens. word
        embeddings were ini- tialized with a dimension of 64. the convolutional layer contained 100 neurons with a kernel window size of
        3. the latent dimension for the final user-item interaction layer was set to 10. we used a learning rate of 0.002, a dropout rate
        of 0.1, and a batch size of 128 throughout the training process.5.4 metrics recommender systems are evaluated using both rating
        accuracy and ranking quality. offline evaluation based on historical data is commonly used [ 1,23]. standard metrics include root
        mean squared error (rmse) for prediction error, and normalized dis- counted cumulative gain (ndcg), mean average precision (map),
        mean reciprocal rank (mrr), and recall for ranking performance. to assess aspects beyond accuracy, novelty and serendipity are
        also considered. below, we define each metric used in this study. rmse quantifies the deviation between predicted and true rat-
        ings: rmse =/√︂adicalt√︁/√︂adicalve√︂tex/√︂adicalbt 1 𝑁𝑁∑︁ 𝑖=1(ˆ𝑟𝑖−𝑟𝑖)2 (8) map combines ranking and relevance: map =1 𝑁𝑁∑︁
        𝑖=1ap𝑖, ap𝑖=1 𝑚𝑖𝐾∑︁ 𝑘=1p@𝑘·rel𝑘 (9) recall@k is the proportion of relevant items retrieved in the top- 𝐾 recommendations:
        recall@𝐾=|rel𝐾| |rel|. (10) mrr measures how early the first relevant item appears in the ranked list: mrr =1 |𝑄||𝑄|∑︁ 𝑖=11 rank𝑖,
        (11) where rank 𝑖is the position of the first relevant item for user 𝑖. ndcg evaluates ranking quality by emphasizing
        higher-ranked relevant items: ndcg@𝐾=dcg@𝐾 idcg@𝐾, (12) dcg@𝐾=𝐾∑︁ 𝑖=1𝑟𝑖 log2(𝑖+1),idcg@𝐾=|𝑅𝐸𝐿|∑︁ 𝑖=11 log2(𝑖+1),(13) where,𝑟𝑖is
        the binary relevance score, and |𝑅𝐸𝐿|is the number of relevant items up to rank 𝐾. novelty measures how uncommon recommended items
        are, based on item popularity in the training data. novelty@k =1 𝐾∑︁ 𝑖∈𝑅𝐾𝑢−log2𝑃(𝑖). (14) the final novelty score is the average
        across all recommended items in the list. serendipity captures how surprisingly relevant items are, relative to the user’s
        interaction history. it is based on the dissimilarity (1 minus cosine similarity) between a recommended relevant item and the set
        of previously interacted items: serendipity@ 𝐾=1 |rel𝐾|∑︁ 𝑖∈rel𝐾/√︁a√︂enleftig 1−cos(v𝑖,vhistory)/√︁a√︂en√︂ightig (15) where
        v𝑖is the embedding of item 𝑖, and vhistory is the average embedding of items in the user’s history.23 webmedia’2025, rio de
        janeiro, brazil ferreira et al. 5.5 methodology we conducted our experiments using a 5-fold cross-validation pro- tocol to ensure
        robust results. additionally, we guarantee that every user-item interaction is part of the test set in exactly one fold. for the
        graft, we implemented an early-stopping mechanism based on the validation set’s rmse to prevent overfitting, with training limited
        to a maximum of 30 epochs for each dataset. the final reported metrics are the average of the test set results from the
        best-performing run of each fold, where “best” is defined as the run that achieved the lowest validation rmse. for fairness and
        reproducibility, we recorded the data partitioning and maintained consistency across all baseline comparisons. additionally, to
        isolate the impact of model architecture, we initialized graft, kann, and deepconn with identical review embedding
        representations. we derived these features from the all-mpnet-base-v2 sentence trans- former model. we kept these embeddings
        frozen during training to ensure a fair and direct comparison of the models’ capabilities. to assess performance beyond observed
        interactions, we applied ranking metrics over a recommendation list constructed for each user. this list consisted of the
        ground-truth items, defined as those rated above 70%, ratings greater than 7.0 for imdb, and 3.5 for ama- zon and rotten tomatoes,
        combined with 100 randomly sampled negative items. we drew these negative items from the global item pool, excluding those the
        user had previously interacted with. this setup enables evaluation of the model’s ability to distinguish rele- vant items from
        non-relevant ones in a realistic recommendation scenario. 6 results and analysis this section presents the results and analysis of
        graft, which we propose, as well as the baseline models, including the rmse and ranking metrics. it encompasses an exploratory
        study of the results of the topic extraction. additionally, we conduct a qualitative analysis that aims to explore aspects beyond
        traditional metrics, with a focus on the quality of the rankings that we recommend. 6.1 topics extraction we applied bertopic to
        extract latent topics from review datasets, using contextualized embeddings and dimensionality reduction to cluster semantically
        similar documents. we characterized each topic by its most representative terms and associated reviews. to enhance topic quality,
        we conducted a qualitative inspection of the extracted topics. we found that certain high-frequency but semantically weak terms
        (e.g., “movie,” “series, ” “watching”) reduced the distinctiveness of the topics. as a result, we refined the countvectorizer step
        by extending the stopword list to exclude such domain-specific, non- informative words, leading to more coherent and meaningful
        topic representations. we derived the extracted topics from frequent word groupings and reflect recurring themes and sentiments
        across the reviews. through a curated process of analysis, we observed that many top- ics capture narrative elements such as
        “story line” and “character de- velopment, ” expressions of evaluation including dissatisfaction (e.g., “bad quality”) or
        recommendation (e.g., “recommend,” “worth”), as well as associations with specific genres and cultural references (e.g.,
        “documentary,” “downton abbey,” “star wars,” “pixar”).for the amazon dataset, topics revealed both positive and nega- tive
        sentiment toward content and quality. topic 0 captures dissatis- faction with plot and character development, while topic 1
        centers on complaints about poor quality and overall disappointment. top- ics 2 and 3 highlight user opinions about comedic
        elements and characters. topics 4 and 5 focus on special effects, adaptations, and mixed responses to storylines. topic 6 reflects
        positive opinions on documentaries and informative material, whereas topics 7 and 8 emphasize entertaining storylines and favorite
        selections. topic 9 highlights praise for the downton abbey series, and topic 10 high- lights references to science fiction
        franchises such as terminator andstar wars . in the imdb dataset, topics are more genre-driven. topic 0 re- flects appreciation
        for compelling storytelling. topics 1 and 2 cap- ture emotional connections with themes of love, music, and super- hero
        characters, respectively. topics 3 and 4 represent an interest in action-oriented content, with topic 4 specifically aligning with
        the style of tarantino. topic 5 covers animated disney films, while topic 6 focuses on war narratives. topic 7 reflects interest
        in horror, especially zombie-related content. topics 8 and 9 express general praise for well-told stories and fan-favorite
        franchises such as harry potter andpirates of the caribbean . therotten tomatoes dataset presents a mix of technical and emotional
        feedback. topic 0 discusses characters, plot, and the struc- ture of action. topic 1 highlights directorial quality, performance,
        and soundtrack. topics 2 and 7 reflect entertainment value and comedic content, while topics 3 and 4 focus on documentaries and
        strong acting performances. topic 5 is associated with horror and thriller genres, and topic 6 revolves around romantic and
        comedic themes. topic 8 includes family-friendly animated content, particu- larly disney-related films. topics 9 and 10 refer to
        sequels, remakes, and nostalgic action icons like james bond and clint eastwood. lastly, topic 11 includes spanish-language
        reviews, some of which reference director francis ford coppola. 6.2 recommendation models table 2 presents the performance
        comparison across the baselines on the datasets, where the best results are in bold. the proposed graft algorithm demonstrates
        competitive and stable perfor- mance, especially in terms of rating prediction (rmse). on the amazon dataset, graft achieves the
        lowest rmse (1.0413), indicating superior accuracy in rating prediction compared to svd (1.0525), deepconn (1.0792), and kann
        (1.2297). however, svd outperforms graft in all ranking-based metrics (ndcg@10, recall@10, mrr@10, and map@10), suggesting that
        traditional latent factor models may still be more effective at producing top- ranked item lists under sparse conditions. for the
        imdb dataset, graft again records the lowest rmse (2.0337), demonstrating its robustness in rating prediction even under increased
        sparsity. nonetheless, svd leads in all ranking metrics here as well. graft remains competitive in mrr and map, demonstrating that
        while it may not produce the most relevant items as effectively as svd, it consistently learns to rank moderately relevant items.
        on the rotten tomatoes dataset, graft achieves the best rmse (0.7652), reaf- firming its strength in accurate rating prediction.
        in contrast, svd again outperforms all models in ndcg@10, recall@10, mrr@10,24 a gated review attention framework for topics in
        graph-based recommenders webmedia’2025, rio de janeiro, brazil table 2: performance on amazon movies & tv, reported as mean
        ±standard deviation (sd) over 5-fold cross-validation. algorithm dataset rmse ndcg@10 recall@10 mrr@10 map@10 graft amazon movies
        and tv 1.0413±0.0312 0.0400±0.0014 0.0884±0.0019 0.0256±0.0012 0.0256±0.0012 svd amazon movies and tv 1.0525 ±0.0315 0.0663±0.0056
        0.1475±0.0115 0.0418±0.0038 0.0419±0.0038 deepconn amazon movies and tv 1.0792 ±0.0317 0.0444±0.0174 0.0951±0.0353 0.0289±0.0119
        0.0289±0.0119 kann amazon movies and tv 1.2297 ±0.0338 0.0491±0.0028 0.1069±0.0057 0.0317±0.0020 0.0317±0.0020 graft imdb
        2.0337±0.0354 0.0606±0.0070 0.1189±0.0110 0.0377±0.0046 0.0383±0.0047 svd imdb 2.0451 ±0.0391 0.0797±0.0031 0.1511±0.0054
        0.0520±0.0023 0.0527±0.0024 deepconn imdb 2.0712 ±0.0344 0.0405±0.0032 0.0844±0.0067 0.0235±0.0017 0.0239±0.0017 kann imdb 2.4935
        ±0.0560 0.0447±0.0059 0.0908±0.0127 0.0272±0.0039 0.0276±0.0039 graft rotten tomatoes 0.7652±0.0084 0.0894±0.0041 0.2026±0.0074
        0.0555±0.0039 0.0556±0.0039 svd rotten tomatoes 0.7770 ±0.0086 0.1457±0.0051 0.3017±0.0080 0.0980±0.0054 0.0981±0.0053 deepconn
        rotten tomatoes 0.7789 ±0.0097 0.0295±0.0024 0.0645±0.0037 0.0190±0.0020 0.0190±0.0020 kann rotten tomatoes 1.0161 ±0.0074
        0.0478±0.0098 0.1022±0.0171 0.0311±0.0074 0.0312±0.0074 and map@10. this consistent gap in ranking metrics suggests that graft’s
        current architecture favors precision in rating regression over high-ranking item retrieval. paired t-tests were conducted to
        evaluate the performance of the proposed graft model against the strongest baseline, svd, using rmse and ranking-based metrics
        (ndcg@10, recall@10, mrr@10, and map@10). results indicate that graft significantly outperformed svd in terms of rmse across all
        datasets: amazon (𝑡(4)=−10.24,𝑝=0.0005 ),imdb (𝑡(4)=−3.14,𝑝=0.0349 ), and rotten tomatoes (𝑡(4)=−3.78,𝑝=0.0194 ), confirming its
        advantage in rating prediction accuracy. despite svd obtaining higher absolute scores on ranking metrics, graft consistently
        showed statistically significant differences in all cases. for ndcg@10, graft was significantly lower than svd on amazon
        (𝑡(4)=−11.88,𝑝=0.0003 ),imdb (𝑡(4)=−6.88, 𝑝=0.0023 ), and rotten tomatoes (𝑡(4)=−14.81,𝑝=0.0001 ). the same trend held for
        recall@10 ( amazon :𝑡(4)=−12.30,𝑝=0.0003; imdb :𝑡(4)=−8.50,𝑝=0.0011;rotten tomatoes :𝑡(4)=−15.65,𝑝= 0.0001), mrr@10 ( amazon
        :𝑡(4)=−11.37,𝑝=0.0003;imdb :𝑡(4)= −6.83,𝑝=0.0024;rotten tomatoes :𝑡(4)=−12.53,𝑝=0.0002), and map@10 ( amazon
        :𝑡(4)=−11.38,𝑝=0.0003;imdb :𝑡(4)=−6.82, 𝑝=0.0024;rotten tomatoes :𝑡(4)=−12.65,𝑝=0.0002). table 3 presents the novelty and
        serendipity metrics for the graft, svd, deepconn, and kann models across the datasets. graft demonstrates a consistently balanced
        performance, achiev- ing high novelty scores (e.g., 15.03±0.03onamazon ) and moderate but stable serendipity, particularly
        excelling on rotten tomatoes (0.1818±0.0073). this indicates that graft is capable of offering di- verse recommendations while
        maintaining relevance and surprise, aligning well with user interests. table 3 presents the novelty and serendipity metrics for
        the graft, svd, deepconn, and kann models across the amazon , imdb , and rotten tomatoes datasets. graft demonstrates a consis-
        tent and balanced behavior, achieving moderate novelty scores (e.g., 15.03±0.03onamazon , which are slightly lower than other
        models) but notably higher serendipity than deepconn and kann, espe- cially on rotten tomatoes (0.1818±0.0073). this indicates
        graft’s strength in recommending items that are not necessarily the mosttable 3: novelty and serendipity metrics (mean ±sd) for
        each model on the amazon, imdb, and rotten tomatoes datasets, calculated over 5-fold cross-validation. model dataset novelty
        serendipity graft amazon 15.0317 ±0.0335 0.0550±0.0009 svd amazon 14.9348 ±0.0157 0.1583±0.0091 deepconn amazon 15.5111±0.1929
        0.0079±0.0069 kann amazon 15.4146 ±0.0175 0.0309±0.0111 graft imdb 9.9088 ±0.0238 0.0958±0.0086 svd imdb 10.0486 ±0.0095
        0.1487±0.0040 deepconn imdb 10.0539 ±0.0520 0.0844±0.0068 kann imdb 10.5072±0.0014 0.0085±0.0037 graft rotten tomatoes 13.8079
        ±0.0272 0.1818±0.0073 svd rotten tomatoes 13.6807 ±0.0153 0.2994±0.0126 deepconn rotten tomatoes 15.2170±0.0965 0.0645±0.0038 kann
        rotten tomatoes 15.0869 ±0.0021 0.0195±0.0122 obscure but are still diverse and contextually relevant, often result- ing in
        pleasant user surprise. svd stands out with the highest serendipity values across all datasets, reaching 0.2988±0.0081 onrotten
        tomatoes . still, it does so at the expense of novelty, especially on imdb , where its novelty drops to 10.51±0.0026 . this
        suggests that svd favors more con- ventional or popular items that may occasionally be unexpected but are less exploratory.
        deepconn, in contrast, demonstrates the highest novelty values in most scenarios (e.g., 15.51±0.19onamazon ) but suffers from
        extremely low serendipity on that same dataset ( 0.0079±0.0069). this imbalance suggests that deepconn often recommends rare or
        lesser-known items, but these may not effectively surprise or satisfy the user, indicating weaker personalization. kann performs
        close to svd in novelty (e.g., 15.41±0.02onama- zon). still, its serendipity is substantially lower across all datasets,
        particularly on imdb (0.0085±0.0037) and rotten tomatoes (0.0195± 0.0122 ). this suggests that while kann is capable of
        suggesting25 webmedia’2025, rio de janeiro, brazil ferreira et al. 012345678910 t op-10 items with similarity >
        0.7020004000600080001000012000number of users (a) amazon movies and tv 012345678910 t op-10 items with similarity >
        0.7050010001500200025003000number of users (b) imdb 0 1 2 3 4 5 6 7 8 t op-10 items with similarity > 0.70100200300400500number of
        users (c) rotten tomatoes figure 1: distribution of high-similarity items (>0.7) in top-10 ranked recommendations across datasets.
        each subplot shows the number of users who received a given count of high-similarity items in their recommendation list. novel
        items, it struggles to make those recommendations contextu- ally surprising or relevant to users. 6.3 discussion and the graft
        analysis these results confirm that although graft does not achieve the best top-𝑘ranking metrics, the differences with svd are
        statisti- cally significant. the consistent improvement in rmse, paired with competitive performance in ranking metrics,
        underscores graft’s unique capacity to capture nuanced user-item relationships through review-driven graph modeling, even if those
        advantages do not directly translate into higher rank-based scores. overall, graft demonstrates clear advantages in rating
        accuracy across all datasets. while it does not surpass svd in ranking metrics, its strength lies in combining review-derived
        semantic signals with structural graph information to more accurately estimate rating values. this balance underscores the model’s
        effectiveness in learning user and item representations from sparse, semantically rich data. nonetheless, this design centers on
        direct user–item interactions and may underutilize richer, higher-order graph structures that contribute to ranking efficacy.
        while the gated attention mecha- nism effectively integrates review semantics to refine user and item representations, yielding
        superior accuracy in rating prediction, it primarily operates within explicit user–item relations. this direct modeling can limit
        the propagation of signals across the graph, thereby reducing the model’s ability to infer transitive preferences, which are
        crucial for ranking tasks. moreover, the fusion gate may attenuate weaker collaborative signals in favor of stronger textual cues,
        which benefits regression objectives but can hinder relative ranking performance. overall, the results highlight a trade-off be-
        tween semantic precision and generalization in ranking, which is intrinsic to graft’s design. to complement the quantitative
        evaluation of the recommenda- tion model, we implement a qualitative analysis that aims to inter- pret the model’s decision-making
        process. by examining the align- ment between predicted item rankings and ground-truth relevance, we strive to understand how well
        the model captures meaningful relationships beyond conventional metrics. the analysis evaluates the distribution and proportion of
        high-similarity recommenda- tions (>0.7) within the top-10 ranked items across the datasets. the goal is to evaluate the model’s
        ability to rank highly similar items within the recommendation list consistently.the figure 1 presents a general histogram showing
        the similarity between the ground truth list and the top-10 ranked recommenda- tion list for each dataset. in amazon, 54.21% of
        the recommended items exhibit similarity above the threshold. moreover, 84.04% of users receive at least three items above this
        threshold. the figure 1a reflects this distribution, with a concentration of users receiving between 5 and 9 high-similarity
        items. for imdb, surprisingly, the behavior is even more pronounced in contrast to the general results from the models, where this
        dataset presents the most challeng- ing ratings to predict. the overall proportion of high-similarity items reaches 90.31%, and
        99.01% of users are served with three or more such items. figure 1b confirms this, showing that most users receive between 8 and
        10 high-similarity items. rotten tomatoes presents a contrasting behavior. only 24.05% of the top-10 items exceed the similarity
        threshold, and just 45.41% of users receive three or more despite the similarity proportions being relatively balanced across the
        top-k positions (ranging from 21.96% to 25.45%). figure 1c shows a marked decline in the number of users with more than 7
        high-similarity items. the absence of values for ranks 9 and 10 is not a visualization artifact, but rather reflects that no users
        received 9 or more items with similarity above 0.7. nevertheless, the corresponding proportions in top-9 and top-10 indicate that
        these ranks still contain relevant items across users, although not concentrated within individual recommendation lists. overall,
        the model demonstrates strong alignment in the imdb dataset, moderate performance in amazon, and lower alignment in rotten
        tomatoes. these trends highlight the variation in user-item similarity structure across datasets and emphasize the importance of
        analyzing both visual and quantitative aspects when evaluating recommender system behavior. 6.4 limitations and points of
        improvement this work presents certain limitations that define the scope of the current proposal. first, the model does not
        account for temporal aspects. all reviews are treated equally, regardless of when they were written, even though more recent
        reviews often carry more weight in influencing user behavior and item perception. second, like many text-based recommenders, graft
        relies on a sufficient volume of explicit reviews to extract reliable topics and gating signals; in cold-start scenarios, where
        new users or items have few or no reviews, its performance may degrade. lastly, while the use of topic information allows for some
        level of semantic abstraction,26 a gated review attention framework for topics in graph-based recommenders webmedia’2025, rio de
        janeiro, brazil the model does not incorporate sentiment analysis in the review processing pipeline. as a result, explicit
        emotional tone or polarity expressed in the text is not directly captured or modeled. these aspects define the current boundaries
        of the approach and indicate areas where the methodology could be strengthened. 7 conclusion and future remarks in this work, we
        proposed graft: a gated review attention frame- work for topics in graph-based recommenders. our approach in- tegrates topic
        representations extracted from user reviews into a graph attention architecture, enabling more nuanced modeling of user
        preferences and item characteristics. by incorporating a gating mechanism inspired by recurrent neural networks, the model learns
        to dynamically control the influence of review-derived topics along- side traditional latent embeddings. experimental results
        across multiple datasets demonstrate that graft consistently enhances predictive performance and recommendation quality,
        particularly when textual context contributes significantly to item differentia- tion. these findings reinforce our hypothesis
        that incorporating semantic information from reviews enhances the model’s ability to generate more expressive user and item
        representations. both quan- titative results and similarity-based qualitative analysis confirm that the model retrieves
        contextually coherent recommendations aligned with user preferences. despite these promising results, several limitations point to
        fu- ture directions. first, temporal aspects of reviews, such as recency and evolving user interests, were not considered,
        although they may affect the weight or relevance of extracted topics. second, the model’s attention and gating layers increase
        dimensionality and computational cost in proportion to the number of attention heads and layers, raising concerns about
        scalability. efficient neighbor sampling strategies and dimensionality reduction techniques could help mitigate this. moreover,
        adapting the model for constrained or edge environments remains an open challenge that necessitates further exploration.
        acknowledgments we want to thank the coordenação de aperfeiçoamento de pessoal de nível superior (capes – brazil) for funding this
        research under grant code 001. this research was also supported in part by the fapesb incite pie0002/2022 grant and fapesb
        ppf0001/2021grant. references [1]charu c. aggarwal. 2016. recommender systems: the textbook (1st ed.). springer publishing
        company, incorporated. [2]pablo castells and dietmar jannach. 2023. recommender systems: a primer. arxiv:2302.02579 [cs.ir]
        [3]chong chen, min zhang, yiqun liu, and shaoping ma. 2018. neural attentional rating regression with review-level explanations.
        in proceedings of the 2018 world wide web conference (lyon, france) (www ’18) . international world wide web conferences steering
        committee, republic and canton of geneva, che, 1583–1592. https://doi.org/10.1145/3178876.3186070 [4]li chen, guanliang chen, and
        feng wang. 2015. recommender systems based on user reviews: the state of the art. user modeling and user-adapted interaction 25, 2
        (june 2015), 99–154. https://doi.org/10.1007/s11257-015-9155-5 [5]tao chen, premaratne samaranayake, xiongying cen, meng qi, and
        yi-chen lan. 2022. the impact of online reviews on consumers’ purchasing decisions: evidence from an eye-tracking study. frontiers
        in psychology volume 13 - 2022 (2022). https://doi.org/10.3389/fpsyg.2022.865702 [6]zhiyong cheng, ying ding, xiangnan he, lei
        zhu, xuemeng song, and mo- han kankanhalli. 2018. a3ncf: an adaptive aspect attention model for ratingprediction. in proceedings
        of the 27th international joint conference on artificial intelligence (stockholm, sweden) (ijcai’18) . aaai press, 3748–3754.
        [7]kyunghyun cho, bart van merrienboer, caglar gulcehre, dzmitry bahdanau, fethi bougares, holger schwenk, and yoshua bengio.
        2014. learning phrase representations using rnn encoder-decoder for statistical machine translation. arxiv:1406.1078 [cs.cl]
        https://arxiv.org/abs/1406.1078 [8]shivangi gheewala, shuxiang xu, soonja yeom, and sumbal maqsood. 2024. ex- ploiting deep
        transformer models in textual review based recommender systems. expert systems with applications 235 (2024), 121120.
        https://doi.org/10.1016/j. eswa.2023.121120 [9]maarten grootendorst. 2022. bertopic: neural topic modeling with a class-based
        tf-idf procedure. arxiv:2203.05794 [cs.cl] https://arxiv.org/abs/2203.05794 [10] xiangfu he, qiyao peng, minglai shao, and yueheng
        sun. 2024. diffusion review- based recommendation. in knowledge science, engineering and management , cungeng cao, huajun chen,
        liang zhao, junaid arshad, taufiq asyhari, and yonghao wang (eds.). springer nature singapore, singapore, 255–269. [11] nicolas
        hug. 2020. surprise: a python library for recommender systems. journal of open source software 5, 52 (2020), 2174.
        https://doi.org/10.21105/joss.02174 [12] dietmar jannach, markus zanker, alexander felfernig, and gerhard friedrich. 2010.
        recommender systems: an introduction (1st ed.). cambridge university press, usa. [13] n. zafar ali khan and r. mahalakshmi. 2023.
        a novel user review-based contextual recommender system. international journal of modeling, simula- tion, and scientific computing
        14, 01 (2023), 2341002. https://doi.org/10.1142/ s1793962323410027 arxiv:https://doi.org/10.1142/s1793962323410027 [14] zheng li,
        di jin, and ke yuan. 2023. attentional factorization machine with review-based user–item interaction for recommendation.
        scientific reports 13, 1 (2023), 1–17. https://doi.org/10.1038/s41598-023-40633-4 [15] yun liu and jun miyazaki. 2022.
        knowledge-aware attentional neural network for review-based movie recommendation with explanations. neural comput. appl. 35, 3
        (sep 2022), 2717–2735. https://doi.org/10.1007/s00521-022-07689-1 [16] cataldo musto, marco de gemmis, giovanni semeraro, and
        pasquale lops. 2017. a multi-criteria recommender system exploiting aspect-based sentiment analysis of users’ reviews. in
        proceedings of the eleventh acm conference on recommender systems (como, italy) (recsys ’17) . association for computing
        machinery, new york, ny, usa, 321–325. https://doi.org/10.1145/3109859.3109905 [17] pedro pires, bruno rizzi, and tiago almeida.
        2024. why ignore content? a guideline for intrinsic evaluation of item embeddings for collaborative filtering. inproceedings of
        the 30th brazilian symposium on multimedia and the web (juiz de fora/mg). sbc, porto alegre, rs, brasil, 345–354.
        https://doi.org/10.5753/ webmedia.2024.243199 [18] shaina raza and chen ding. 2022. news recommender system: a review of recent
        progress, challenges, and opportunities. artif. intell. rev. 55, 1 (jan. 2022), 749–800.
        https://doi.org/10.1007/s10462-021-10043-x [19] fu shang, jiatu shi, yadong shi, and shuwen zhou. 2024. enhancing e-commerce
        recommendation systems with deep learning-based sentiment analysis of user reviews. international journal of engineering and
        management research 14, 4 (aug 2024). https://doi.org/10.5281/zenodo.13221409 [20] petar veličković, arantxa casanova, pietro liò,
        guillem cucurull, adriana romero, and yoshua bengio. 2018. graph attention networks. 6th international conference on learning
        representations, iclr 2018 - conference track proceedings (2018), 1–12. https://doi.org/10.1007/978-3-031-01587-8_7
        arxiv:1710.10903 [21] qiang wang, wen zhang, jian li, feng mai, and zhenzhong ma. 2022. effect of online review sentiment on
        product sales: the moderating role of review credibility perception. computers in human behavior 133 (2022), 107272. https:
        //doi.org/10.1016/j.chb.2022.107272 [22] shuang yang and xuesong cai. 2023. an enhanced recommendation model based on review text
        graph and interaction graph. ieee access 11 (2023), 88234–88244. https://doi.org/10.1109/access.2023.3305954 [23] eva zangerle and
        christine bauer. 2022. evaluating recommender systems: survey and framework. acm comput. surv. 55, 8, article 170 (dec. 2022), 38
        pages. https://doi.org/10.1145/3556536 [24] andré zanon, leonardo rocha, and marcelo manzato. 2024. o impacto de estratégias de
        embeddings de grafos na explicabilidade de sistemas de re- comendação. in proceedings of the 30th brazilian symposium on
        multimedia and the web (juiz de fora/mg). sbc, porto alegre, rs, brasil, 231–239. https: //doi.org/10.5753/webmedia.2024.241857
        [25] lei zheng, vahid noroozi, and philip s. yu. 2017. joint deep modeling of users and items using reviews for recommendation. in
        proceedings of the tenth acm international conference on web search and data mining (cambridge, united kingdom) (wsdm ’17) .
        association for computing machinery, new york, ny, usa, 425–434. https://doi.org/10.1145/3018661.3018665 [26] yuanyuan zhuang and
        jaekyeong kim. 2021. a bert-based multi-criteria recommender system for hotel promotion management. sustainability 13, 14 (2021).
        https://doi.org/10.3390/su1314803927

4. RESUMO GERAL:
    we then project these initial representations into a structural space of
    size𝑑′to align with the multi-head attention mechanism, as defined by:
    ℎ𝑢=𝑅𝑒𝐿𝑈(𝑊𝑝𝑟𝑜𝑗.𝑒𝑢), ℎ𝑖=𝑅𝑒𝐿𝑈(𝑊𝑝𝑟𝑜𝑗.𝑒𝑖),(1) where theℎ𝑢andℎ𝑖are the projected
    embeddings of the user and items, after applying a linear transformation by a
    relu activation, and𝑊𝑝𝑟𝑜𝑗∈r𝑑′×𝑑is the projection matrix used to transform the
    initial embeddings in the structural space used in graph attention network (gat)
    layers. for the imdb dataset, the optimal model parameters in- cluded an
    embedding dimension of 128, two layers, four attention heads,𝛼=0.2, a learning
    rate of 0.001, and a dropout rate of 0.2. for the amazon dataset, the ideal
    configuration featured an em- bedding dimension of 32, two layers, four
    attention heads, 𝛼=0.4, a learning rate of 0.001, and a dropout rate of 0.5. the
    best setup for rotten tomatoes was identical to that of imdb, with an embed-
    ding dimension of 128, two layers, four attention heads, 𝛼=0.2, a learning rate
    of 0.001, and a dropout rate of 0.2. all configurations utilized concat=false .
    all hidden layers were configured with a size of 1024, and the number of
    attention spaces 𝐻was set to 4. to manage input length, we retained the portion
    of reviews that covered 90% of users and items in terms of length, and 80% in
    terms of quantity. word embeddings were ini- tialized with a dimension of 64.
    the convolutional layer contained 100 neurons with a kernel window size of 3.
    the latent dimension for the final user-item interaction layer was set to 10. we
    used a learning rate of 0.002, a dropout rate of 0.1, and a batch size of 128
    throughout the training process.5.4 metrics recommender systems are evaluated
    using both rating accuracy and ranking quality. it is based on the dissimilarity
    (1 minus cosine similarity) between a recommended relevant item and the set of
    previously interacted items: serendipity@ 𝐾=1 |rel𝐾|∑︁ 𝑖∈rel𝐾/√︁a√︂enleftig
    1−cos(v𝑖,vhistory)/√︁a√︂en√︂ightig (15) where v𝑖is the embedding of item 𝑖, and
    vhistory is the average embedding of items in the user’s history.23
    webmedia’2025, rio de janeiro, brazil ferreira et al. 5.5 methodology we
    conducted our experiments using a 5-fold cross-validation pro- tocol to ensure
    robust results. the goal is to evaluate the model’s ability to rank highly
    similar items within the recommendation list consistently.the figure 1 presents
    a general histogram showing the similarity between the ground truth list and the
    top-10 ranked recommenda- tion list for each dataset.

==================================================

--- ARTIGO: articles/A Zero-Shot Prompting Approach for Automated Feedback Generation on ENEM Essays.pdf ---

1. TOP 10 TERMOS:
    - feedback       : 69
    - c              : 47
    - essay          : 42
    - essays         : 39
    - model          : 33
    - enem           : 31
    - models         : 26
    - competency     : 26
    - portuguese     : 17
    - sabi           : 17

2. REFERÊNCIAS EXTRAÍDAS (29 total):
    [1] [1]hugo abonizio, thales sales almeida, thiago laitz, roseval malaquias junior, giovana
kerche bonás, rodrigo nogueira, and ramon pires. 2025. sabiá-3 . technical report.
maritaca ai.
    [2] [2]rafael t anchiêta, rogério f de sousa, and raimundo s moura. 2024. a robust- ness
analysis of automated essay scoring methods. in anais do xv simpósio brasileiro de
tecnologia da informação e da linguagem humana . sbc, belém, brazil, 75–80.
    [3] [3]rogério f. de sousa, jeziel c. marinho, francisco a. r. neto, rafael t. anchiêta, and
raimundo s. moura. 2024. piln at propor: a bert-based strategy for grading narrative
essays. in proceedings of the 16th international conference on computational processing of
portuguese - vol. 2 . association for computational linguistics, santiago de compostela,
galicia/spain, 10–13.
    [4] [4]jacob devlin, ming-wei chang, kenton lee, and kristina toutanova. 2019. bert:
pre-training of deep bidirectional transformers for language understanding. in proceedings
of the 2019 conference of the north american chapter of the association for computational
linguistics: human language technologies, volume 1 (long and short papers) . association
for computational linguistics, minneapolis, minnesota, 4171–4186.
    [5] [5]anton havnes, kari smith, olga dysthe, and kristine ludvigsen. 2012. forma- tive
assessment and feedback: making learning visible. studies in educational evaluation 38, 1
(2012), 21–27.
    [6] [6]scott hellman, william murray, adam wiemerslage, mark rosenstein, peter foltz, lee
becker, and marcia derr. 2020. multiple instance learning for content feedback
localization without annotation. in proceedings of the fifteenth work- shop on innovative
use of nlp for building educational applications . association for computational
linguistics, seattle, wa, usa →online, 30–40.
    [7] [7]zixuan ke and vincent ng. 2019. automated essay scoring: a survey of the state of the
art. in proceedings of the 28th international joint conference on artificial intelligence
. aaai press, macao, china, 6300–6308.
    [8] [8]vivekanandan kumar and david boulanger. 2020. explainable automated essay scoring: deep
learning really has pedagogical value. frontiers in education 5 (2020), 22.
    [9] [9]chin-yew lin. 2004. rouge: a package for automatic evaluation of summaries. intext
summarization branches out . association for computational linguistics, barcelona, spain,
74–81.
    [10] [10] pengfei liu, weizhe yuan, jinlan fu, zhengbao jiang, hiroaki hayashi, and graham
neubig. 2023. pre-train, prompt, and predict: a systematic survey of prompting methods in
natural language processing. acm computing surveys 55, 9 (2023), 1–35.
6https://soberania.ai/
    [11] [11] yuanchao liu, jiawei han, alexander sboev, and ilya makarov. 2024. geef: a neural
network model for automatic essay feedback generation by integrating writing skills
assessment. expert systems with applications 245 (2024), 123043.
    [12] [12] scott m lundberg and su-in lee. 2017. a unified approach to interpreting model
predictions. in advances in neural information processing systems . curran associates,
inc., long beach, ca, usa, 4765–4774.
    [13] [13] jeziel c. marinho, rafael t. anchiêta, and raimundo s. moura. 2021. essay-br: a
brazilian corpus of essays. in xxxiv simpósio brasileiro de banco de dados: dataset
showcase workshop, sbbd 2021 . sbc, online, 53–64.
    [14] [14] jeziel c. marinho, rafael t. anchiêta, and raimundo s. moura. 2022. essay-br: a
brazilian corpus to automatic essay scoring task. journal of information and data
management 13, 1 (2022), 65–76.
    [15] [15] jeziel c. marinho, fábio c., rafael t. anchiêta, and raimundo s. moura. 2022.
automated essay scoring: an approach based on enem competencies. in anais do xix encontro
nacional de inteligência artificial e computacional . sbc, campinas, brazil, 49–60.
    [16] [16] rafael ferreira mello, hilário oliveira, moésio wenceslau, hyan batista, thiago
cordeiro, ig ibert bittencourt, and seiji isotanif. 2024. propor‘24 competition on
automatic essay scoring of portuguese narrative essays. in proceedings of the 16th
international conference on computational processing of portuguese - vol. 2 . association
for computational linguistics, santiago de compostela, galicia/spain, 1–5.
    [17] [17] haile misgna, byung-won on, ingyu lee, and gyu sang choi. 2025. a survey on deep
learning-based automated essay scoring and feedback generation. artificial intelligence
review 58, 2 (2025), 1–40.
    [18] [18] hilário oliveira, rafael ferreira mello, bruno alexandre barreiros rosa, mladen
rakovic, pericles miranda, thiago cordeiro, seiji isotani, ig bittencourt, and dragan
gasevic. 2023. towards explainable prediction of essay cohesion in portuguese and english.
in proceedings of the 13th international learning analytics and knowledge conference .
association for computing machinery, arlington tx usa, 509–519.
    [19] [19] hilário oliveira, rafael ferreira mello, péricles miranda, hyan batista, moé- sio
wenceslau da silva filho, thiago cordeiro, ig ibert bittencourt, and seiji isotani. 2025.
a benchmark dataset of narrative student essays with multi- competency grades for
automatic essay scoring in brazilian portuguese. data in brief 60 (2025), 111526.
    [20] [20] leanne owen. 2016. the impact of feedback as formative assessment on student
performance. international journal of teaching and learning in higher education 28, 2
(2016), 168–175.
    [21] [21] ellis b page. 1966. the imminence of... grading essays by computer. the phi delta
kappan 47, 5 (1966), 238–243.
    [22] [22] kishore papineni, salim roukos, todd ward, and wei-jing zhu. 2002. bleu: a method for
automatic evaluation of machine translation. in proceedings of the 40th annual meeting of
the association for computational linguistics . association for computational linguistics,
philadelphia, pennsylvania, usa, 311–318.
    [23] [23] melissa m patchan, christian d schunn, and richard j correnti. 2016. the nature of
feedback: how peer feedback features affect students’ implementation rate and quality of
revisions. journal of educational psychology 108, 8 (2016), 1098.
    [24] [24] mark d shermis and felicia d barrera. 2002. exit assessments: evaluating writing
ability through automated essay scoring. in annual meeting of the american educational
research association . eric, new orleans, la, 1–30.
    [25] [25] joyce m silva, rafael t anchiêta, rogério f de sousa, and raimundo s moura. 2024.
investigating methods to detect off-topic essays. in proceedings of the 34th brazilian
conference on intelligent systems . springer, belém, brazil, 346–357.
    [26] [26] igor cataneo silveira, andré barbosa, daniel silva lopes da costa, and de- nis
deratani mauá. 2024. investigating universal adversarial attacks against
transformers-based automatic essay scoring systems. in proceedings of the 34th brazilian
conference on intelligent systems . springer, belém, brazil, 169–183.
    [27] [27] igor cataneo silveira, andré barbosa, and denis deratani mauá. 2024. a new benchmark
for automatic essay scoring in portuguese. in proceedings of the 16th international
conference on computational processing of portuguese - vol. 1 . asso- ciation for
computational linguistics, santiago de compostela, galicia/spain, 228–237.
    [28] [28] an yang, anfeng li, baosong yang, beichen zhang, binyuan hui, bo zheng, bowen yu,
chang gao, chengen huang, chenxu lv, chujie zheng, dayiheng liu, fan zhou, fei huang, feng
hu, hao ge, haoran wei, huan lin, jialong tang, jian yang, jianhong tu, jianwei zhang,
jianxin yang, jiaxi yang, jing zhou, jingren zhou, junyang lin, kai dang, keqin bao, kexin
yang, le yu, lianghao deng, mei li, mingfeng xue, mingze li, pei zhang, peng wang, qin
zhu, rui men, ruize gao, shixuan liu, shuang luo, tianhao li, tianyi tang, wenbiao yin,
xingzhang ren, xinyu wang, xinyu zhang, xuancheng ren, yang fan, yang su, yichang zhang,
yinger zhang, yu wan, yuqiong liu, zekun wang, zeyu cui, zhenru zhang, zhipeng zhou, and
zihan qiu. 2025. qwen3 technical report. arxiv:2505.09388 [cs.cl]
https://arxiv.org/abs/2505.09388
    [29] [29] tianyi zhang, varsha kishore, felix wu, kilian q. weinberger, and yoav artzi. 2020.
bertscore: evaluating text generation with bert. in 8th international conference on
learning representations . openreview.net, online.515

3. PARÁGRAFOS RELEVANTES (TOP-1):
  > OBJETIVO:
    Score: 2.000
        a zero-shot prompting approach for automated feedback generation on enem essays rafael t. anchiêta rafael.torres@ifma.edu.br
        federal institute of maranhão caxias, maranhãoanthony i. m. luz marquesanthony62@gmail.com federal institute of piauí picos, piauí
        shara l. c. lopes shara.lopes@ifpi.edu.br federal institute of piauí campo maior, piauíraimundo s. moura rsm@ufpi.edu.br federal
        university of piauí teresina, piauí abstract automated essay scoring (aes) has made significant progress in evaluating written
        texts, but the generation of constructive feed- back for essays, particularly in portuguese, remains underexplored. this paper
        proposes a zero-shot prompting approach to automati- cally generate feedback for enem essays, an essential component of formative
        assessments. we evaluate several large language models (llms) – gemini 2.0 flash, sabiá 3, llama 3-8b, and qwen 3-8b – to provide
        feedback on five competencies defined by the enem scor- ing rubric. using the aes-enem dataset, we prompt the models to generate
        feedback for each competency, comparing their semantic similarity with human feedback using the bertscore metric. ad- ditionally,
        a linguist with expertise in enem essays evaluates the feedback for its constructiveness and informativeness. our results
        demonstrate that while the models perform similarly in bertscore evaluations, the qwen model produces the most informative and
        constructive feedback. this work contributes to the development of automated systems that not only grade essays but also assist in
        improving student writing skills, potentially reducing teacher workload in large-scale assessments. keywords essays, feedback,
        language model, zero-shot 1 introduction automated essay scoring (aes) is the computer technology that evaluates and scores the
        written prose [ 24]. it aims to provide com- putational models for automatically grading essays with minimal human involvement [
        21]. this research area began with page in 1966 with the project essay grader system [ 21], which have con- tinuously evolved
        since then, as noted by ke and ng [7]. the aes area has recently gained the attention of the brazil- ian community through
        publicly available corpora [ 13,14,19,27], methods to grade an essay or its characteristics [ 3,15,18,25], and robustness analysis
        [ 2,26]. moreover, the propor’24 competition recently occurred, aiming to develop computer systems capable of automatically
        evaluating essays [16]. in: proceedings of the brazilian symposium on multimedia and the web (webme- dia’2025). rio de janeiro,
        brazil. porto alegre: brazilian computer society, 2025. ©2025 sbc – brazilian computing society. issn 2966-2753despite the growing
        interest in the aes area for portuguese, researchers have overlooked the generation of feedback for essays. feedback is a crucial
        element in evaluating essay writing. assigning grades to essays alone does not effectively help students improve their essay
        writing skills [ 17]. furthermore, guiding students on areas for improvement and how to enhance their writing skills is essential
        to the learning process of essay writing [ 23]. formative assessments, which aim to improve writing proficiency through ongoing
        interaction, necessitate providing feedback to essay au- thors [ 5,20]. thus, developing aes systems that not only grade essays
        but also provide insightful feedback is crucial for practical formative writing assessments. to bridge the gap in research
        concerning feedback generation for portuguese, this paper contributes a zero-shot prompting strategy designed to generate feedback
        from enem essays. the high school national exam (enem - exame nacional do ensino médio ) is used to assess the quality of high
        school education and serves as an ad- mission test for most public and private universities. enem adopts specific competencies to
        grade essays (cross-prompt trait scoring), analyzing aspects such as adherence to formal language norms, text structure, argument
        development, and the proposal of solutions, making the development of automatic assessment strategies more challenging. our
        methodology investigated several large language mod- els (llms), applied to a selection of essays from the aes-enem dataset [ 27].
        we prompted gemini 2.0 flash1, sabiá 3 [ 1], llama 32, and qwen 3 [ 28] models to generate feedback for each enem com- petency.
        then, we compared the automatic and manual feedback using the bertscore metric [ 29], which measures the semantic similarity
        between a generated text and a reference text using contextual embeddings from a bert model [ 4]. furthermore, we enlisted the
        assistance of one linguist with expertise in evaluating enem essays to assess and rank the feedback generated by the llms, aiming
        to identify which responses were the most construc- tive and informative. it is important to say that the human was unaware that
        the feedback was automatically generated. our findings revealed that all llms achieved similar results when compared with human
        feedback using the bert-score metric. when assessed by a human, the qwen model ranked highest across all competencies. human
        evaluation has also indicated that this 1https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-0-flash
        2https://ai.meta.com/blog/meta-llama-3/511 webmedia’2025, rio de janeiro, brazil anchiêta et al. automatically generated feedback
        may be helpful in an educational context, helping teachers reduce their workload. to the best of our knowledge, this is the first
        initiative on automated feedback generation on enem essays. the rest of this paper is organized as follows. section 2 briefly
        presents the related work. in section 3, we introduce the corpus used to generate automatic feedback. in section 4, we detail our
        zero-shot prompt strategy to condition llms to provide feedback. section 5 discusses the results achieved. finally, section 6
        concludes the paper and presents future directions. 2 related work as mentioned, researchers have neglected the generation of
        feed- back for essays in portuguese. here, we concisely present the works related to the english language, which is the most
        studied. hellman et al. [ 6] proposed an approach called knn-mil, which employs k-nearest neighbor (knn) and multi-instance
        learning (mil) models for determining the impact of each sentence in the overall score of the essay. the aggregated score from the
        sentences is used to create a document-level holistic score. by framing the aes task as mil, this work presented a sentence
        annotation mechanism to enhance the feedback process in building an explainable aes model. kumar and boulanger [ 8] proposed a
        deep learning approach to automated essay scoring, which provides feedback using expla- nation. the proposed approach aims to
        predict the quality of the writing style and expose the decision process that led to these pre- dictions. to this end, the authors
        utilized the shap tool [ 12] to generate local and global explanations. liu et al. [ 11] developed an encoder-decoder neural
        network model called geef (generate essay feedback), which addresses dif- ferent aspects of essay writing, such as fluency,
        coherence, richness, and literary talent. the authors compared their approach with base- line methods using bleu [ 22] and rouge [
        9] metrics, achieving promising results. our strategy differs from others because we leverage the text generation capability of
        language models to provide feedback on essays written in portuguese. in the next section, we present the corpus used in the
        experiments. 3 corpus we utilized a selection of essays from the aes-enem dataset [ 27]. this corpus is composed of essays from
        the vestibular uol3and uol educação4websites, and it consists of 3,586 essays. besides the graded essays, the corpus includes a
        prompt, supporting text, and feedback for each essay. however, only 190 essays contain feedback for each enem competency, which we
        used in our experiments. from these 190 essays, we computed some statistics about feedback for each competency, as shown in table
        1. as we can see, the competencies with the most tokens and sen- tences are 3 and 1, respectively. the latter is related to
        adherence to the formal written norm of portuguese, while the former refers to argumentation in defense of a point of view. we
        suggest consulting 3https://vestibular.brasilescola.uol.com.br/banco-de-redacoes
        4https://educacao.uol.com.br/bancoderedacoes/table 1: statistics for each competency. competencytokens sentences mean std mean std
        c1 25 .31 12 .65 2 .83 1 .81 c2 19 .00 9 .29 2 .03 1 .11 c3 28 .15 16 .91 3 .16 2 .22 c4 13 .58 6 .03 1 .52 0 .75 c5 15 .16 8 .62
        1 .75 1 .03 the participant’s handbook for more details about the enem essay assessment criterion5. additionally, we calculated
        the distribution of essay grades, as illustrated in figure 1. the distribution is somewhat similar to the normal distribution,
        with a concentration of essay grades between 480 and 600. 040 80120 160 200 240 280 320 360 400 440 480 520 560 600 640 680 720
        760 800 840 880 920 9601000 final grade0.02.55.07.510.012.515.017.520.0count 5.0 1.0 1.0 1.03.06.0 3.0 3.07.0 3.015.0 11.021.0
        19.0 17.018.0 7.0 6.015.0 6.0 5.0 3.07.0 2.0 2.03.0distribution of final grades figure 1: distribution of final grades. in the
        following section, we outline our strategy for generating feedback. 4 zero-shot prompting zero-shot prompting is a technique for
        conditioning a language model with instructions to perform a task without any examples. this method of conditioning is called
        “prompting”, and it must not be part of the training data of the model [10]. with a zero-shot strategy, we prompted several
        language models to generate feedback for each enem competency. we designed a prompt and organized it into three steps. first, we
        explain the task context, as depicted in figure 2. in this context, we requested the model act as a specialized proofreader for
        enem essays, providing it with an essay and supporting text. act as a specialized proofreader in dissertative-argumentative essays
        for enem. the following essay was written by a high school student, and you will need to revise it in just 5 sentences: {essay}
        use the following supporting text to check whether the writing is in line with the topic: {supporting_text} figure 2: context for
        the models. 5https://download.inep.gov.br/publicacoes/institucionais/avaliacoes_e_exames_da_
        educacao_basica/a_redacao_no_enem_2024_cartilha_do_participante.pdf512 a zero-shot prompting approach for automated feedback
        generation on enem essays webmedia’2025, rio de janeiro, brazil second, we detail the model task, as shown in figure 3. in the
        task, the model should provide feedback for each enem competency based on the enem criteria. each feedback should be one sentence
        long and constructive, clear, and detailed. although the feedback in the corpus is, on average, longer than one sentence, we
        requested language models to generate one sentence to avoid hallucinations. you must provide feedback for each enem competency. in
        the first sentence, provide feedback related to the formal use of the portuguese language. take into account the grammatical and
        spelling aspects, suitability for formal writing, and choice of vocabulary. in the second sentence, analyze whether the essay is
        related to the proposed theme and the presence of sociocultural repertoire. in the third sentence, analyze whether the essay
        selects, relates, organizes, and interprets information, facts, opinions, and arguments in defense of the chosen point of view. in
        the fourth sentence, analyze the cohesion and coherence of the essay. in the fifth sentence, analyze the proposed intervention in
        the essay. keep a constructive, clear, and detailed tone. figure 3: task to be performed by the models. in the third step, we
        asked the model for an output, as presented in figure 4. this output indicates the sentences for each enem competency. the output
        should be as follows: ## competency 1 ## first sentence ## competency 2 ## second sentence ## competency 3 ## third sentence ##
        competency 4 ## fourth sentence ## competency 5 ## fifth sentence figure 4: example of output of the model. from this prompt, we
        conditioned the following models: gemini 2.0 flash, sabiá 3, llama 3-8b, and qwen 3-8b. we chose these models because they have a
        free application programming interface (api) or are open-source. for example, the first one is a google model, which has a
        free-of-charge api that is sufficient for our experiments. the second is a maritaca ai model. it was trained on documents written
        in portuguese, with a special focus on brazil- related resources. moreover, it offers a free api for teaching and research
        purposes. the third and fourth are open-source models from meta ai and alibaba cloud, respectively. we used the default parameters
        to prompt the models. table 2 shows values for temperature ,top_p , and top_k parameters. the first controls the randomness and
        creativity of the generated text. the second controls the cumulative probability threshold for token selection, and the last
        limits the number of tokens the model con- siders at each step. the top_k value for sabiá is not informed inits documentation.
        however, since this model is based on llama, we believe the value of this parameter is the same as in the llama model. table 2:
        parameters for the llms. modelparameter temperature top_p top_k gemini 1.0 0.95 64 sabiá 0.7 0.95 - llama 0.8 0.95 50 qwen 0.6
        0.95 20 in the following section, we detail our experiments and results. 5 experiments and results first, we computed the number
        of tokens and sentences produced by the models for each competency. table 3 presents the results for gemini, sabiá, while table 4
        shows llama and qwen values. the symbol “ ↑” denotes that the model generated more information than humans (table 1), whereas “ ↓”
        indicates the opposite. regarding tokens, only gemini produced fewer tokens (c1, c3) than humans. concerning the sentences, gemini
        (all competencies), sabiá (c1, c2, and c3), and llama (c1 and c3) generated fewer sentences than humans. the qwen model generated
        significantly more tokens and sentences than the other models, indicating a higher level of verbosity. table 3: statistics for
        each competency - gemini and sabiá. gemini sabiá competencytokens sentences tokens sentences mean std mean std mean std mean std
        c1 20 .25↓3.67 1 .03↓0.18 29 .71↑6.16 2 .12↓0.46 c2 23 .09↑3.73 1 .01↓0.07 27 .34↑4.29 1 .85↓0.38 c3 22 .97↓3.27 1 .02↓0.14 29
        .84↑3.61 2 .03↓0.25 c4 18 .97↑3.02 1 .02↓0.14 28 .08↑4.66 2 .72↑0.58 c5 23 .36↑5.64 1 .02↓0.12 30 .63↑4.58 2 .24↑0.48 table 4:
        statistics for each competency - llama and qwen. llama qwen competencytokens sentences tokens sentences mean std mean std mean std
        mean std c1 28 .37↑8.63 2 .56↓0.71 49 .42↑9.36 3 .58↑0.91 c2 26 .79↑5.68 2 .25↑0.47 45 .02↑6.64 3 .21↑0.66 c3 28 .81↑5.91 2
        .55↓0.54 47 .24↑7.31 3 .74↑0.72 c4 20 .72↑4.35 2 .29↑0.48 44 .18↑7.93 3 .88↑0.74 c5 30 .87↑8.20 2 .59↑0.78 44 .33↑7.40 3 .51↑0.77
        in addition to the number of tokens and sentences, we compared automatic and manual feedback using the bertscore metric [ 29]. as
        a bert model, we utilized the multilingual bert-based model. one can see in table 5 that the results are very similar. only the513
        webmedia’2025, rio de janeiro, brazil anchiêta et al. qwen model achieved a slightly lower result than the other models. we
        believe it is due to the number of tokens and sentences generated by the model. table 5: comparison between automatic and manual
        feed- back. competencybertscore - f1 gemini sabiá llama qwen c1 0.67 0 .67 0 .67 0 .66 c2 0.69 0 .69 0 .69 0 .67 c3 0.68 0 .68 0
        .69 0 .68 c4 0.69 0 .68 0 .69 0 .67 c5 0.68 0 .67 0 .68 0 .67 to better understand the results, we organized the corpus into
        intervals of 200per score, as presented in table 6. we are interested in knowing the score interval where the automatic feedback
        agrees with human feedback. however, as in table 5, the results for each interval and competency are very similar. table 6:
        detailed comparison between automatic and manual feedback. competency intervalbertscore - f1 gemini sabiá llama qwen c1[0,200]
        0.67 0 .67 0 .68 0 .66 (200 ,400] 0.68 0 .67 0 .67 0 .67 (400 ,600] 0.68 0 .68 0 .68 0 .67 (600 ,800] 0.68 0 .67 0 .68 0 .66 (800
        ,1000] 0.69 0 .68 0 .69 0 .67 c2[0,200] 0.70 0 .69 0 .70 0 .68 (200 ,400] 0.70 0 .69 0 .69 0 .68 (400 ,600] 0.69 0 .69 0 .69 0 .68
        (600 ,800] 0.69 0 .68 0 .69 0 .68 (800 ,1000] 0.68 0 .69 0 .69 0 .67 c3[0,200] 0.68 0 .68 0 .67 0 .68 (200 ,400] 0.69 0 .68 0 .68
        0 .68 (400 ,600] 0.68 0 .68 0 .67 0 .68 (600 ,800] 0.68 0 .68 0 .67 0 .68 (800 ,1000] 0.69 0 .69 0 .69 0 .68 c4[0,200] 0.69 0 .67
        0 .68 0 .67 (200 ,400] 0.69 0 .68 0 .70 0 .68 (400 ,600] 0.70 0 .68 0 .70 0 .68 (600 ,800] 0.70 0 .68 0 .70 0 .67 (800 ,1000] 0.70
        0 .68 0 .69 0 .67 c5[0,200] 0.70 0 .68 0 .69 0 .67 (200 ,400] 0.69 0 .68 0 .68 0 .68 (400 ,600] 0.68 0 .68 0 .68 0 .68 (600 ,800]
        0.68 0 .68 0 .68 0 .68 (800 ,1000] 0.69 0 .68 0 .69 0 .68 given the similarity in results across models, using bertscore, we
        invited one linguist with expertise in evaluating enem essays to rank the automatically generated feedback for each competency.our
        objective was to identify which model produces the most in- formative and constructive feedback in each case. to accomplish this,
        we randomly selected 50 essays, 10 essays for each 200-point interval. next, the linguist ranked the automatic feedback for each
        competency. this ranking was based on the enem criteria for each competency, analyzing whether the feedback helps a student im-
        prove their writing skills. finally, the linguist chose between the best-ranked feedback of each competency and the human feedback
        to identify which is more informative and constructive. to prevent bias, the linguist was unaware that the feedback originated
        from llm models and also did not know which feedback was produced by a human. figure 5 presents the llms ranked by the linguist.
        notably, the qwen model consistently achieved the highest ranking across all competencies, producing feedback that is more
        informative and constructive. we believe that one contributing factor to this result is the number of tokens and sentences
        generated by the model, even though we prompted it to generate only one sentence. figure 5: ranking of the llm models. gemini and
        sabiá models were both ranked second. gemini won sabiá in the first and fifth competencies, while sabiá beat gemini in the third
        and fourth competencies. this result suggests that gemini was better able to handle the standard norm of portuguese (c1) and the
        intervention proposal for the problem addressed in the essay (c5). in contrast, sabiá was better at identifying if an essay
        presents a coherent and cohesive argumentation (c3 and c4). finally, the llama model was ranked last in all competencies. after
        ranking the models, the linguist voted between the best- ranked feedback of each competency and the human feedback. table 7 shows
        the comparison between human feedback and the best-ranked model. table 7: comparison between human feedback and the best- ranked
        model. competency human victories qwen victories c1 9 17 c2 2 25 c3 3 28 c4 1 21 c5 3 17514 a zero-shot prompting approach for
        automated feedback generation on enem essays webmedia’2025, rio de janeiro, brazil we can see from this table that, out of 50
        essays, few human feedbacks were better than those generated by llms, indicating that, most of the time, automatic feedback was
        more constructive and informative than human feedback. 6 final remarks this paper explored a zero-shot prompting strategy for
        generating automated feedback on enem essays, addressing a significant gap in the automated essay scoring (aes) research,
        particularly for por- tuguese. our findings demonstrated that while quantitative evalua- tion using bertscore revealed broadly
        similar performance across the models, a qualitative assessment highlighted qwen 3 as the top-performing model, consistently
        generating feedback deemed more informative and constructive across all enem competencies. for future work, we intend to create a
        large corpus with human feedback for each enem competency. we will also explore other strategies, such as few-shot learning,
        chain-of-thought, and fine- tuning, using models developed exclusively for portuguese, such as soberania6. the source code and
        dataset used are available at https://github.com/rafaelanchieta/feedback-essay. acknowledgments the authors are grateful to
        maritaca ai for providing credits for experiments with sabiá 3. references [1]hugo abonizio, thales sales almeida, thiago laitz,
        roseval malaquias junior, giovana kerche bonás, rodrigo nogueira, and ramon pires. 2025. sabiá-3 . technical report. maritaca ai.
        [2]rafael t anchiêta, rogério f de sousa, and raimundo s moura. 2024. a robust- ness analysis of automated essay scoring methods.
        in anais do xv simpósio brasileiro de tecnologia da informação e da linguagem humana . sbc, belém, brazil, 75–80. [3]rogério f. de
        sousa, jeziel c. marinho, francisco a. r. neto, rafael t. anchiêta, and raimundo s. moura. 2024. piln at propor: a bert-based
        strategy for grading narrative essays. in proceedings of the 16th international conference on computational processing of
        portuguese - vol. 2 . association for computational linguistics, santiago de compostela, galicia/spain, 10–13. [4]jacob devlin,
        ming-wei chang, kenton lee, and kristina toutanova. 2019. bert: pre-training of deep bidirectional transformers for language
        understanding. in proceedings of the 2019 conference of the north american chapter of the association for computational
        linguistics: human language technologies, volume 1 (long and short papers) . association for computational linguistics,
        minneapolis, minnesota, 4171–4186. [5]anton havnes, kari smith, olga dysthe, and kristine ludvigsen. 2012. forma- tive assessment
        and feedback: making learning visible. studies in educational evaluation 38, 1 (2012), 21–27. [6]scott hellman, william murray,
        adam wiemerslage, mark rosenstein, peter foltz, lee becker, and marcia derr. 2020. multiple instance learning for content feedback
        localization without annotation. in proceedings of the fifteenth work- shop on innovative use of nlp for building educational
        applications . association for computational linguistics, seattle, wa, usa →online, 30–40. [7]zixuan ke and vincent ng. 2019.
        automated essay scoring: a survey of the state of the art. in proceedings of the 28th international joint conference on artificial
        intelligence . aaai press, macao, china, 6300–6308. [8]vivekanandan kumar and david boulanger. 2020. explainable automated essay
        scoring: deep learning really has pedagogical value. frontiers in education 5 (2020), 22. [9]chin-yew lin. 2004. rouge: a package
        for automatic evaluation of summaries. intext summarization branches out . association for computational linguistics, barcelona,
        spain, 74–81. [10] pengfei liu, weizhe yuan, jinlan fu, zhengbao jiang, hiroaki hayashi, and graham neubig. 2023. pre-train,
        prompt, and predict: a systematic survey of prompting methods in natural language processing. acm computing surveys 55, 9 (2023),
        1–35. 6https://soberania.ai/[11] yuanchao liu, jiawei han, alexander sboev, and ilya makarov. 2024. geef: a neural network model
        for automatic essay feedback generation by integrating writing skills assessment. expert systems with applications 245 (2024),
        123043. [12] scott m lundberg and su-in lee. 2017. a unified approach to interpreting model predictions. in advances in neural
        information processing systems . curran associates, inc., long beach, ca, usa, 4765–4774. [13] jeziel c. marinho, rafael t.
        anchiêta, and raimundo s. moura. 2021. essay-br: a brazilian corpus of essays. in xxxiv simpósio brasileiro de banco de dados:
        dataset showcase workshop, sbbd 2021 . sbc, online, 53–64. [14] jeziel c. marinho, rafael t. anchiêta, and raimundo s. moura.
        2022. essay-br: a brazilian corpus to automatic essay scoring task. journal of information and data management 13, 1 (2022),
        65–76. [15] jeziel c. marinho, fábio c., rafael t. anchiêta, and raimundo s. moura. 2022. automated essay scoring: an approach
        based on enem competencies. in anais do xix encontro nacional de inteligência artificial e computacional . sbc, campinas, brazil,
        49–60. [16] rafael ferreira mello, hilário oliveira, moésio wenceslau, hyan batista, thiago cordeiro, ig ibert bittencourt, and
        seiji isotanif. 2024. propor‘24 competition on automatic essay scoring of portuguese narrative essays. in proceedings of the 16th
        international conference on computational processing of portuguese - vol. 2 . association for computational linguistics, santiago
        de compostela, galicia/spain, 1–5. [17] haile misgna, byung-won on, ingyu lee, and gyu sang choi. 2025. a survey on deep
        learning-based automated essay scoring and feedback generation. artificial intelligence review 58, 2 (2025), 1–40. [18] hilário
        oliveira, rafael ferreira mello, bruno alexandre barreiros rosa, mladen rakovic, pericles miranda, thiago cordeiro, seiji isotani,
        ig bittencourt, and dragan gasevic. 2023. towards explainable prediction of essay cohesion in portuguese and english. in
        proceedings of the 13th international learning analytics and knowledge conference . association for computing machinery, arlington
        tx usa, 509–519. [19] hilário oliveira, rafael ferreira mello, péricles miranda, hyan batista, moé- sio wenceslau da silva filho,
        thiago cordeiro, ig ibert bittencourt, and seiji isotani. 2025. a benchmark dataset of narrative student essays with multi-
        competency grades for automatic essay scoring in brazilian portuguese. data in brief 60 (2025), 111526. [20] leanne owen. 2016.
        the impact of feedback as formative assessment on student performance. international journal of teaching and learning in higher
        education 28, 2 (2016), 168–175. [21] ellis b page. 1966. the imminence of... grading essays by computer. the phi delta kappan 47,
        5 (1966), 238–243. [22] kishore papineni, salim roukos, todd ward, and wei-jing zhu. 2002. bleu: a method for automatic evaluation
        of machine translation. in proceedings of the 40th annual meeting of the association for computational linguistics . association
        for computational linguistics, philadelphia, pennsylvania, usa, 311–318. [23] melissa m patchan, christian d schunn, and richard j
        correnti. 2016. the nature of feedback: how peer feedback features affect students’ implementation rate and quality of revisions.
        journal of educational psychology 108, 8 (2016), 1098. [24] mark d shermis and felicia d barrera. 2002. exit assessments:
        evaluating writing ability through automated essay scoring. in annual meeting of the american educational research association .
        eric, new orleans, la, 1–30. [25] joyce m silva, rafael t anchiêta, rogério f de sousa, and raimundo s moura. 2024. investigating
        methods to detect off-topic essays. in proceedings of the 34th brazilian conference on intelligent systems . springer, belém,
        brazil, 346–357. [26] igor cataneo silveira, andré barbosa, daniel silva lopes da costa, and de- nis deratani mauá. 2024.
        investigating universal adversarial attacks against transformers-based automatic essay scoring systems. in proceedings of the 34th
        brazilian conference on intelligent systems . springer, belém, brazil, 169–183. [27] igor cataneo silveira, andré barbosa, and
        denis deratani mauá. 2024. a new benchmark for automatic essay scoring in portuguese. in proceedings of the 16th international
        conference on computational processing of portuguese - vol. 1 . asso- ciation for computational linguistics, santiago de
        compostela, galicia/spain, 228–237. [28] an yang, anfeng li, baosong yang, beichen zhang, binyuan hui, bo zheng, bowen yu, chang
        gao, chengen huang, chenxu lv, chujie zheng, dayiheng liu, fan zhou, fei huang, feng hu, hao ge, haoran wei, huan lin, jialong
        tang, jian yang, jianhong tu, jianwei zhang, jianxin yang, jiaxi yang, jing zhou, jingren zhou, junyang lin, kai dang, keqin bao,
        kexin yang, le yu, lianghao deng, mei li, mingfeng xue, mingze li, pei zhang, peng wang, qin zhu, rui men, ruize gao, shixuan liu,
        shuang luo, tianhao li, tianyi tang, wenbiao yin, xingzhang ren, xinyu wang, xinyu zhang, xuancheng ren, yang fan, yang su,
        yichang zhang, yinger zhang, yu wan, yuqiong liu, zekun wang, zeyu cui, zhenru zhang, zhipeng zhou, and zihan qiu. 2025. qwen3
        technical report. arxiv:2505.09388 [cs.cl] https://arxiv.org/abs/2505.09388 [29] tianyi zhang, varsha kishore, felix wu, kilian q.
        weinberger, and yoav artzi. 2020. bertscore: evaluating text generation with bert. in 8th international conference on learning
        representations . openreview.net, online.515
  > PALAVRAS-CHAVES:
    Não encontrado.
  > PROBLEMA:
    Não encontrado.
  > CONTRIBUIÇÃO:
    Não encontrado.

4. RESUMO GERAL:
    furthermore, we enlisted the assistance of one linguist with expertise in
    evaluating enem essays to assess and rank the feedback generated by the llms,
    aiming to identify which responses were the most construc- tive and informative.
    the following essay was written by a high school student, and you will need to
    revise it in just 5 sentences: {essay} use the following supporting text to
    check whether the writing is in line with the topic: {supporting_text} figure 2:
    context for the models.
    5https://download.inep.gov.br/publicacoes/institucionais/avaliacoes_e_exames_da_
    educacao_basica/a_redacao_no_enem_2024_cartilha_do_participante.pdf512 a
    zero-shot prompting approach for automated feedback generation on enem essays
    webmedia’2025, rio de janeiro, brazil second, we detail the model task, as shown
    in figure 3. in the task, the model should provide feedback for each enem
    competency based on the enem criteria. the second controls the cumulative
    probability threshold for token selection, and the last limits the number of
    tokens the model con- siders at each step. competencybertscore - f1 gemini sabiá
    llama qwen c1 0.67 0 .67 0 .67 0 .66 c2 0.69 0 .69 0 .69 0 .67 c3 0.68 0 .68 0
    .69 0 .68 c4 0.69 0 .68 0 .69 0 .67 c5 0.68 0 .67 0 .68 0 .67 to better
    understand the results, we organized the corpus into intervals of 200per score,
    as presented in table 6. we are interested in knowing the score interval where
    the automatic feedback agrees with human feedback. competency intervalbertscore
    - f1 gemini sabiá llama qwen c1[0,200] 0.67 0 .67 0 .68 0 .66 (200 ,400] 0.68 0
    .67 0 .67 0 .67 (400 ,600] 0.68 0 .68 0 .68 0 .67 (600 ,800] 0.68 0 .67 0 .68 0
    .66 (800 ,1000] 0.69 0 .68 0 .69 0 .67 c2[0,200] 0.70 0 .69 0 .70 0 .68 (200
    ,400] 0.70 0 .69 0 .69 0 .68 (400 ,600] 0.69 0 .69 0 .69 0 .68 (600 ,800] 0.69 0
    .68 0 .69 0 .68 (800 ,1000] 0.68 0 .69 0 .69 0 .67 c3[0,200] 0.68 0 .68 0 .67 0
    .68 (200 ,400] 0.69 0 .68 0 .68 0 .68 (400 ,600] 0.68 0 .68 0 .67 0 .68 (600
    ,800] 0.68 0 .68 0 .67 0 .68 (800 ,1000] 0.69 0 .69 0 .69 0 .68 c4[0,200] 0.69 0
    .67 0 .68 0 .67 (200 ,400] 0.69 0 .68 0 .70 0 .68 (400 ,600] 0.70 0 .68 0 .70 0
    .68 (600 ,800] 0.70 0 .68 0 .70 0 .67 (800 ,1000] 0.70 0 .68 0 .69 0 .67
    c5[0,200] 0.70 0 .68 0 .69 0 .67 (200 ,400] 0.69 0 .68 0 .68 0 .68 (400 ,600]
    0.68 0 .68 0 .68 0 .68 (600 ,800] 0.68 0 .68 0 .68 0 .68 (800 ,1000] 0.69 0 .68
    0 .69 0 .68 given the similarity in results across models, using bertscore, we
    invited one linguist with expertise in evaluating enem essays to rank the
    automatically generated feedback for each competency.our objective was to
    identify which model produces the most in- formative and constructive feedback
    in each case.

==================================================

--- ARTIGO: articles/ClearFace Facial Acne Detection and Classification System Using YOLOv11 and EfficientNet-B0.pdf ---

1. TOP 10 TERMOS:
    - acne           : 53
    - detection      : 45
    - classification : 36
    - vol            : 36
    - model          : 31
    - dermatology    : 28
    - pp             : 27
    - j              : 27
    - lesions        : 26
    - p              : 25

2. REFERÊNCIAS EXTRAÍDAS (54 total):
    [1] [1] a. l. zaenglein, “acne vulgaris,” new england journal of medicine , vol. 379, no. 14,
pp. 1343–1352, 2018.
    [2] [2] d. v . samuels, r. rosenthal, r. lin, s. chaudhari, and m. n. natsuaki, “acne vulgaris
and risk of depression and anxiety: a meta-analytic review,” journal of the american
academy of dermatology , vol. 83, no. 2, pp. 532–541, 2020.
    [3] [3] i. vallerand, r. lewinson, l. parsons, m. lowerison, a. frolkis, g. kaplan, c.
barnabe, a. bulloch, and s. patten, “risk of depression among patients with acne in the
uk: a population-based cohort study,” british journal of dermatology , vol. 178, no. 3,
pp. e194–e195, 2018.
    [4] [4] x. wu, n. wen, j. liang, y .-k. lai, d. she, m.-m. cheng, and j. yang, “joint acne
image grading and counting via label distribution learning,” inproceedings of the ieee/cvf
international conference on computer vision (iccv) , october 2019.
    [5] [5] y . akpinar kara and d. ozdemir, “evaluation of food consumption in patients with acne
vulgaris and its relationship with acne severity,” journal of cosmetic dermatology , vol.
19, no. 8, pp. 2109–2113, 2020.
    [6] [6] e. nasr-esfahani, s. samavi, n. karimi, s. soroushmehr, m. jafari, k. ward, and k.
najarian, “2016 38th annual international conference of the ieee engineering in medicine
and biology society (embc),” melanoma detection by analysis of clinical images using
convolutional neural network , pp. 1373–1376, 2016.
    [7] [7] y . fujisawa, y . otomo, y . ogata, y . nakamura, r. fujita, y . ishitsuka, r.
watanabe, n. okiyama, k. ohara, and m. fujimoto, “deep-learning- based, computer-aided
classifier developed with a small dataset of clinical images surpasses board-certified
dermatologists in skin tumour diagnosis,” british journal of dermatology , vol. 180, no.
2, pp. 373–381, 02 2019. [online]. available: https://doi.org/10.1111/bjd.16924
    [8] [8] k. r. glines, w. haidari, l. ramani, z. m. akkurt, and s. r. feldman, “digital future
of dermatology,” dermatology online journal , vol. 26, no. 10, 2020.
    [9] [9] n. saranummi, “ieee transactions on information technology in biomedicine (t-itb),”
ieee transactions on information technology in biomedicine , vol. 7, no. 4, pp. 226–226,
2004.
    [10] [10] j. d. bernhard, “journal of the american academy of dermatology editorial office,”
journal of the american academy of dermatology , vol. 49, no. 6, p. 1028, 2003.
    [11] [11] k. byamba, s. syed-abdul, m. garc ´ıa-romero, c.-w. huang, s. nergyi, a. nyamdorj,
p.-a. nguyen, u. iqbal, k. paik, l. celi et al. , “mobile teledermatology for a prompter
and more efficient dermatological care in rural mongolia,” british journal of dermatology
, vol. 173, no. 1, pp. 265–267, 2015.
    [12] [12] f. m. walocko and t. tejasvi, “teledermatology applications in skin cancer
diagnosis,” dermatologic clinics , vol. 35, no. 4, pp. 559–563, 2017.
    [13] [13] s. ouellette and b. k. rao, “usefulness of smartphones in dermatology: a us-based
review,” international journal of environmental research and public health , vol. 19, no.
6, p. 3553, 2022.
    [14] [14] r. s. azfar, j. l. weinberg, g. cavric, i. a. lee-keltner, w. b. bilker, j. m.
gelfand, and c. l. kovarik, “hiv-positive patients in botswana state that mobile
teledermatology is an acceptable method for receiving dermatology care,” journal of
telemedicine and telecare , vol. 17, no. 6, pp. 338–340, 2011.
    [15] [15] i. radosavovic, r. p. kosaraju, r. girshick, k. he, and p. doll ´ar, “designing
network design spaces,” in proceedings of the ieee/cvf conference on computer vision and
pattern recognition , 2020, pp. 10 428–10 436.
    [16] [16] r. a. diptho and s. basak, “enhancing dermatological diagnosis through medical image
analysis: how effective is yolo11 compared to leading cnn models?” ndt , vol. 3, no. 2, p.
11, 2025.
    [17] [17] g. jocher and j. qiu, “ultralytics yolo11,” 2024. [online]. available:
https://github.com/ultralytics/ultralytics
    [18] [18] j. torous, h. wisniewski, b. bird, e. carpenter, g. david, e. elejalde, d. fulford,
s. guimond, r. hays, p. henson et al. , “creating a digital health smartphone app and
digital phenotyping platform for mental health and diverse healthcare needs: an
interdisciplinary and collaborative approach,” journal of technology in behavioral science
, vol. 4, no. 2, pp. 73–85, 2019.
    [19] [19] h. cort ´es, m. rojas-m ´arquez, m. l. del prado-audelo, o. d. reyes- hern ´andez, m.
gonz ´alez-del carmen, and g. leyva-g ´omez, “alter- ations in mental health and quality
of life in patients with skin disorders: a narrative review,” international journal of
dermatology , vol. 61, no. 7, pp. 783–791, 2022.
    [20] [20] a. c. brewer, d. c. endly, j. henley, m. amir, b. p. sampson, j. f. moreau, and r. p.
dellavalle, “mobile applications in dermatology,” jama dermatology , vol. 149, no. 11, pp.
1300–1304, 2013.
    [21] [21] k. tran, m. ayad, j. weinberg, a. cherng, m. chowdhury, s. monir, m. el hariri, and
c. kovarik, “mobile teledermatology in the developing world: implications of a feasibility
study on 30 egyptian patients with common skin diseases,” journal of the american academy
of dermatology , vol. 64, no. 2, pp. 302–309, 2011.
    [22] [22] h. kim, j. kim, e. jung, d. park, and j. roh, “mobile application in dermatology: a
useful tool for better communication and patient education,” hong kong journal of
dermatology & venereology , vol. 2, no. 26, pp. 67–70, 2018.
    [23] [23] s. j. lofgreen, k. ashack, k. a. burton, and r. p. dellavalle, “mobile device use in
dermatologic patient care,” current dermatology reports , vol. 5, no. 2, pp. 77–82, 2016.
    [24] [24] l. c. de guzman, r. p. c. maglaque, v . m. b. torres, s. p. a. zapido, and m. o.
cordel, “design and evaluation of a multi-model, multi- level artificial neural network
for eczema skin lesion detection,” in 2015 3rd international conference on artificial
intelligence, modelling and simulation (aims) . ieee, 2015, pp. 42–47.
    [25] [25] u. p. sudhakara, h. hebbar, g. arunkumar, and n. sampathila, “a technology framework
for remote patient care in dermatology for early diagnosis,” informatics in medicine
unlocked , vol. 15, p. 100171, 2019.
    [26] [26] e. g ¨oc ¸eri, “impact of deep learning and smartphone technologies in dermatology:
automated diagnosis,” in 2020 tenth international confer- ence on image processing theory,
tools and applications (ipta) . ieee, 2020, pp. 1–6.
    [27] [27] e. goceri, “diagnosis of skin diseases in the era of deep learning and mobile
technology,” computers in biology and medicine , vol. 134, p. 104458, 2021.
    [28] [28] s. wongvibulsin, m. j. yan, v . pahalyants, w. murphy, r. daneshjou, and v .
rotemberg, “current state of dermatology mobile applications with artificial intelligence
features,” jama dermatology , vol. 160, no. 6, pp. 646–650, 2024.
    [29] [29] p. p. rebouc ¸as filho, s. a. peixoto, r. v . m. da n ´obrega, d. j. hemanth, a. g.
medeiros, a. k. sangaiah, and v . h. c. de albuquerque, “auto- matic histologically-closer
classification of skin lesions,” computerized medical imaging and graphics , vol. 68, pp.
40–54, 2018.
    [30] [30] a. de, a. sarda, s. gupta, and s. das, “use of artificial intelligence in
dermatology,” indian journal of dermatology , vol. 65, no. 5, pp. 352– 357, 2020.
    [31] [31] t. j. brinker, a. hekler, a. h. enk, j. klode, a. hauschild, c. berking, b.
schilling, s. haferkamp, d. schadendorf, s. fr ¨ohling et al. , “a convo- lutional neural
network trained with dermoscopic images performed on par with 145 dermatologists in a
clinical melanoma image classification task,” european journal of cancer , vol. 111, pp.
148–154, 2019.
    [32] [32] m.-j. yim, j. m. lee, h.-s. kim, g. choi, y .-m. kim, d.-s. lee, and i.-w. choi,
“inhibitory effects of a sargassum miyabei yendo on cutibacterium acnes-induced skin
inflammation,” nutrients , vol. 12, no. 9, p. 2620, 2020.
    [33] [33] a. sangha and m. rizvi, “detection of acne by deep learning object detection,”
medrxiv , 2021.
    [34] [34] “automatic acne object detection and acne severity grading using smartphone images
and artificial intelligence,” diagnostics , vol. 12, no. 8, 2022.
    [35] [35] “acne detection by ensemble neural networks,” sensors , vol. 22, no. 18, 2022.
    [36] [36] “acne8m: an acne detection and differential diagnosis system using ai technologies,”
2023, study link provided, no doi available.
    [37] [37] “acne vulgaris detection and classification: a dual integrated deep cnn model,”
informatica (slovenia) , vol. 47, no. 4, 2023.
    [38] [38] c. huang et al. , “a computer vision application for assessing facial acne severity
from selfie images,” https://arxiv.org/abs/1907.07901, 2019.
    [39] [39] z. xu et al. , “acnet: mask-aware attention with dynamic context en- hancement for
robust acne detection,” https://arxiv.org/abs/2105.14891, 2021.
    [40] [40] k. simonyan and a. zisserman, “very deep convolutional networks for large-scale image
recognition,” arxiv preprint arxiv:1409.1556 , 2014.
    [41] [41] k. he, x. zhang, s. ren, and j. sun, “deep residual learning for image recognition,”
2016.
    [42] [42] c. szegedy, v . vanhoucke, s. ioffe, j. shlens, and z. wojna, “rethinking the
inception architecture for computer vision,” in proceedings of the ieee conference on
computer vision and pattern recognition (cvpr) , 2016.
    [43] [43] g. huang, z. liu, l. van der maaten, and k. q. weinberger, “densely connected
convolutional networks,” 2017.
    [44] [44] j. redmon, s. divvala, r. girshick, and a. farhadi, “you only look once: unified,
real-time object detection,” in proceedings of the ieee conference on computer vision and
pattern recognition (cvpr) , 2016.
    [45] [45] w. liu, d. anguelov, d. erhan, c. szegedy, s. reed, c.-y . fu, and a. c. berg, “ssd:
single shot multibox detector,” in european conference on computer vision (eccv) .
springer, 2016.
    [46] [46] s. vijayarani and s. dhivya, “facial acne classification using image processing and
machine learning,” international journal of computer applications , vol. 123, no. 9, 2015.
    [47] [47] p. k. kalra, a. ghosh, and a. kumar, “acne detection using clustering based image
segmentation and texture feature extraction with svm classifier,” procedia computer
science , vol. 167, pp. 2391–2400, 2019.
    [48] [48] m. everingham, l. van gool, c. williams, j. winn, and a. zisserman, “the pascal
visual object classes (voc) challenge,” international journal of computer vision , vol.
88, no. 2, pp. 303–338, 2010.
    [49] [49] t.-y . lin, m. maire, s. belongie, j. hays, p. perona, d. ramanan, p. doll ´ar, and
c. l. zitnick, “microsoft coco: common objects in context,” in european conference on
computer vision . springer, 2014, pp. 740–755.
    [50] [50] h. zhang and t. ma, “acne detection by ensemble neural networks,” sensors , vol. 22,
no. 18, 2022. [online]. available: https://www.mdpi.com/1424-8220/22/18/6828
    [51] [51] x. shen, j. zhang, c. yan, and h. zhou, “an automatic diagnosis method of facial acne
vulgaris based on convolutional neural network,” scientific reports , vol. 8, no. 1, p.
5839, 2018.
    [52] [52] r. sabir and t. mehmood, “classification of melanoma skin cancer based on image data
set using different neural networks,” scientific reports , vol. 14, no. 1, p. 29704, 2024.
    [53] [53] j. frederich, j. himawan, and m. rizkinia, “skin lesion classification using
efficientnet b0 and b1 via transfer learning for computer aided diagnosis,” in aip
conference proceedings , vol. 3080, no. 1. aip publishing, 2024.
    [54] [54] h. alsulaimani, a. kokandi, s. khawandanh, and r. hamad, “severity of acne vulgaris:
comparison of two assessment methods,” clinical, cosmetic and investigational dermatology
, pp. 711–716, 2020.

3. PARÁGRAFOS RELEVANTES (TOP-1):
  > OBJETIVO:
    Score: 3.001
        clearface: facial acne detection and classification system using yolov11 and efficientnet-b0 thierrir alencar da s. viana‡‡,
        ismael henrique gonc ¸alves‡, isa´ıas silva de paula‡, francisco h ´ercules dos s. silva∗‡e pedro p. rebouc ¸as filho∗†‡ ∗laborat
        ´orio de processamento de imagens, sinais e computac ¸ ˜ao aplicada (lapisco) †programa de p ´os-graduac ¸ ˜ao em ci ˆencias da
        computac ¸ ˜ao (ppgcc) instituto federal do cear ´a (ifce), fortaleza, cear ´a, brasil ‡instituto federal do cear ´a (ifce) autor
        correspondente: pedrosarf@ifce.edu.br abstract —facial acne is a highly prevalent dermatological condition that significantly
        affects individuals’ physical and psychological well-being. although clinical diagnosis remains the gold standard, limited access
        to specialized care highlights the need for scalable, automated solutions. this study presents a deep learning-based system for
        the detection and classification of facial acne lesions, combining object detection and image classification techniques. the
        yolov11-m model was employed to localize lesions in facial images, followed by classification using an efficientnet-b0 network. to
        train and evaluate the system, the acne21 dataset was adapted to a two-stage pipeline: bounding boxes were used for detection,
        while cropped regions were labeled into six classes for classification. the system generates lesion counts and calculates the
        investigator’s global assessment (iga) severity score based on clinical weights. experimental results demonstrate the model’s
        effectiveness in detecting and categorizing different lesion types, offering a promising tool for preliminary acne self-assessment
        in mobile health applications. this approach contributes to the advancement of accessible dermatological care through ai-driven
        technologies. i. i ntroduction acne, a chronic inflammatory skin disease that affects the pilosebaceous units, is characterized by
        seborrhea, comedones, papules, nodules, pimples, and scars [1], [2]. this condition affects up to 650 million people, including
        85% of teenagers and young adults worldwide [3]. in addition to physical dam- age, acne has a significant impact on patients’
        psychological health, often resulting in low self-esteem, depression, anxiety, and even suicidal tendencies [4], [5]. although
        common, access to clinical diagnosis is not always immediate, especially in regions with limited specialized pro- fessionals. the
        adoption of technology in healthcare practices shows significant potential, especially in the field of derma- tology, where
        precision in skin visualization and analysis is crucial [6], [7]. the increase in skin diseases and the need for accessible and
        accurate diagnoses are driving innovations that overcome physical barriers and broaden access to information [8], [9].
        teledermatology has emerged as a significant solution, enabling remote consultations with dermatologists and making care more
        accessible [10]–[12]. patients can send photos of their dermatological conditions for evaluation, reducing the need for
        face-to-face consultations and facilitating access tospecialized care, especially in regions with more limited access to
        specialists [13], [14]. deep neural networks (dnns) are a class of machine learn- ing algorithms inspired by the structure of the
        human brain. they consist of multiple layers of artificial neurons, which process and transform data at different levels of
        abstraction. the concept of deep neural networks dates back to the 1940s and 1950s, with the development of the first artificial
        neuron models. however, it is only in recent decades, with the increase in computing power and the development of efficient
        training algorithms, that dnns have become widely used. the applicability of deep neural networks is vast and covers a wide range
        of areas, including computer vision, nat- ural language processing, speech recognition, bioinformatics, among others. one of the
        most significant milestones in the advancement of dnns was the emergence of convolutional neural networks (cnns), especially in
        the area of computer vision. cnns are highly effective at extracting features from images and have found wide application in tasks
        such as object recognition, image segmentation, medical image diagnosis, and beyond [15]. a recent example is the yolov11 model,
        which has been explored to improve diagnosis in medical images analysis, as discussed by [16], [17]. the use of artificial
        intelligence (ai) and computer vision (cv) techniques allows the implementation of algorithms that perform complex tasks, such as
        skin lesion characterization, which are essential to the success of this project. robust diagnostic tools are of critical
        importance due to the significant impact of skin diseases on the quality of life of patients, who can suffer from low self-esteem
        and mental health problems. this technology seeks to accelerate diagnostic processes and mitigate these impacts [18], [19]. at the
        same time, advances in dermatological analysis have enabled detailed assessments of the skin, such as inflammation, texture, and
        blocked pores. these solutions facilitate derma- tologists to make precise diagnoses and personalize treatments according to each
        patient’s needs [8], [20], [21]. recent studies show not only the feasibility of adopting new technologies in dermatology, but
        also their implementation, which has been well received by patients and healthcare professionals [22], [23]. in addition, the
        application of artificial intelligence to sup- port the diagnosis and treatment of dermatological conditions reflects the
        continuous trajectory of innovation in the field [24]–[29]. these advances underscore the importance of re- searching and
        implementing ai-based solutions designed to provide more accurate diagnoses and significantly improve the clinical management of
        dermatological diseases [30]–[32]. in this context, the present project aimed to develop an arti- ficial intelligence model, based
        on computer vision techniques, to classify the severity of facial acne. the proposal seeks to enable users to conduct a
        preliminary self-assessment of their skin condition using a mobile application. the main stages developed were: •theoretical
        survey on acne and the main methodologies for classifying its severity; •definition of the technologies and tools for use in the
        development of the solution; •training of the yolov11 model in acne detection and classification. •training of the yolov11 model
        for the detection and classification of acne lesions; •development of an api for integration between the mobile application and
        the ai model; •implementation of the mobile application for acne self- assessment. the structure of this article is as follows:
        section ii presents the state of the art; section iii describes the methodology adopted; section iv discusses the results
        obtained; and section v presents the conclusions of this study. ii. s tate of art recent advancements in artificial intelligence
        (ai) and computer vision have facilitated the automation of facial acne detection and classification systems, reducing depen-
        dence on subjective dermatologist assessments [33], [34]. most approaches employ convolutional neural networks (cnns),
        segmentation algorithms, and object detectors such as yolo to localize lesions in facial images [35], [36]. once localized,
        lesions can be classified and assigned a severity score, such as the global acne grading system (gags) or the investigator’s
        global assessment (iga) [37], [38]. although accuracy has improved through public datasets, expert annotations, and data
        augmentation, research continues to explore attention and context-aware models to enhance robustness against variations in
        lighting, skin tone, and facial angle [39]. a. detection common acne detection typically involves a clinical visual examination by
        a specialist, which can be costly and subject to variability. to address these challenges, automated detection methods using
        artificial intelligence (ai) have been proposed, helping to mitigate issues related to human error [34], [38]. in this context,
        convolutional neural networks (cnns) are the most commonly used architectures for detecting facial lesions, due to their ability
        to extract hierarchical patterns from images [37], [39].the main models employing this technique include vgg16, resnet, densenet,
        and inceptionv3, which have been used across various projects to fulfill this role [40]–[43]. other models focused on object
        detection, such as yolo (you only look once) which is more general but less accurate in medical contexts—and ssd (single shot
        multibox detec- tor) which tends to be more precise for medical applications but also slower are also frequently applied in the
        field, even though they were not originally designed specifically for facial lesion detection [44], [45]. additionally, techniques
        such as semantic segmentation and transfer learning are commonly employed in the context of lesion detection [33], [39]. b.
        classification the classification of acne severity is often based on clinical examination, similarly to the detection process.
        however, while detection aims to identify the presence and location of acne lesions, classification focuses on determining the
        type and severity of those lesions. both tasks traditionally depend on dermatologists’ expertise and are subject to inter-observer
        variability and high operational costs [38]. to address these limitations, artificial intelligence (ai)- based models have been
        developed for the classification of facial acne severity. these models frequently leverage pre- trained convolutional neural
        networks (cnns) or combine multiple deep learning and machine learning techniques to improve accuracy and generalization [34],
        [35], [37]. one notable example is acnedet, which combines faster r-cnn for lesion detection with lightgbm for severity clas-
        sification. this model is capable of identifying up to four types of lesions and has achieved classification accuracy of up to 85
        percent on benchmark datasets [34]. similarly, the dli-net architecture, which integrates deeplabv3 and inceptionv3, reached an
        accuracy of 97 percent [37], while an ensemble approach combining resnet50 and yolov5 demonstrated high performance in both
        detection and classification tasks [35]. an alternative based on traditional machine learning is the use of a hybrid pipeline
        combining k-means clustering, gray- level co-occurrence matrix (glcm) texture analysis, and a random forest classifier. previous
        research has demonstrated that such approaches can achieve high accuracy in classifying different types of facial acne [46], [47].
        these methods present a viable alternative to purely cnn-based architectures, partic- ularly in scenarios with limited
        computational resources. despite the promising results, most models have been evaluated under controlled conditions and may not
        generalize well to real-world settings with diverse skin tones, lighting variations, or smartphone-quality images. therefore,
        further research is needed to enhance robustness, interpretability, and clinical reliability [36], [39]. c. metrics to assess the
        performance of the proposed system for acne lesion detection and classification, we adopted three widely used metrics in the field
        of computer vision: precision, recall, and mean average precision (map). precision indicates the proportion of correct predictions
        among all detections made, while recall measures the model’s ability to identify all actual lesions present in an image. map, in
        turn, provides the aver- age precision across different intersection over union (iou) thresholds, reflecting the overall
        performance of the model across all classes. these metrics are standard in renowned benchmarks such as pascal voc [48] and ms coco
        [49], and have also been adopted in recent studies on dermatological detection, such as zhang et al. [50]. by employing them, we
        aim to ensure a robust and consistent evaluation of the automated acne detection system, as well as enable direct and reliable
        comparisons with existing approaches in the literature. iii. m ethodology the study focused on building an automated system for
        identifying facial acne by combining object detection and image classification techniques. the proposed approach was designed as a
        two-stage pipeline: (i) a detection model to localize acne lesions in facial images, and (ii) a classification model to categorize
        each lesion into clinically relevant cat- egories (blackheads, whiteheads, papules, pustules, nodules, and cysts), following
        recent frameworks in dermatology re- search [50]. the overall operating pipeline of the system is illustrated in figure 1. figure
        1. operating pipeline of the proposed system a. preparation and transformation of the dataset the acne21 dataset was employed in
        this study, with annotations in the yolov11 format, including class identifiers and bounding box coordinates. to train the
        detection model, all lesion types were merged into a single label (“acne”), pre- serving only bounding box information. this
        transformation was automated through a python script to ensure annotation consistency, following practices adopted in related work
        [51]. for training the efficientnet-b0 classifier, the dataset was reorganized into a directory structure with six subfolders,
        each corresponding to one acne category: blackhead, whitehead, papule, pustule, nodule, and cyst. cropped regions were ex- tracted
        using bounding boxes from the original dataset and assigned to their respective class folders. this step ensured compatibility
        with classification models and follows recent dermatology studies that leverage lightweight convolutional networks such as
        efficientnet [52].b. training the models detection stage. for lesion detection, we employed yolov11-l with 640x640 input
        resolution, trained for 50 epochs (batch size 8, gpu, no amp). yolov11 was chosen for its effectiveness in detecting small objects
        [17], crucial for early acne lesions. the model was restricted to localization only, since (i) preliminary tests showed
        overlapping low- confidence predictions even after nms, and (ii) fine-grained subtype classification is outside yolo’s scope. to
        address this, we set a lower confidence threshold to maximize recall and delegated subtype classification to a specialized model
        on cropped regions. classification stage. the efficientnet-b0 model was used to categorize cropped lesion images. preprocessing
        included resizing to 384×384 pixels and applying data augmentation (randomhorizontalflip, randomrotation, and colorjitter).
        training was performed for 50 epochs with a batch size of 32 and a learning rate of 1×10−3, using the adamw optimizer with
        crossentropyloss. two learning rate sched- ulers (cosineannealinglr and reducelronplateau) were ap- plied, and early stopping was
        configured with patience of 5 epochs. the best-performing model was saved via checkpoint (“best model.pth”). efficientnet-b0 was
        selected for its bal- ance between accuracy and computational efficiency, as noted in [53]. c. integration of the models after
        training, the models were integrated into a unified pipeline. yolov11 was responsible solely for detecting and cropping lesion
        regions, while efficientnet-b0 classified each region into one of the six categories. the system generated a json file containing:
        the original image, a list of detected classes, a count of each lesion type, and the investigator’s global assessment (iga) score.
        the iga score was calculated using clinical weights (blackheads and whiteheads = 1, papules = 2, pustules = 3, nodules = 4, cysts
        = 5), following standard dermatological practice [54]. this design enables both pre- cise localization and clinically
        interpretable severity scoring, providing a scalable solution for mobile health applications. iv. r esults and discussion this
        section examines clearface results, including detection performance, classification, iga score estimation, qualitative analysis of
        predictions, and comparison with related studies. a. detection performance the yolov11-m model reached a precision of 42. 4%, a
        recall of 35. 2%, 31. 5% map@50, and 10. 3% map@50–95. these values indicate reasonable but limited performance, particularly
        considering the visual subtlety of certain acne lesions and variability in skin tone, lighting, and image quality. the large gap
        between precision and recall suggests that the model behaves conservatively: when a lesion is detected, it is usually correct
        (high precision), but many lesions are missed (low recall). the 31.5% map@50 aligns with results observed for lightweight models
        in medical tasks. however, the low map@50–95 score highlights the model’s limited ability to localize lesions precisely across
        multiple iou thresholds. figure 2. performance metrics of the yolo model results. b. classification performance the
        efficientnet-b0 classifier achieved 66.3% accuracy, 67.1% precision, 65.8% recall, and 66.2% f1-score. these results were computed
        using cropped images derived from bounding boxes in the acne21 dataset, ensuring alignment between regions of interest and their
        labels. this pattern is consistent with findings by shen et al. [51], who also reported significant confusion among certain lesion
        types when training skin condition classifiers. although the performance is moderate, potential improve- ments may be achieved by
        integrating attention mechanisms, using deeper efficientnet versions (e.g., b3 or b5), or applying stronger supervision
        techniques. c. iga score estimation the iga score regression resulted in a mean absolute error (mae) of 17.65, mean squared error
        (mse) of 726.57, root mean squared error (rmse) of 26.95, and mean absolute percentage error (mape) of 252.16%. these high errors
        indicate substantial inconsistency in sever- ity estimation, likely related to incorrect classification of severe lesion types,
        such as pustules and nodules. table i regression error metrics for the iga score metric abbreviation value mean absolute error mae
        17.65 mean squared error mse 726.57 root mean squared error rmse 26.95 mean absolute percentage error mape 252.16% d. qualitative
        examples and discussion evaluation of visual examples revealed that, when predic- tions were correct, the system localized lesions
        and assigned the appropriate classes with confidence. figure 3. examples of successful acne detections and classifications.
        failure cases included mislocalizations, missing lesions, or classification confusion. these issues were particularly frequent
        among lesions that were small, clustered, or visually ambiguous. figure 4. examples of incorrect acne detections and
        classifications. most visual errors were concentrated among pustules, papules, and nodules, reinforcing the difficulty in
        differentiat- ing between these visually similar forms. e. comparison with related studies clearface achieved 66.3% accuracy in
        classification using the efficientnet-b0 model on cropped lesion images. this result is lower than that reported by huynh et al.
        (2022), who achieved 85% accuracy on images captured with mobile phones. this performance gap is likely related to the fact that
        huynh et al.’s model was jointly optimized for detection and classification, resulting in fewer errors across pipeline stages.
        additionally, their dataset included greater diversity in acquisition conditions. in terms of severity estimation, clearface
        produced a mape of 252.16%, compared to 118% reported by gao et al. (2025) using a combined classification and regression
        approach. incorporating regression alongside classification, as in gao et al., could potentially reduce errors in severity as-
        sessment. clearface also produced significant errors in severe lesion types, such as pustules and nodules, consistent with
        previous observations by shen et al. (2018). overall, this analysis highlights the simplicity of clear- face’s two-stage
        architecture. however, performance may be improved by integrating multitask models or attention mecha- nisms to enhance detection
        and classification of subtle lesions. figure 5. normalized confusion matrix of yolov11 detection. furthermore, an error matrix was
        generated for the yolov11 model’s detection phase, going beyond basic per- formance metrics. results reveal that a substantial
        number of lesions were wrongly categorized as background, resulting in a high false-negative rate. in absolute and normalized
        matrices, nearly 71% of real lesions were missed. the model struggled to detect smaller or low-contrast lesions, particularly in
        lower-quality images captured under challenging lighting or overlapping skin conditions. v. c onclusion the primary objective of
        this study was to develop an artifi- cial intelligence model based on computer vision, designed to classify the severity of facial
        acne and to provide users with a preliminary self-assessment of their skin condition through a mobile application. the results
        indicated that, despite the limitations of the yolov11 model in complex scenarios, the efficientnet-b0 classifier performed more
        consistently, achiev- ing an accuracy of 67.1%. this result suggests that the model is capable of correctly identifying the
        majority of lesions in cropped images, even when faced with moderate variations in the input conditions. thus, this study
        represents an initial advance in the application of deep learning models to support dermatological assessment, contributing to the
        development of accessible and scalable solutions in the clinical context. a. future work although the results obtained are
        promising, especially with the efficientnet-b0 classifier, the quality of the classifications still depends directly on the
        previous detection stage, which, as shown, has significant limitations. to enable the system to achieve a level of reliability
        appropriate for potential clinical or personalized recommendation applications, several essential improvements are required.the
        first is the adoption of the gags (global acne grad- ing system) method, widely used by dermatologists because it considers not
        only the type of lesions, but also their distribution in the different anatomical regions of the face. to make this feasible, it
        will be necessary to incorporate facial semantic segmentation techniques, which will allow the precise delineation of areas such
        as the forehead, cheeks, chin, and nose. this stage will contribute significantly to adapting the system to recognized clinical
        standards. in addition, future versions of the project could investigate the use of alternative detection models beyond yolov11,
        such as yolov8, faster r-cnn, or architectures that demon- strate superior performance in contexts with small lesions and minimal
        texture variation. another promising line involves replacing or supplementing the current dataset with larger, more diverse
        databases annotated with standardized clinical criteria, which would enable the training of more robust and generalizable models.
        acknowledgment the authors acknowledge the financial support from the instituto federal de educac ¸ ˜ao, ci ˆencia e tecnologia do
        cear ´a (ifce) through the edital nº 9/2024 prpi/reitoria- ifce, which made this research possible. references [1] a. l.
        zaenglein, “acne vulgaris,” new england journal of medicine , vol. 379, no. 14, pp. 1343–1352, 2018. [2] d. v . samuels, r.
        rosenthal, r. lin, s. chaudhari, and m. n. natsuaki, “acne vulgaris and risk of depression and anxiety: a meta-analytic review,”
        journal of the american academy of dermatology , vol. 83, no. 2, pp. 532–541, 2020. [3] i. vallerand, r. lewinson, l. parsons, m.
        lowerison, a. frolkis, g. kaplan, c. barnabe, a. bulloch, and s. patten, “risk of depression among patients with acne in the uk: a
        population-based cohort study,” british journal of dermatology , vol. 178, no. 3, pp. e194–e195, 2018. [4] x. wu, n. wen, j.
        liang, y .-k. lai, d. she, m.-m. cheng, and j. yang, “joint acne image grading and counting via label distribution learning,”
        inproceedings of the ieee/cvf international conference on computer vision (iccv) , october 2019. [5] y . akpinar kara and d.
        ozdemir, “evaluation of food consumption in patients with acne vulgaris and its relationship with acne severity,” journal of
        cosmetic dermatology , vol. 19, no. 8, pp. 2109–2113, 2020. [6] e. nasr-esfahani, s. samavi, n. karimi, s. soroushmehr, m. jafari,
        k. ward, and k. najarian, “2016 38th annual international conference of the ieee engineering in medicine and biology society
        (embc),” melanoma detection by analysis of clinical images using convolutional neural network , pp. 1373–1376, 2016. [7] y .
        fujisawa, y . otomo, y . ogata, y . nakamura, r. fujita, y . ishitsuka, r. watanabe, n. okiyama, k. ohara, and m. fujimoto,
        “deep-learning- based, computer-aided classifier developed with a small dataset of clinical images surpasses board-certified
        dermatologists in skin tumour diagnosis,” british journal of dermatology , vol. 180, no. 2, pp. 373–381, 02 2019. [online].
        available: https://doi.org/10.1111/bjd.16924 [8] k. r. glines, w. haidari, l. ramani, z. m. akkurt, and s. r. feldman, “digital
        future of dermatology,” dermatology online journal , vol. 26, no. 10, 2020. [9] n. saranummi, “ieee transactions on information
        technology in biomedicine (t-itb),” ieee transactions on information technology in biomedicine , vol. 7, no. 4, pp. 226–226, 2004.
        [10] j. d. bernhard, “journal of the american academy of dermatology editorial office,” journal of the american academy of
        dermatology , vol. 49, no. 6, p. 1028, 2003. [11] k. byamba, s. syed-abdul, m. garc ´ıa-romero, c.-w. huang, s. nergyi, a.
        nyamdorj, p.-a. nguyen, u. iqbal, k. paik, l. celi et al. , “mobile teledermatology for a prompter and more efficient
        dermatological care in rural mongolia,” british journal of dermatology , vol. 173, no. 1, pp. 265–267, 2015. [12] f. m. walocko
        and t. tejasvi, “teledermatology applications in skin cancer diagnosis,” dermatologic clinics , vol. 35, no. 4, pp. 559–563, 2017.
        [13] s. ouellette and b. k. rao, “usefulness of smartphones in dermatology: a us-based review,” international journal of
        environmental research and public health , vol. 19, no. 6, p. 3553, 2022. [14] r. s. azfar, j. l. weinberg, g. cavric, i. a.
        lee-keltner, w. b. bilker, j. m. gelfand, and c. l. kovarik, “hiv-positive patients in botswana state that mobile teledermatology
        is an acceptable method for receiving dermatology care,” journal of telemedicine and telecare , vol. 17, no. 6, pp. 338–340, 2011.
        [15] i. radosavovic, r. p. kosaraju, r. girshick, k. he, and p. doll ´ar, “designing network design spaces,” in proceedings of the
        ieee/cvf conference on computer vision and pattern recognition , 2020, pp. 10 428–10 436. [16] r. a. diptho and s. basak,
        “enhancing dermatological diagnosis through medical image analysis: how effective is yolo11 compared to leading cnn models?” ndt ,
        vol. 3, no. 2, p. 11, 2025. [17] g. jocher and j. qiu, “ultralytics yolo11,” 2024. [online]. available:
        https://github.com/ultralytics/ultralytics [18] j. torous, h. wisniewski, b. bird, e. carpenter, g. david, e. elejalde, d.
        fulford, s. guimond, r. hays, p. henson et al. , “creating a digital health smartphone app and digital phenotyping platform for
        mental health and diverse healthcare needs: an interdisciplinary and collaborative approach,” journal of technology in behavioral
        science , vol. 4, no. 2, pp. 73–85, 2019. [19] h. cort ´es, m. rojas-m ´arquez, m. l. del prado-audelo, o. d. reyes- hern ´andez,
        m. gonz ´alez-del carmen, and g. leyva-g ´omez, “alter- ations in mental health and quality of life in patients with skin
        disorders: a narrative review,” international journal of dermatology , vol. 61, no. 7, pp. 783–791, 2022. [20] a. c. brewer, d. c.
        endly, j. henley, m. amir, b. p. sampson, j. f. moreau, and r. p. dellavalle, “mobile applications in dermatology,” jama
        dermatology , vol. 149, no. 11, pp. 1300–1304, 2013. [21] k. tran, m. ayad, j. weinberg, a. cherng, m. chowdhury, s. monir, m. el
        hariri, and c. kovarik, “mobile teledermatology in the developing world: implications of a feasibility study on 30 egyptian
        patients with common skin diseases,” journal of the american academy of dermatology , vol. 64, no. 2, pp. 302–309, 2011. [22] h.
        kim, j. kim, e. jung, d. park, and j. roh, “mobile application in dermatology: a useful tool for better communication and patient
        education,” hong kong journal of dermatology & venereology , vol. 2, no. 26, pp. 67–70, 2018. [23] s. j. lofgreen, k. ashack, k.
        a. burton, and r. p. dellavalle, “mobile device use in dermatologic patient care,” current dermatology reports , vol. 5, no. 2,
        pp. 77–82, 2016. [24] l. c. de guzman, r. p. c. maglaque, v . m. b. torres, s. p. a. zapido, and m. o. cordel, “design and
        evaluation of a multi-model, multi- level artificial neural network for eczema skin lesion detection,” in 2015 3rd international
        conference on artificial intelligence, modelling and simulation (aims) . ieee, 2015, pp. 42–47. [25] u. p. sudhakara, h. hebbar,
        g. arunkumar, and n. sampathila, “a technology framework for remote patient care in dermatology for early diagnosis,” informatics
        in medicine unlocked , vol. 15, p. 100171, 2019. [26] e. g ¨oc ¸eri, “impact of deep learning and smartphone technologies in
        dermatology: automated diagnosis,” in 2020 tenth international confer- ence on image processing theory, tools and applications
        (ipta) . ieee, 2020, pp. 1–6. [27] e. goceri, “diagnosis of skin diseases in the era of deep learning and mobile technology,”
        computers in biology and medicine , vol. 134, p. 104458, 2021. [28] s. wongvibulsin, m. j. yan, v . pahalyants, w. murphy, r.
        daneshjou, and v . rotemberg, “current state of dermatology mobile applications with artificial intelligence features,” jama
        dermatology , vol. 160, no. 6, pp. 646–650, 2024. [29] p. p. rebouc ¸as filho, s. a. peixoto, r. v . m. da n ´obrega, d. j.
        hemanth, a. g. medeiros, a. k. sangaiah, and v . h. c. de albuquerque, “auto- matic histologically-closer classification of skin
        lesions,” computerized medical imaging and graphics , vol. 68, pp. 40–54, 2018.[30] a. de, a. sarda, s. gupta, and s. das, “use of
        artificial intelligence in dermatology,” indian journal of dermatology , vol. 65, no. 5, pp. 352– 357, 2020. [31] t. j. brinker,
        a. hekler, a. h. enk, j. klode, a. hauschild, c. berking, b. schilling, s. haferkamp, d. schadendorf, s. fr ¨ohling et al. , “a
        convo- lutional neural network trained with dermoscopic images performed on par with 145 dermatologists in a clinical melanoma
        image classification task,” european journal of cancer , vol. 111, pp. 148–154, 2019. [32] m.-j. yim, j. m. lee, h.-s. kim, g.
        choi, y .-m. kim, d.-s. lee, and i.-w. choi, “inhibitory effects of a sargassum miyabei yendo on cutibacterium acnes-induced skin
        inflammation,” nutrients , vol. 12, no. 9, p. 2620, 2020. [33] a. sangha and m. rizvi, “detection of acne by deep learning object
        detection,” medrxiv , 2021. [34] “automatic acne object detection and acne severity grading using smartphone images and artificial
        intelligence,” diagnostics , vol. 12, no. 8, 2022. [35] “acne detection by ensemble neural networks,” sensors , vol. 22, no. 18,
        2022. [36] “acne8m: an acne detection and differential diagnosis system using ai technologies,” 2023, study link provided, no doi
        available. [37] “acne vulgaris detection and classification: a dual integrated deep cnn model,” informatica (slovenia) , vol. 47,
        no. 4, 2023. [38] c. huang et al. , “a computer vision application for assessing facial acne severity from selfie images,”
        https://arxiv.org/abs/1907.07901, 2019. [39] z. xu et al. , “acnet: mask-aware attention with dynamic context en- hancement for
        robust acne detection,” https://arxiv.org/abs/2105.14891, 2021. [40] k. simonyan and a. zisserman, “very deep convolutional
        networks for large-scale image recognition,” arxiv preprint arxiv:1409.1556 , 2014. [41] k. he, x. zhang, s. ren, and j. sun,
        “deep residual learning for image recognition,” 2016. [42] c. szegedy, v . vanhoucke, s. ioffe, j. shlens, and z. wojna,
        “rethinking the inception architecture for computer vision,” in proceedings of the ieee conference on computer vision and pattern
        recognition (cvpr) , 2016. [43] g. huang, z. liu, l. van der maaten, and k. q. weinberger, “densely connected convolutional
        networks,” 2017. [44] j. redmon, s. divvala, r. girshick, and a. farhadi, “you only look once: unified, real-time object
        detection,” in proceedings of the ieee conference on computer vision and pattern recognition (cvpr) , 2016. [45] w. liu, d.
        anguelov, d. erhan, c. szegedy, s. reed, c.-y . fu, and a. c. berg, “ssd: single shot multibox detector,” in european conference
        on computer vision (eccv) . springer, 2016. [46] s. vijayarani and s. dhivya, “facial acne classification using image processing
        and machine learning,” international journal of computer applications , vol. 123, no. 9, 2015. [47] p. k. kalra, a. ghosh, and a.
        kumar, “acne detection using clustering based image segmentation and texture feature extraction with svm classifier,” procedia
        computer science , vol. 167, pp. 2391–2400, 2019. [48] m. everingham, l. van gool, c. williams, j. winn, and a. zisserman, “the
        pascal visual object classes (voc) challenge,” international journal of computer vision , vol. 88, no. 2, pp. 303–338, 2010. [49]
        t.-y . lin, m. maire, s. belongie, j. hays, p. perona, d. ramanan, p. doll ´ar, and c. l. zitnick, “microsoft coco: common objects
        in context,” in european conference on computer vision . springer, 2014, pp. 740–755. [50] h. zhang and t. ma, “acne detection by
        ensemble neural networks,” sensors , vol. 22, no. 18, 2022. [online]. available: https://www.mdpi.com/1424-8220/22/18/6828 [51] x.
        shen, j. zhang, c. yan, and h. zhou, “an automatic diagnosis method of facial acne vulgaris based on convolutional neural
        network,” scientific reports , vol. 8, no. 1, p. 5839, 2018. [52] r. sabir and t. mehmood, “classification of melanoma skin cancer
        based on image data set using different neural networks,” scientific reports , vol. 14, no. 1, p. 29704, 2024. [53] j. frederich,
        j. himawan, and m. rizkinia, “skin lesion classification using efficientnet b0 and b1 via transfer learning for computer aided
        diagnosis,” in aip conference proceedings , vol. 3080, no. 1. aip publishing, 2024. [54] h. alsulaimani, a. kokandi, s.
        khawandanh, and r. hamad, “severity of acne vulgaris: comparison of two assessment methods,” clinical, cosmetic and
        investigational dermatology , pp. 711–716, 2020.
  > PALAVRAS-CHAVES:
    Não encontrado.
  > PROBLEMA:
    Não encontrado.
  > CONTRIBUIÇÃO:
    Não encontrado.

4. RESUMO GERAL:
    in addition, the application of artificial intelligence to sup- port the
    diagnosis and treatment of dermatological conditions reflects the continuous
    trajectory of innovation in the field [24]–[29]. the main stages developed were:
    •theoretical survey on acne and the main methodologies for classifying its
    severity; •definition of the technologies and tools for use in the development
    of the solution; •training of the yolov11 model in acne detection and
    classification. •training of the yolov11 model for the detection and
    classification of acne lesions; •development of an api for integration between
    the mobile application and the ai model; •implementation of the mobile
    application for acne self- assessment. the structure of this article is as
    follows: section ii presents the state of the art; section iii describes the
    methodology adopted; section iv discusses the results obtained; and section v
    presents the conclusions of this study. the overall operating pipeline of the
    system is illustrated in figure 1. figure 1. operating pipeline of the proposed
    system a. preparation and transformation of the dataset the acne21 dataset was
    employed in this study, with annotations in the yolov11 format, including class
    identifiers and bounding box coordinates. to enable the system to achieve a
    level of reliability appropriate for potential clinical or personalized
    recommendation applications, several essential improvements are required.the
    first is the adoption of the gags (global acne grad- ing system) method, widely
    used by dermatologists because it considers not only the type of lesions, but
    also their distribution in the different anatomical regions of the face.

==================================================

--- ARTIGO: articles/Multi-Pathology Segmentation of the Lumbar Spine.pdf ---

1. TOP 10 TERMOS:
    - class          : 45
    - multi          : 40
    - segmentation   : 32
    - approach       : 19
    - label          : 19
    - model          : 19
    - binary         : 17
    - learning       : 17
    - et             : 17
    - al             : 17

2. REFERÊNCIAS EXTRAÍDAS (19 total):
    [1] [1] g. mcnicoll, ”world population ageing 1950-2050,” popul. dev. rev. , pp. 814-816,
2002.
    [2] [2] m.g. fehlings et al., ”the aging of the global population: the changing epidemiology
of disease and spinal disorders,” neurosurgery , pp. s1-s5, 2015.
    [3] [3] j. w. van der graaf et al., “lumbar spine segmentation in mr images: a dataset and a
public benchmark,” sci. data, vol. 11, no. 264, 2024.
    [4] [4]˙i. altun et al., ”lss-unet: lumbar spinal stenosis semantic segmenta- tion using deep
learning,” multimed. tools appl. , 82:41287-41305, 2023.
    [5] [5] j. qian et al., ”lumbar disc herniation diagnosis using deep learning on mri,” j.
radiat. res. appl. sci. , 17(3):100988, 2024.
    [6] [6] r. windsor et al., ”spinenetv2: automated detection, labelling and radiological
grading of clinical mr scans,” arxiv:2205.01683, 2022.
    [7] [7] a. hatamizadeh et al., ”unetr: transformers for 3d medical image segmentation,” in
wacv , pp. 1748-1758, 2022.
    [8] [8] e. kerfoot et al., ”left-ventricle quantification using residual u-net,” in stacom ,
lncs 11395, pp. 371-380, 2019.
    [9] [9] f. milletari et al., ”v-net: fully convolutional neural networks for volumetric
medical image segmentation,” in 3dv, pp. 565-571, 2016.
    [10] [10] a. hatamizadeh et al., ”swin unetr: swin transformers for semantic segmentation of
brain tumors in mri images,” in brainles , lncs 12962, pp. 272-284, 2022.
    [11] [11] k. he et al., ”deep residual learning for image recognition,” in cvpr , pp. 770-778,
2016.
    [12] [12] t.-y . lin et al., ”focal loss for dense object detection,” in iccv , pp. 2980-2988,
2017.
    [13] [13] c. h. sudre et al., ”generalised dice overlap as a deep learning loss function for
highly unbalanced segmentations,” in dlmia, miccai wkshp. , pp. 240-248, 2017.
    [14] [14] w. mbarki et al., ”a novel method based on deep learning for herniated lumbar disc
segmentation,” in ic aset , pp. 394-399, 2020.
    [15] [15] j. qian et al., ”lumbar disc herniation diagnosis using deep learning on mri,” j.
radiat. res. appl. sci. , 17(3):100988, 2024.
    [16] [16] q. pan et al., ”automatically diagnosing disk bulge and disk hernia- tion...: method
development study,” jmir med. inform. , 9(5):e14755, 2021.
    [17] [17] y . chen et al., ”deep learning-based computer-aided diagnostic system for lumbar
degenerative diseases classification using mri,” biomed. signal process. control ,
109:108002, 2025.
    [18] [18] y . wang et al., ”deep learning-driven diagnosis of multi-type vertebra diseases
based on computed tomography images,” quant. imaging med. surg. , 14(1):800, 2023.
    [19] [19] m.-l. zhang and z.-h. zhou, ”a review on multi-label learning algo- rithms,” ieee
trans. knowl. data eng. , 26(8):1819-1837, 2013.

3. PARÁGRAFOS RELEVANTES (TOP-1):
  > OBJETIVO:
    Score: 3.001
        multi-pathology segmentation of the lumbar spine claudio leite federal university of s ˜ao carlos (ufscar)jurandy almeida federal
        university of s ˜ao carlos (ufscar) abstract —the diagnosis of spinal pathologies is complex due to the frequent overlap of
        multiple diseases in the same anatomical location, a scenario that current segmentation or classification methods do not
        efficiently address. this work presents an empirical study on the segmentation of multiple overlapping pathologies, proposing and
        systematically comparing three strate- gies: (i) a baseline binary class approach using independent models; (ii) a multi-class
        approach mapping disease combinations to unique labels; and (iii) a multi-label approach using parallel channels to explicitly
        model co-occurrence. we evaluated over 300 training and inference pipelines, combining five neural network architectures and three
        loss functions. our preliminary results show that the multi-label strategy significantly outperforms the other approaches in both
        accuracy and computational efficiency, establishing a promising direction for developing robust, scalable diagnostic tools. i. i
        ntroduction low back pain is a leading cause of disability world- wide [2], and magnetic resonance imaging (mri) of the lumbar
        spine is a cornerstone for its diagnosis [1]. however, a central challenge in the automated analysis of these images is the
        semantic overlap of multiple classes, where a single intervertebral disc may simultaneously present with conditions like a
        herniation and disc narrowing—a scenario most current methods are not designed to handle. current deep learning methods for lumbar
        spine analysis typically follow two paths: single-disease segmentation [4], [5] or complex multi-stage classification pipelines
        [6]. the former ignores pathological co-occurrence, while the latter are often computationally inefficient and difficult to
        generalize. neither approach effectively handles the common clinical scenario of multiple, overlapping pathologies within a
        unified framework. to address this gap, this paper presents an ongoing, compre- hensive study on the segmentation of multiple
        pathologies in lumbar discs. we propose and compare three distinct strategies to manage diagnostic overlap. our goal is to
        determine the most effective and efficient strategy for simultaneously delin- eating and diagnosing multiple co-occurring
        conditions. the main contributions of this work in progress are: •the proposition of three strategies for the multi-diagnosis
        problem: (i) a binary class approach treating each pathol- ogy independently; (ii) a multi-class approach mapping disease
        combinations to unique and exclusive classes; and (iii) a multi-label approach, which explicitly models the coexistence of
        diagnoses in distinct binary channels. •a systematic comparative analysis with over 300 training and inference pipelines,
        evaluating five neural networks and three loss functions, establishing a reference bench- mark for this complex clinical
        scenario.•the demonstration that the proposed multi-label strategy offers a superior trade-off between accuracy and compu-
        tational cost, achieving performance comparable to the significantly more expensive binary approach. the rest of this work is
        organized as follows. section ii discusses related work. section iii presents our approaches to multi-pathology diagnosis. section
        iv describes the experi- mental setup. section v reports our results. finally, section vi offers our conclusions and directions
        for future work. ii. r elated work the literature on spinal imaging with deep learning is exten- sive. one significant branch of
        research focuses on segmenting symptomatic areas for a single pathology, such as lumbar spinal stenosis [4] or disc herniation
        [14], [15]. while effective for their specific tasks, these methods are inherently single-label and cannot address the frequent
        coexistence of multiple diseases. a second line of work aims to diagnose multiple diseases but typically relies on complex,
        multi-stage pipelines that sep- arate structure localization from classification [6], [16]. these fragmented approaches are often
        computationally expensive and difficult to generalize. although some recent works have explored multi-label classification of
        spinal pathologies [17], [18], they operate on an image or patch level, failing to provide the precise spatial localization that
        semantic segmentation offers. our work bridges this gap by proposing end-to-end segmentation frameworks explicitly designed to
        handle multi- pathology overlap. iii. o urapproaches to address the challenge of multi-pathology diagnosis, we propose and
        systematically evaluate three distinct seman- tic segmentation strategies. these strategies—binary class, multi-class, and
        multi-label segmentation—represent differ- ent conceptual frameworks for handling diagnostic overlap and are detailed in the
        following subsections. a. binary class segmentation the first strategy (figure 1), binary class segmentation , serves as our
        baseline and decomposes the complex multi- diagnosis problem into a series of independent binary segmen- tation tasks. in this
        formulation, a separate segmentation model is trained specifically for each of the pathologies analyzed. letx∈rd×h×wbe an input
        magnetic resonance imaging (mri) volume and p={p1, . . . , p n}be the set of npathologies. for each pathology pk∈ p, a
        corresponding class1 class2 class3 masks overlapping masks segmentation outputsigmoidmodels images class1 class2 class3fig. 1:
        binary class segmentation. binary ground truth mask yk∈ {0,1}d×h×windicates its location. the objective is to learn a set of
        nindependent models {mk}n k=1, where each model mk:rd×h×w→ [0,1]d×h×wis trained to predict the mask yk. the final diagnosis for
        the volume xis the collection of all nindividual predictions and can be expressed as: ˆyk=mk(x),fork= 1, . . . , n (1) where each
        predicted mask ˆykis generated by a model mk. the main advantage of this strategy is its simplicity and focus. by training a model
        for a single task (e.g., segmenting only disc herniation), the network can specialize in learning the unique visual features of
        that condition. this can lead to high performance for each individual disease and establishes a robust performance ceiling against
        which the other, more complex strategies can be compared. however, the drawback of this approach lies in its high computational
        cost and resource inefficiency. the need to train, validate, and store nindependent models multiplies the experimentation time and
        hardware demand. furthermore, in a clinical scenario, it would be necessary to run all these models on a single patient’s mri to
        obtain a complete diagnosis, making the process slow and cumbersome. this strategy also fails to learn any correlations that may
        exist between different diseases, treating each as an isolated event. b. multi-class segmentation the second strategy (figure 2),
        multi-class segmenta- tion, reformulates the multi-diagnosis problem into a non- overlapping multi-class segmentation task. the
        premise is to create a unique class identifier for every possible combination of pathologies that can occur in a specific
        intervertebral disc. letcobs⊆2pbe the set of munique pathology combina- tions observed in the dataset. we create a new ground
        truth mask y′∈ {0,1, . . . , m }d×h×w. for each intervertebral disc, all its voxels are assigned a single integer label c∈ {1, . .
        . , m }that uniquely identifies the specific combination of pathologies present, with c= 0for the background. the goal is class1
        class2 class3 masks segmentation outputsoftmaxmodels images class1 class2 class3 non-overlapping maskslabel transformationfig. 2:
        multi-class segmentation. to learn a single model m:rd×h×w→r(m+1)×d×h×w that performs standard multi-class over these fused
        labels. this operation can be expressed as: ˆy′=argmax c(m(x)) (2) where the model moutputs a probability distribution over the m+
        1 classes for each voxel, and the final prediction ˆy′is the class with the maximum probability. the main advantage of this
        approach is its conceptual simplicity, allowing standard deep learning architectures to be trained end-to-end. however, its
        primary drawback is the combinatorial explosion in the number of classes, which increases model complexity and exacerbates class
        imbalance, as many pathology combinations are extremely rare. in this study, the m= 70 classes observed in the dataset were used.
        c. multi-label segmentation the final and most flexible strategy is multi-label seg- mentation (figure 3), which directly
        addresses the problem of coexisting pathologies. in this formulation, each disease is treated as an independent, binary
        segmentation channel, allowing for multiple, overlapping predictions. let the ground truth be a tensor y∈ {0,1}n×d×h×w, where each
        channel ykis the binary mask for pathology pk∈ p . the objective is to learn a single model m: rd×h×w→[0,1]n×d×h×wthat takes an
        mri volume and outputs a tensor of nprobability maps, one for each pathology. the operation for this approach can be expressed as:
        {ˆy1,ˆy2, . . . , ˆyn}=m(x) (3) where a single model msimultaneously generates a set of n distinct prediction masks. the primary
        advantage of this strategy is its flexibility and efficiency. by treating each disease as an independent task within a single
        model, it can generalize to pathology combinations not seen during training and is far more compu- tationally efficient than the
        binary class strategy. additionally, class1 class2 class3 masks overlapping masks segmentation outputsigmoidmodels images class1
        class2 class3fig. 3: multi-label segmentation. the model can learn shared features that may be relevant to multiple diseases,
        potentially improving overall performance. its complexity, however, lies in the training process, as it requires optimizing ntasks
        simultaneously. this demands rigorous gradient management and careful selection of the loss function to ensure balanced learning
        across all tasks. iv. e xperimental setup preliminary experiments were conducted on the public spider (spine imaging diagnostic
        extended resource) dataset [3]. it contains 447 t1 and t2-weighted mri series from 257 patients, collected from four different
        hospitals in the netherlands, with patient ages ranging from 18 to 95 years. the dataset is enriched with two types of expert-
        validated annotations: precise anatomical segmentations of vertebrae, intervertebral discs, and the spinal canal, alongside
        detailed radiological classifications for a spectrum of degen- erative changes, including disc herniation, spondylolisthesis, and
        modic changes. this simultaneous availability of segmen- tation masks and multi-pathology labels provides the essential ground
        truth required for our investigation into automated multi-pathology diagnosis. to evaluate the proposed strategies, we selected
        five state- of-the-art architectures for medical image segmentation, span- ning convolutional (cnn), hybrid, and transformer-based
        models. the cnn architectures include the u-net 3d [8], an extension of u-net for volumetric data, and the v-net [9], which
        integrates residual connections for deeper networks. as a hybrid approach, we used a u-net with a resnet-50 [11] encoder for more
        powerful feature extraction. finally, we explored transformer-based models: the unetr [7], which uses a transformer as an encoder
        to capture long-range spatial dependencies, and its evolution, the swin unetr [10], which employs the more efficient attention of
        the swin transformer to model global relationships. to optimize model training, we evaluated three distinct loss functions
        tailored for this task: the standard dice loss [9], a hybrid dice+focal loss [12], and the generalized dice loss [13].all
        experiments followed a standardized protocol using only t2-weighted mri scans. the dataset was partitioned into training (134
        scans), validation (34 scans), and test (42 scans) sets. to ensure reproducibility, all runs were initialized with a fixed random
        seed (42). for preprocessing, all mri volumes were intensity-scaled and resized to 32×192×192voxels using center cropping or
        zero-padding. all models were trained for 500 epochs using the adam optimizer with a learning rate of 1×10−4and a batch size of 8.
        performance was measured using the dice similarity coefficient (dsc). we report both the macro-average across classes, which
        assess performance at the class level; and the example-based average across voxels, which assess performance at the instance level
        [19]. v. c urrent state of the research in this stage of the research, we have processed and evalu- ated over 300 training and
        inference pipelines to systematically compare the three proposed strategies. the analysis of the obtained results has allowed us
        to draw important conclusions about the feasibility of each approach. a. preliminary results and discussion figure 4 provides a
        detailed comparison between the bi- nary class, multi-class, and multi-label strategies across all architecture-loss combinations.
        the multi-class strategy proved to be ineffective. due to the extreme class imbalance created by mapping 70 unique pathology
        combinations to distinct classes, the macro-average dsc scores were consis- tently below 0.15 for nearly all models. the poor
        performance confirms that this approach is not viable for this problem. consequently, it was excluded from further comparison. the
        results in figure 4(a) show a clear and significant finding: the multi-label strategy consistently outperforms the binary class
        baseline . the best multi-label configura- tions (v-net and swin unetr with dice loss) achieved a macro-average dsc of
        0.36and0.35. in contrast, the best- performing binary class model (unetr with dice/gdl) only reached a score of 0.34. this
        strongly suggests that training a single, unified model capable of learning shared features across pathologies is more effective
        than training specialized, isolated models. the example-based dsc results in figure 4(b) measure the model’s ability to predict
        the correct set of labels for each voxel. here, the performance gap narrows. the best binary class models achieved a score of
        0.39, while the best multi-label model was just behind at 0.38. this indicates that while the multi-label approach is superior at
        identifying pathologies at a macro level, the specialized single models remain competitive at identifying the precise combination
        of labels at a given location. our results confirm the efficacy of the multi-label strat- egy, which achieves superior performance
        with a single model, making it more computationally efficient and clinically practi- cal than the binary class approach. its
        success stems from the ability to learn shared representations. the swin unetr and (a) macro-average dsc (b) example-based dsc
        fig. 4: dsc results for the three proposed strategies across different models and loss functions. v-net architectures consistently
        performed best, especially with dice loss , confirming our approach’s robustness. b. next steps based on these results, the
        research has advanced to a second experimental phase to refine and validate our conclu- sions. we are currently utilizing random
        crops of dimension 32×192×192instead of a fixed center crop for training. fur- thermore, inference will be performed with a
        sliding window approach to generate full-size segmentation maps, aiming to improve the method’s clinical applicability. vi. c
        onclusion in this work-in-progress, we presented a systematic evalua- tion of three deep learning strategies for the challenging
        task of multi-pathology segmentation in lumbar spine mri. our preliminary results indicate that a multi-label segmentation
        strategy is significantly more effective and efficient than treating each disease independently or mapping combinations to unique
        classes. architectures like swin unetr andv-net , optimized with a dice loss , have shown the most promise. this study establishes
        a strong foundation for future re- search. our ongoing work involves exploring random crops for training and a sliding
        window-based inference, aiming to generate full-size segmentation maps of the scan and thus enhance the clinical applicability of
        our approach. the ultimate goal is to develop a validated, scalable, and clinically useful tool for automated spinal diagnosis.
        acknowledgment this research was supported by fapesp (grants 2023/17577-0 and 2024/22985-3) and cnpq (grants 315220/2023-6,
        420442/2023-5, and 444982/2024-8).references [1] g. mcnicoll, ”world population ageing 1950-2050,” popul. dev. rev. , pp. 814-816,
        2002. [2] m.g. fehlings et al., ”the aging of the global population: the changing epidemiology of disease and spinal disorders,”
        neurosurgery , pp. s1-s5, 2015. [3] j. w. van der graaf et al., “lumbar spine segmentation in mr images: a dataset and a public
        benchmark,” sci. data, vol. 11, no. 264, 2024. [4]˙i. altun et al., ”lss-unet: lumbar spinal stenosis semantic segmenta- tion
        using deep learning,” multimed. tools appl. , 82:41287-41305, 2023. [5] j. qian et al., ”lumbar disc herniation diagnosis using
        deep learning on mri,” j. radiat. res. appl. sci. , 17(3):100988, 2024. [6] r. windsor et al., ”spinenetv2: automated detection,
        labelling and radiological grading of clinical mr scans,” arxiv:2205.01683, 2022. [7] a. hatamizadeh et al., ”unetr: transformers
        for 3d medical image segmentation,” in wacv , pp. 1748-1758, 2022. [8] e. kerfoot et al., ”left-ventricle quantification using
        residual u-net,” in stacom , lncs 11395, pp. 371-380, 2019. [9] f. milletari et al., ”v-net: fully convolutional neural networks
        for volumetric medical image segmentation,” in 3dv, pp. 565-571, 2016. [10] a. hatamizadeh et al., ”swin unetr: swin transformers
        for semantic segmentation of brain tumors in mri images,” in brainles , lncs 12962, pp. 272-284, 2022. [11] k. he et al., ”deep
        residual learning for image recognition,” in cvpr , pp. 770-778, 2016. [12] t.-y . lin et al., ”focal loss for dense object
        detection,” in iccv , pp. 2980-2988, 2017. [13] c. h. sudre et al., ”generalised dice overlap as a deep learning loss function for
        highly unbalanced segmentations,” in dlmia, miccai wkshp. , pp. 240-248, 2017. [14] w. mbarki et al., ”a novel method based on
        deep learning for herniated lumbar disc segmentation,” in ic aset , pp. 394-399, 2020. [15] j. qian et al., ”lumbar disc
        herniation diagnosis using deep learning on mri,” j. radiat. res. appl. sci. , 17(3):100988, 2024. [16] q. pan et al.,
        ”automatically diagnosing disk bulge and disk hernia- tion...: method development study,” jmir med. inform. , 9(5):e14755, 2021.
        [17] y . chen et al., ”deep learning-based computer-aided diagnostic system for lumbar degenerative diseases classification using
        mri,” biomed. signal process. control , 109:108002, 2025. [18] y . wang et al., ”deep learning-driven diagnosis of multi-type
        vertebra diseases based on computed tomography images,” quant. imaging med. surg. , 14(1):800, 2023. [19] m.-l. zhang and z.-h.
        zhou, ”a review on multi-label learning algo- rithms,” ieee trans. knowl. data eng. , 26(8):1819-1837, 2013.
  > PALAVRAS-CHAVES:
    Não encontrado.
  > PROBLEMA:
    Score: 2.001
        multi-pathology segmentation of the lumbar spine claudio leite federal university of s ˜ao carlos (ufscar)jurandy almeida federal
        university of s ˜ao carlos (ufscar) abstract —the diagnosis of spinal pathologies is complex due to the frequent overlap of
        multiple diseases in the same anatomical location, a scenario that current segmentation or classification methods do not
        efficiently address. this work presents an empirical study on the segmentation of multiple overlapping pathologies, proposing and
        systematically comparing three strate- gies: (i) a baseline binary class approach using independent models; (ii) a multi-class
        approach mapping disease combinations to unique labels; and (iii) a multi-label approach using parallel channels to explicitly
        model co-occurrence. we evaluated over 300 training and inference pipelines, combining five neural network architectures and three
        loss functions. our preliminary results show that the multi-label strategy significantly outperforms the other approaches in both
        accuracy and computational efficiency, establishing a promising direction for developing robust, scalable diagnostic tools. i. i
        ntroduction low back pain is a leading cause of disability world- wide [2], and magnetic resonance imaging (mri) of the lumbar
        spine is a cornerstone for its diagnosis [1]. however, a central challenge in the automated analysis of these images is the
        semantic overlap of multiple classes, where a single intervertebral disc may simultaneously present with conditions like a
        herniation and disc narrowing—a scenario most current methods are not designed to handle. current deep learning methods for lumbar
        spine analysis typically follow two paths: single-disease segmentation [4], [5] or complex multi-stage classification pipelines
        [6]. the former ignores pathological co-occurrence, while the latter are often computationally inefficient and difficult to
        generalize. neither approach effectively handles the common clinical scenario of multiple, overlapping pathologies within a
        unified framework. to address this gap, this paper presents an ongoing, compre- hensive study on the segmentation of multiple
        pathologies in lumbar discs. we propose and compare three distinct strategies to manage diagnostic overlap. our goal is to
        determine the most effective and efficient strategy for simultaneously delin- eating and diagnosing multiple co-occurring
        conditions. the main contributions of this work in progress are: •the proposition of three strategies for the multi-diagnosis
        problem: (i) a binary class approach treating each pathol- ogy independently; (ii) a multi-class approach mapping disease
        combinations to unique and exclusive classes; and (iii) a multi-label approach, which explicitly models the coexistence of
        diagnoses in distinct binary channels. •a systematic comparative analysis with over 300 training and inference pipelines,
        evaluating five neural networks and three loss functions, establishing a reference bench- mark for this complex clinical
        scenario.•the demonstration that the proposed multi-label strategy offers a superior trade-off between accuracy and compu-
        tational cost, achieving performance comparable to the significantly more expensive binary approach. the rest of this work is
        organized as follows. section ii discusses related work. section iii presents our approaches to multi-pathology diagnosis. section
        iv describes the experi- mental setup. section v reports our results. finally, section vi offers our conclusions and directions
        for future work. ii. r elated work the literature on spinal imaging with deep learning is exten- sive. one significant branch of
        research focuses on segmenting symptomatic areas for a single pathology, such as lumbar spinal stenosis [4] or disc herniation
        [14], [15]. while effective for their specific tasks, these methods are inherently single-label and cannot address the frequent
        coexistence of multiple diseases. a second line of work aims to diagnose multiple diseases but typically relies on complex,
        multi-stage pipelines that sep- arate structure localization from classification [6], [16]. these fragmented approaches are often
        computationally expensive and difficult to generalize. although some recent works have explored multi-label classification of
        spinal pathologies [17], [18], they operate on an image or patch level, failing to provide the precise spatial localization that
        semantic segmentation offers. our work bridges this gap by proposing end-to-end segmentation frameworks explicitly designed to
        handle multi- pathology overlap. iii. o urapproaches to address the challenge of multi-pathology diagnosis, we propose and
        systematically evaluate three distinct seman- tic segmentation strategies. these strategies—binary class, multi-class, and
        multi-label segmentation—represent differ- ent conceptual frameworks for handling diagnostic overlap and are detailed in the
        following subsections. a. binary class segmentation the first strategy (figure 1), binary class segmentation , serves as our
        baseline and decomposes the complex multi- diagnosis problem into a series of independent binary segmen- tation tasks. in this
        formulation, a separate segmentation model is trained specifically for each of the pathologies analyzed. letx∈rd×h×wbe an input
        magnetic resonance imaging (mri) volume and p={p1, . . . , p n}be the set of npathologies. for each pathology pk∈ p, a
        corresponding class1 class2 class3 masks overlapping masks segmentation outputsigmoidmodels images class1 class2 class3fig. 1:
        binary class segmentation. binary ground truth mask yk∈ {0,1}d×h×windicates its location. the objective is to learn a set of
        nindependent models {mk}n k=1, where each model mk:rd×h×w→ [0,1]d×h×wis trained to predict the mask yk. the final diagnosis for
        the volume xis the collection of all nindividual predictions and can be expressed as: ˆyk=mk(x),fork= 1, . . . , n (1) where each
        predicted mask ˆykis generated by a model mk. the main advantage of this strategy is its simplicity and focus. by training a model
        for a single task (e.g., segmenting only disc herniation), the network can specialize in learning the unique visual features of
        that condition. this can lead to high performance for each individual disease and establishes a robust performance ceiling against
        which the other, more complex strategies can be compared. however, the drawback of this approach lies in its high computational
        cost and resource inefficiency. the need to train, validate, and store nindependent models multiplies the experimentation time and
        hardware demand. furthermore, in a clinical scenario, it would be necessary to run all these models on a single patient’s mri to
        obtain a complete diagnosis, making the process slow and cumbersome. this strategy also fails to learn any correlations that may
        exist between different diseases, treating each as an isolated event. b. multi-class segmentation the second strategy (figure 2),
        multi-class segmenta- tion, reformulates the multi-diagnosis problem into a non- overlapping multi-class segmentation task. the
        premise is to create a unique class identifier for every possible combination of pathologies that can occur in a specific
        intervertebral disc. letcobs⊆2pbe the set of munique pathology combina- tions observed in the dataset. we create a new ground
        truth mask y′∈ {0,1, . . . , m }d×h×w. for each intervertebral disc, all its voxels are assigned a single integer label c∈ {1, . .
        . , m }that uniquely identifies the specific combination of pathologies present, with c= 0for the background. the goal is class1
        class2 class3 masks segmentation outputsoftmaxmodels images class1 class2 class3 non-overlapping maskslabel transformationfig. 2:
        multi-class segmentation. to learn a single model m:rd×h×w→r(m+1)×d×h×w that performs standard multi-class over these fused
        labels. this operation can be expressed as: ˆy′=argmax c(m(x)) (2) where the model moutputs a probability distribution over the m+
        1 classes for each voxel, and the final prediction ˆy′is the class with the maximum probability. the main advantage of this
        approach is its conceptual simplicity, allowing standard deep learning architectures to be trained end-to-end. however, its
        primary drawback is the combinatorial explosion in the number of classes, which increases model complexity and exacerbates class
        imbalance, as many pathology combinations are extremely rare. in this study, the m= 70 classes observed in the dataset were used.
        c. multi-label segmentation the final and most flexible strategy is multi-label seg- mentation (figure 3), which directly
        addresses the problem of coexisting pathologies. in this formulation, each disease is treated as an independent, binary
        segmentation channel, allowing for multiple, overlapping predictions. let the ground truth be a tensor y∈ {0,1}n×d×h×w, where each
        channel ykis the binary mask for pathology pk∈ p . the objective is to learn a single model m: rd×h×w→[0,1]n×d×h×wthat takes an
        mri volume and outputs a tensor of nprobability maps, one for each pathology. the operation for this approach can be expressed as:
        {ˆy1,ˆy2, . . . , ˆyn}=m(x) (3) where a single model msimultaneously generates a set of n distinct prediction masks. the primary
        advantage of this strategy is its flexibility and efficiency. by treating each disease as an independent task within a single
        model, it can generalize to pathology combinations not seen during training and is far more compu- tationally efficient than the
        binary class strategy. additionally, class1 class2 class3 masks overlapping masks segmentation outputsigmoidmodels images class1
        class2 class3fig. 3: multi-label segmentation. the model can learn shared features that may be relevant to multiple diseases,
        potentially improving overall performance. its complexity, however, lies in the training process, as it requires optimizing ntasks
        simultaneously. this demands rigorous gradient management and careful selection of the loss function to ensure balanced learning
        across all tasks. iv. e xperimental setup preliminary experiments were conducted on the public spider (spine imaging diagnostic
        extended resource) dataset [3]. it contains 447 t1 and t2-weighted mri series from 257 patients, collected from four different
        hospitals in the netherlands, with patient ages ranging from 18 to 95 years. the dataset is enriched with two types of expert-
        validated annotations: precise anatomical segmentations of vertebrae, intervertebral discs, and the spinal canal, alongside
        detailed radiological classifications for a spectrum of degen- erative changes, including disc herniation, spondylolisthesis, and
        modic changes. this simultaneous availability of segmen- tation masks and multi-pathology labels provides the essential ground
        truth required for our investigation into automated multi-pathology diagnosis. to evaluate the proposed strategies, we selected
        five state- of-the-art architectures for medical image segmentation, span- ning convolutional (cnn), hybrid, and transformer-based
        models. the cnn architectures include the u-net 3d [8], an extension of u-net for volumetric data, and the v-net [9], which
        integrates residual connections for deeper networks. as a hybrid approach, we used a u-net with a resnet-50 [11] encoder for more
        powerful feature extraction. finally, we explored transformer-based models: the unetr [7], which uses a transformer as an encoder
        to capture long-range spatial dependencies, and its evolution, the swin unetr [10], which employs the more efficient attention of
        the swin transformer to model global relationships. to optimize model training, we evaluated three distinct loss functions
        tailored for this task: the standard dice loss [9], a hybrid dice+focal loss [12], and the generalized dice loss [13].all
        experiments followed a standardized protocol using only t2-weighted mri scans. the dataset was partitioned into training (134
        scans), validation (34 scans), and test (42 scans) sets. to ensure reproducibility, all runs were initialized with a fixed random
        seed (42). for preprocessing, all mri volumes were intensity-scaled and resized to 32×192×192voxels using center cropping or
        zero-padding. all models were trained for 500 epochs using the adam optimizer with a learning rate of 1×10−4and a batch size of 8.
        performance was measured using the dice similarity coefficient (dsc). we report both the macro-average across classes, which
        assess performance at the class level; and the example-based average across voxels, which assess performance at the instance level
        [19]. v. c urrent state of the research in this stage of the research, we have processed and evalu- ated over 300 training and
        inference pipelines to systematically compare the three proposed strategies. the analysis of the obtained results has allowed us
        to draw important conclusions about the feasibility of each approach. a. preliminary results and discussion figure 4 provides a
        detailed comparison between the bi- nary class, multi-class, and multi-label strategies across all architecture-loss combinations.
        the multi-class strategy proved to be ineffective. due to the extreme class imbalance created by mapping 70 unique pathology
        combinations to distinct classes, the macro-average dsc scores were consis- tently below 0.15 for nearly all models. the poor
        performance confirms that this approach is not viable for this problem. consequently, it was excluded from further comparison. the
        results in figure 4(a) show a clear and significant finding: the multi-label strategy consistently outperforms the binary class
        baseline . the best multi-label configura- tions (v-net and swin unetr with dice loss) achieved a macro-average dsc of
        0.36and0.35. in contrast, the best- performing binary class model (unetr with dice/gdl) only reached a score of 0.34. this
        strongly suggests that training a single, unified model capable of learning shared features across pathologies is more effective
        than training specialized, isolated models. the example-based dsc results in figure 4(b) measure the model’s ability to predict
        the correct set of labels for each voxel. here, the performance gap narrows. the best binary class models achieved a score of
        0.39, while the best multi-label model was just behind at 0.38. this indicates that while the multi-label approach is superior at
        identifying pathologies at a macro level, the specialized single models remain competitive at identifying the precise combination
        of labels at a given location. our results confirm the efficacy of the multi-label strat- egy, which achieves superior performance
        with a single model, making it more computationally efficient and clinically practi- cal than the binary class approach. its
        success stems from the ability to learn shared representations. the swin unetr and (a) macro-average dsc (b) example-based dsc
        fig. 4: dsc results for the three proposed strategies across different models and loss functions. v-net architectures consistently
        performed best, especially with dice loss , confirming our approach’s robustness. b. next steps based on these results, the
        research has advanced to a second experimental phase to refine and validate our conclu- sions. we are currently utilizing random
        crops of dimension 32×192×192instead of a fixed center crop for training. fur- thermore, inference will be performed with a
        sliding window approach to generate full-size segmentation maps, aiming to improve the method’s clinical applicability. vi. c
        onclusion in this work-in-progress, we presented a systematic evalua- tion of three deep learning strategies for the challenging
        task of multi-pathology segmentation in lumbar spine mri. our preliminary results indicate that a multi-label segmentation
        strategy is significantly more effective and efficient than treating each disease independently or mapping combinations to unique
        classes. architectures like swin unetr andv-net , optimized with a dice loss , have shown the most promise. this study establishes
        a strong foundation for future re- search. our ongoing work involves exploring random crops for training and a sliding
        window-based inference, aiming to generate full-size segmentation maps of the scan and thus enhance the clinical applicability of
        our approach. the ultimate goal is to develop a validated, scalable, and clinically useful tool for automated spinal diagnosis.
        acknowledgment this research was supported by fapesp (grants 2023/17577-0 and 2024/22985-3) and cnpq (grants 315220/2023-6,
        420442/2023-5, and 444982/2024-8).references [1] g. mcnicoll, ”world population ageing 1950-2050,” popul. dev. rev. , pp. 814-816,
        2002. [2] m.g. fehlings et al., ”the aging of the global population: the changing epidemiology of disease and spinal disorders,”
        neurosurgery , pp. s1-s5, 2015. [3] j. w. van der graaf et al., “lumbar spine segmentation in mr images: a dataset and a public
        benchmark,” sci. data, vol. 11, no. 264, 2024. [4]˙i. altun et al., ”lss-unet: lumbar spinal stenosis semantic segmenta- tion
        using deep learning,” multimed. tools appl. , 82:41287-41305, 2023. [5] j. qian et al., ”lumbar disc herniation diagnosis using
        deep learning on mri,” j. radiat. res. appl. sci. , 17(3):100988, 2024. [6] r. windsor et al., ”spinenetv2: automated detection,
        labelling and radiological grading of clinical mr scans,” arxiv:2205.01683, 2022. [7] a. hatamizadeh et al., ”unetr: transformers
        for 3d medical image segmentation,” in wacv , pp. 1748-1758, 2022. [8] e. kerfoot et al., ”left-ventricle quantification using
        residual u-net,” in stacom , lncs 11395, pp. 371-380, 2019. [9] f. milletari et al., ”v-net: fully convolutional neural networks
        for volumetric medical image segmentation,” in 3dv, pp. 565-571, 2016. [10] a. hatamizadeh et al., ”swin unetr: swin transformers
        for semantic segmentation of brain tumors in mri images,” in brainles , lncs 12962, pp. 272-284, 2022. [11] k. he et al., ”deep
        residual learning for image recognition,” in cvpr , pp. 770-778, 2016. [12] t.-y . lin et al., ”focal loss for dense object
        detection,” in iccv , pp. 2980-2988, 2017. [13] c. h. sudre et al., ”generalised dice overlap as a deep learning loss function for
        highly unbalanced segmentations,” in dlmia, miccai wkshp. , pp. 240-248, 2017. [14] w. mbarki et al., ”a novel method based on
        deep learning for herniated lumbar disc segmentation,” in ic aset , pp. 394-399, 2020. [15] j. qian et al., ”lumbar disc
        herniation diagnosis using deep learning on mri,” j. radiat. res. appl. sci. , 17(3):100988, 2024. [16] q. pan et al.,
        ”automatically diagnosing disk bulge and disk hernia- tion...: method development study,” jmir med. inform. , 9(5):e14755, 2021.
        [17] y . chen et al., ”deep learning-based computer-aided diagnostic system for lumbar degenerative diseases classification using
        mri,” biomed. signal process. control , 109:108002, 2025. [18] y . wang et al., ”deep learning-driven diagnosis of multi-type
        vertebra diseases based on computed tomography images,” quant. imaging med. surg. , 14(1):800, 2023. [19] m.-l. zhang and z.-h.
        zhou, ”a review on multi-label learning algo- rithms,” ieee trans. knowl. data eng. , 26(8):1819-1837, 2013.
  > CONTRIBUIÇÃO:
    Não encontrado.

4. RESUMO GERAL:
    multi-pathology segmentation of the lumbar spine claudio leite federal
    university of s ˜ao carlos (ufscar)jurandy almeida federal university of s ˜ao
    carlos (ufscar) abstract —the diagnosis of spinal pathologies is complex due to
    the frequent overlap of multiple diseases in the same anatomical location, a
    scenario that current segmentation or classification methods do not efficiently
    address. this work presents an empirical study on the segmentation of multiple
    overlapping pathologies, proposing and systematically comparing three strate-
    gies: (i) a baseline binary class approach using independent models; (ii) a
    multi-class approach mapping disease combinations to unique labels; and (iii) a
    multi-label approach using parallel channels to explicitly model co-occurrence.
    the main contributions of this work in progress are: •the proposition of three
    strategies for the multi-diagnosis problem: (i) a binary class approach treating
    each pathol- ogy independently; (ii) a multi-class approach mapping disease
    combinations to unique and exclusive classes; and (iii) a multi-label approach,
    which explicitly models the coexistence of diagnoses in distinct binary
    channels. this operation can be expressed as: ˆy′=argmax c(m(x)) (2) where the
    model moutputs a probability distribution over the m+ 1 classes for each voxel,
    and the final prediction ˆy′is the class with the maximum probability. finally,
    we explored transformer-based models: the unetr [7], which uses a transformer as
    an encoder to capture long-range spatial dependencies, and its evolution, the
    swin unetr [10], which employs the more efficient attention of the swin
    transformer to model global relationships. the best binary class models achieved
    a score of 0.39, while the best multi-label model was just behind at 0.38. this
    indicates that while the multi-label approach is superior at identifying
    pathologies at a macro level, the specialized single models remain competitive
    at identifying the precise combination of labels at a given location.

==================================================

--- ARTIGO: articles/Socially Responsible and Explainable Automated Fact-Checking and Hate Speech Detection.pdf ---

1. TOP 10 TERMOS:
    - hate           : 27
    - speech         : 26
    - language       : 21
    - research       : 16
    - nlp            : 14
    - social         : 14
    - detection      : 13
    - models         : 13
    - ai             : 12
    - fact           : 11

2. REFERÊNCIAS EXTRAÍDAS (18 total):
    [1] [1]aida mostafazadeh davani, mohammad atari, brendan kennedy, and morteza dehghani. 2023.
hate speech classifiers learn normative social stereotypes. transactions of the
association for computational linguistics 11 (2023), 300–319.
    [2] [2]thomas davidson, debasmita bhattacharya, and ingmar weber. 2019. racial bias in hate
speech and abusive language detection datasets. in proceedings of the 3rd workshop on
abusive language online . florence, italy, 25–35.
    [3] [3]michael hameleers, toni van der, and rens vliegenthart. 2022. civilized truths, hateful
lies? incivility and hate speech in false information – evidence from fact-checked
statements in the us. information, communication & society 25, 11 (2022), 1596–1613.
    [4] [4]cheng li, mengzhuo chen, jindong wang, sunayana sitaram, and xing xie. 2024.
culturellm: incorporating cultural differences into large language models. in advances in
neural information processing systems , vol. 37. 84799–84838.
    [5] [5]cheng li, damien teney, linyi yang, qingsong wen, xing xie, and jindong wang. 2025.
culturepark: boosting cross-cultural understanding in large language models. in
proceedings of the 38th international conference on neural information processing systems
(vancouver, bc, canada) (nips ’24) . red hook, ny, usa, article 2082, 34 pages.
    [6] [6]chandler may, alex wang, shikha bordia, samuel r. bowman, and rachel rudinger. 2019. on
measuring social biases in sentence encoders. in proceed- ings of the 2019 conference of
the north american chapter of the association for computational linguistics: human
language technologies , jill burstein, christy doran, and thamar solorio (eds.).
minneapolis, minnesota, 622–628.
    [7] [7]fabio poletto, valerio basile, manuela sanguinetti, cristina bosco, and viviana patti.
2021. resources and benchmark corpora for hate speech detection: a systematic review.
language resources and evaluation 55, 3 (2021), 477–523.
    [8] [8]isadora salles, francielle vargas, and fabrício benevenuto. 2025. hatebrxplain: a
benchmark dataset with human-annotated rationales for explainable hate speech detection in
brazilian portuguese. in proceedings of the 31st international conference on computational
linguistics . abu dhabi, uae, 6659–6669.
    [9] [9]henri tajfel. 1979. an integrative theory of intergroup conflict. the social psychology
of intergroup relations/brooks/cole (1979).
    [10] [10] yulia tsvetkov, vinodkumar prabhakaran, and rob voigt. 2019. socially respon- sible
natural language processing. in companion proceedings of the 2019 world wide web
conference (san francisco, usa) (www ’19) . new york, usa, 1326.
    [11] [11] francielle vargas, isabelle carvalho, ali hürriyetoğlu, thiago pardo, and fabrício
benevenuto. 2023. socially responsible hate speech detection: can classifiers reflect
social stereotypes?. in proceedings of the 14th international conference on recent
advances in natural language processing . varna, bulgaria, 1187–1196.
    [12] [12] francielle vargas, isabelle carvalho, thiago pardo, and fabricio benevenuto. 2024.
context-aware and expert data resources for brazilian portuguese hate speech detection.
natural language processing (2024), 1–22.
    [13] [13] francielle vargas, isabelle carvalho, fabiana rodrigues de góes, thiago pardo, and
fabrício benevenuto. 2022. hatebr: a large expert annotated corpus of brazilian instagram
comments for offensive language and hate speech detec- tion. in proceedings of the 13th
language resources and evaluation conference . marseille, france, 7174–7183.
    [14] [14] francielle vargas, samuel guimarães, shamsuddeen hassan muhammad, diego alves,
ibrahim said ahmad, idris abdulmumin, diallo mohamed, thiago pardo, and fabrício
benevenuto. 2024. hausahate: an expert annotated corpus for hausa hate speech detection.
in proceedings of the 8th workshop on online abuse and harms . mexico city, mexico, 52–58.
    [15] [15] francielle vargas, kokil jaidka, thiago pardo, and fabrício benevenuto. 2023.
predicting sentence-level factuality of news and bias of media outlets. in proceedings of
the 14th international conference on recent advances in natural language processing .
varna, bulgaria, 1197–1206.
    [16] [16] francielle vargas, fabiana rodrigues de góes, isabelle carvalho, fabrício ben-
evenuto, and thiago pardo. 2021. contextual-lexicon approach for abusive language
detection. in proceedings of the international conference on recent advances in natural
language processing . held online, 1438–1447.
    [17] [17] francielle vargas, isadora salles, diego alves, ameeta agrawal, thiago a. s. pardo,
and fabrício benevenuto. 2024. improving explainable fact-checking via sentence-level
factual reasoning. in proceedings of the 7th fact extraction and verification workshop .
miami, usa, 192–204.
    [18] [18] claire wardle. 2024. a conceptual analysis of the overlaps and differences between
hate speech, misinformation and disinformation . department of peace operations (dpo).
office of the special adviser on the prevention of genocide (osapg). united nations.26

3. PARÁGRAFOS RELEVANTES (TOP-1):
  > OBJETIVO:
    Não encontrado.
  > PALAVRAS-CHAVES:
    Não encontrado.
  > PROBLEMA:
    Não encontrado.
  > CONTRIBUIÇÃO:
    Não encontrado.

4. RESUMO GERAL:
    specifically, we introduced five benchmark datasets (hatebr [ 13], hatebrxplain
    [8], hausahate [ 14], factnews [ 15], and mol [ 12]) and developed four novel
    post-hoc and self-explaining methods (selfar [ 17], ssa [11], b+m [ 16] and sra)
    to ensure that both the data and the mod- els used to tackle misinformation and
    hate speech are explainable and mitigate bias. 3 awards & grants this work has
    been widely recognized with multiple awards and grants, including the maria
    carolina monard award in ai (2025), finalist for the sbc thesis award (2025),
    google lara award fellowship (2024), and acl travel grants (emnlp, naacl
    2024).25 ctd’2025, rio de janeiro/rj, brasil vargas et al. 4 research impact
    several prestigious research institutions, including universities and industry
    centers, have been significantly influenced by the provided resources of the
    thesis, as reflected in a substantial number of ci- tations. i was also invited
    to serve on the organizing committee for the international conference on web and
    social media (icwsm) in 2021, 2022, and 2023, as well as the acl workshop on
    online abuse and harms (woah) and the ijcnn special session explainable deep
    neural networks for responsible ai (deepxplain) in 2025. lastly, i have been an
    active participant in the program committee for several top-tier nlp conferences
    and workshops, including acl, emnlp, naacl, lrec, coling, woah, fever, and codi.
    the impact of this research contribut- ing directly to foundational topics in
    multimedia, hypermedia and web, including: (i) benchmarking for future research
    : the datasets created in this thesis (e.g. hatebr, hatebrxplain, hausa- hate,
    mol, and factnews) establish new benchmarks in automated fact-checking and hate
    speech classification for portuguese and hausa languages, enabling future
    studies to compare and refine models; (ii) advancements in explainable ai (xai)
    : this thesis pioneers novel methods that enhance interpretability in nlp (e.g.,
    b+m, sra and selfar). by introducing new explainability mecha- nisms, it sets a
    new standard for developing ethical and transparent ai systems; (iii) bias
    mitigation in nlp : this research provides innovative solutions to mitigate
    biases in nlp models (e.g., ssa method) influencing subfields such as
    fairness-aware machine learn- ing and computational social science; (iv)
    low-resource language processing : by developing datasets and models for
    portuguese and other underrepresented languages, such as hausa, an african
    indigenous language, this work expands the scope of nlp beyond english, making
    nlp technologies more inclusive and globally ap- plicable; (v) positive social
    impact in real-world applications : the resources introduced in this thesis have
    already been adopted by prestigious research institutions worldwide, including
    microsoft research, which has used the hatebr dataset to train two llms:
    culturellm [ 4] and culturepark [ 5], demonstrating its clear rele- vance and
    practical applicability. finally, the methods and systems developed in this
    research may be applied for patents and registered systems with copyrights.6
    publications in total, 15 (fifteen) papers were published in top-tier
    international nlp and ai conferences and journals, including 10 (ten) in qualis
    a1 and 5 (five) in qualis a3 venues: https://franciellevargas.github.io/.

==================================================

--- ARTIGO: articles/Superpixel Segmentation Effect on Hierarchical GNN applied to Image Classification.pdf ---

1. TOP 10 TERMOS:
    - graph          : 60
    - image          : 51
    - superpixel     : 41
    - slic           : 34
    - hierarchical   : 32
    - helmnet        : 30
    - classification : 29
    - j              : 28
    - disf           : 27
    - based          : 26

2. REFERÊNCIAS EXTRAÍDAS (24 total):
    [1] [1] f. scarselli, m. gori, a. c. tsoi, m. hagenbuchner, and g. monfardini, “the graph
neural network model,” ieee transactions on neural networks , vol. 20, no. 1, pp. 61–80,
2009.
    [2] [2] v . p. dwivedi, c. k. joshi, a. t. luu, t. laurent, y . bengio, and x. bresson,
“benchmarking graph neural networks,” j. mach. learn. res., vol. 24, no. 1, jan. 2023.
    [3] [3] j. p. o. batisteli, s. j. f. guimar ˜aes, and z. k. g. do patroc ´ınio j ´unior,
“multi-scale image graph representation: a novel gnn approach for image classification
through scale importance estimation,” in ieee international symposium on multimedia (ism)
, 2023.
    [4] [4] j. p. o. batisteli, s. j. f. guimar ˜aes, and z. k. g. patroc ´ınio, jr, “hierarchical
graph neural networks with scale-aware readout for image classification,” international
journal of semantic computing , vol. 18, no. 04, pp. 713–738, 2024.
    [5] [5] j. p. o. batisteli, s. j. f. guimar ˜aes, and z. k. g. do patroc ´ınio j ´unior,
“hierarchical layered multigraph network with scale importance estima- tion for image
classification,” applied soft computing , 2025, submitted.
    [6] [6] p. h. avelar, a. r. tavares, t. l. da silveira, c. r. jung, and l. c. lamb,
“superpixel image classification with graph attention networks,” in 33rd sibgrapi
conference on graphics, patterns and images (sibgrapi) , 2020, pp. 203–209.
    [7] [7] v . vasudevan, m. bassenne, m. t. islam, and l. xing, “image classifi- cation using
graph neural network and multiscale wavelet superpixels,” pattern recognition letters ,
vol. 166, pp. 89–96, 2023.
    [8] [8] j. rodrigues and j. carbonera, “graph convolutional networks for image classification:
comparing approaches for building graphs from images,” inproceedings of the 26th
international conference on enterprise information systems-volume 1: iceis , 2024, pp.
437–446.
    [9] [9] k. li, d. detone, y . f. s. chen, m. v o, i. reid, h. rezatofighi, c. sweeney, j.
straub, and r. newcombe, “odam: object detection, association, and mapping using posed rgb
video,” in proceedings of the ieee/cvf international conference on computer vision , 2021,
pp. 5998–6008.
    [10] [10] m. khademi and o. schulte, “deep generative probabilistic graph neural networks for
scene graph generation,” in proceedings of the aaai conference on artificial intelligence
, vol. 34, no. 07, 2020, pp. 11 237– 11 245.
    [11] [11] w. liang, y . jiang, and z. liu, “graghvqa: language-guided graph neural networks for
graph-based visual question answering,” in proceed- ings of the third workshop on
multimodal artificial intelligence , jun. 2021, pp. 79–86.
    [12] [12] r. achanta, a. shaji, k. smith, a. lucchi, p. fua, and s. s ¨usstrunk, “slic
superpixels compared to state-of-the-art superpixel methods,” ieee transactions on pattern
analysis and machine intelligence , vol. 34, no. 11, pp. 2274–2282, 2012.
    [13] [13] f. c. bel ´em, s. j. f. guimar ˜aes, and a. x. falc ˜ao, “superpixel segmentation
using dynamic and iterative spanning forest,” ieee signal processing letters , vol. 27,
pp. 1440–1444, 2020.
    [14] [14] d. stutz, a. hermans, and b. leibe, “superpixels: an evaluation of the
state-of-the-art,” computer vision and image understanding , vol. 166, pp. 1–27, 2018.
    [15] [15] i. b. barcelos, f. d. c. bel ´em, l. d. m. jo ˜ao, z. k. g. d. patroc ´ınio, a. x.
falc ˜ao, and s. j. f. guimar ˜aes, “a comprehensive review and new taxonomy on superpixel
segmentation,” acm comput. surv. , vol. 56, no. 8, apr. 2024.
    [16] [16] b. knyazev, x. lin, m. amer, and g. taylor, “image classification with hierarchical
multigraph networks,” in proceedings of the british machine vision conference (bmvc) ,
2019, pp. 223.1–223.13.
    [17] [17] m. munir, w. avery, m. m. rahman, and r. marculescu, “greedyvig: dynamic axial graph
construction for efficient vision gnns,” in pro- ceedings of the ieee/cvf conference on
computer vision and pattern recognition , 2024, pp. 6118–6127.
    [18] [18] k. han, y . wang, j. guo, y . tang, and e. wu, “vision gnn: an image is worth graph
of nodes,” in proceedings of the 36th international conference on neural information
processing systems , ser. nips ’22. red hook, ny , usa: curran associates inc., 2022.
    [19] [19] g. nikolentzos, m. thomas, a. r. rivera, and m. vazirgiannis, “im- age classification
using graph-based representations and graph neural networks,” in complex networks & their
applications ix: volume 2, proceedings of the ninth international conference on complex
networks and their applications , 2021, pp. 142–153.
    [20] [20] r. a. cosma, l. knobel, p. van der linden, d. m. knigge, and e. j. bekkers,
“geometric superpixel representations for efficient image clas- sification with graph
neural networks,” in proceedings of the ieee/cvf international conference on computer
vision , 2023, pp. 109–118.
    [21] [21] j. long, z. yan, and h. chen, “a graph neural network for superpixel image
classification,” journal of physics: conference series , vol. 1871, no. 1, p. 012071, apr
2021.
    [22] [22] j. cousty and l. najman, “incremental algorithm for hierarchical minimum spanning
forests and saliency of watershed cuts,” in ismm , 2011, pp. 272–283.
    [23] [23] f. c. bel ´em, b. perret, j. cousty, s. j. f. guimar ˜aes, and a. x. falc ˜ao,
“towards a simple and efficient object-based superpixel delineation framework,” in 2021
34th sibgrapi conference on graphics, patterns and images (sibgrapi) , 2021, pp. 346–353.
    [24] [24] r. giraud, v .-t. ta, and n. papadakis, “scalp: superpixels with contour adherence
using linear path,” in 2016 23rd international conference on pattern recognition (icpr) ,
2016, pp. 2374–2379.

3. PARÁGRAFOS RELEVANTES (TOP-1):
  > OBJETIVO:
    Não encontrado.
  > PALAVRAS-CHAVES:
    Não encontrado.
  > PROBLEMA:
    Não encontrado.
  > CONTRIBUIÇÃO:
    Não encontrado.

4. RESUMO GERAL:
    as these algorithms offer distinct characteristics and superpixel aspects, this
    work-in- progress presents a study on the performance of the hierarchical
    layered multigraph network (helmnet) according to the variation of superpixel
    methods used to generate the base graph of the hierarchical layered multigraph
    (helm) representation with images from the stl-10 dataset. this arises as a
    necessity because there is no clear guideline for selecting the segmentation
    method, as methods may perform differently on distinct tasks and may even be
    influenced by the nature of the images in the training dataset [15]. however, in
    the context of image classification with graph neural networks (gnns), the
    performance documen- tation for most of these methods is non-existent, and many
    works are limited to the application of the slic method [6], [7], [16], [20],
    [21], thanks to its broad availability and fast execution [12]. e xperimental
    setup this section presents the stl-10 dataset and discusses the superpixel
    method selection to expand the work done in [5] with a brief commentary on the
    reason for choosing to use each method alongside its computational complexity,
    when provided by the authors. this result suggests two hypotheses: (i) the lower
    compactness provided by the disf method is more suitable for image
    classification, as it allows a finer alignment with image boundaries; and (ii)
    even with an overall lowertable ii comparison with state -of-the-art gnn methods
    on the stl-10 dataset .†indicates the target number of nodes because the average
    value was not reported , ’—’ denotes not reported data ,and ’×’stands for not
    applicable . to match helm’s properties, for example, methods classified within
    the hierarchy-based class would signify a prudent conceptual choice to be
    thought into this research in the future.acknowledgment the authors thank the
    pontif ´ıcia universidade cat ´olica de minas gerais – puc-minas, coordenac ¸
    ˜ao de aperfeic ¸oamento de pessoal de n ´ıvel superior – capes – (capes stic-
    amsud 88887.878869/2023-00, 23-stic-10 and finance code 001), the conselho
    nacional de desenvolvimento cient ´ıfico e tecnol ´ogico – cnpq (grants
    407242/2021-0, 306573/2022-9, 442950/2023-3) and fundac ¸ ˜ao de apoio `a
    pesquisa do estado de minas gerais – fapemig (grant apq- 01079-23, apq-05058-23
    and pce-00301-25).

==================================================

--- ARTIGO: articles/Symmetry Shape Analysis.pdf ---

1. TOP 10 TERMOS:
    - symmetry       : 126
    - et             : 59
    - al             : 59
    - vol            : 51
    - pp             : 51
    - symmetries     : 48
    - detection      : 42
    - based          : 38
    - j              : 33
    - computer       : 31

2. REFERÊNCIAS EXTRAÍDAS (80 total):
    [1] [1] m. li, f. c. langbein, and r. r. martin, “detecting approximate symmetries of discrete
point subsets,” comput. aided des. , vol. 40, no. 1, pp. 76–93, jan. 2008.
    [2] [2] m. chang and s. c. park, “reverse engineering of a symmetric object,” computers &
industrial engineering , vol. 55, no. 2, pp. 311–320, 2008.
    [3] [3] j. jiang, z. chen, and k. he, “a feature-based method of rapidly detecting global
exact symmetries in {cad }models,” computer-aided design , vol. 45, no. 8–9, pp.
1081–1094, 2013.
    [4] [4] k. li, g. foucault, j.-c. l ´eon, and m. trlin, “fast global and partial reflective
symmetry analyses using boundary surfaces of mechanical components,” computer-aided design
, vol. 53, pp. 70–89, 2014.
    [5] [5] a. mu, z. liu, g. duan, and j. tan, “structural regularity detection and enhancement
for surface mesh reconstruction in reverse engineering,” computer-aided design , vol. 177,
p. 103780, 2024.
    [6] [6] a. cohen, c. zach, s. sinha, and m. pollefeys, “discovering and ex- ploiting 3d
symmetries in structure from motion,” in cvpr . computer vision and patter recognition,
june 2012.
    [7] [7] d. ceylan, n. j. mitra, y . zheng, and m. pauly, “coupled structure- from-motion and
3d symmetry detection for urban facades,” acm trans. graph. , vol. 33, no. 1, pp.
2:1–2:15, feb. 2014.
    [8] [8] r. p. de figueiredo, p. moreno, and a. bernardino, “efficient pose estimation of
rotationally symmetric objects,” neurocomputing , vol. 150, part a, pp. 126–135, 2015.
    [9] [9] s. wu, c. rupprecht, and a. vedaldi, “unsupervised learning of probably symmetric
deformable 3d objects from images in the wild,” in proceedings of the ieee conference on
computer vision and pattern recognition (cvpr) , 2020.
    [10] [10] q. liao, x. jin, and w. zeng, “enhancing the symmetry and propor- tion of 3d face
geometry,” ieee transactions on visualization and computer graphics , vol. 18, no. 10, pp.
1704–1716, 2012.
    [11] [11] k. son, e. almeida, and d. cooper, “axially symmetric 3d pots config- uration system
using axis of symmetry and break curve,” in computer vision and pattern recognition
(cvpr), 2013 ieee conference on , june 2013, pp. 257–264.
    [12] [12] b. xia, b. ben amor, h. drira, m. daoudi, and l. ballihi, “gender and 3d facial
symmetry: what’s the relationship?” in automatic face and gesture recognition (fg), 2013
10th ieee international conference and workshops on , april 2013, pp. 1–6.
    [13] [13] g. harary, a. tal, and e. grinspun, “context-based coherent surface completion,” acm
trans. graph. , vol. 33, no. 1, pp. 5:1–5:12, feb. 2014.
    [14] [14] e. li, x. zhang, and y . chen, “symmetry based chinese ancient architecture
reconstruction from incomplete point cloud,” in digital home (icdh), 2014 5th
international conference on , nov 2014, pp. 157–161.
    [15] [15] i. sipiran, r. gregor, and t. schreck, “approximate symmetry detection in partial 3d
meshes,” comput. graph. forum , vol. 33, no. 7, pp. 131– 140, oct. 2014.
    [16] [16] s. mansouri and h. ebrahimnezhad, “efficient axial symmetry aware mesh approximation
with application to 3d pottery models,” multimedia tools and applications , pp. 1–33,
2015.
    [17] [17] p. mavridis, i. sipiran, a. andreadis, and g. papaioannou, “object completion using
k-sparse optimization,” computer graphics forum , vol. 34, no. 7, pp. 13–21, 2015.
    [18] [18] w. shui and f. gao, “a geometric completion and shape analysis method for damaged
bilaterally symmetrical artifacts,” journal of cultural heritage , vol. 52, pp. 118–127,
2021.
    [19] [19] j. xu, w. cao, b. liu, and k. jiang, “object restoration based on extrinsic
reflective symmetry plane detection,” vis. comput. , vol. 38, no. 11, p. 3627–3642, nov.
2022.
    [20] [20] w. shui, p. wei, x. zheng, and s. geng, “a landmark-free approach for surface
asymmetry detection and profile drawings from bilaterally symmetrical geometry,” j.
comput. cult. herit. , vol. 16, no. 2, jun. 2023.
    [21] [21] i. sipiran, “the role of computing in the study of latin american cultural heritage,”
commun. acm , vol. 67, no. 8, p. 58–62, aug. 2024.
    [22] [22] w. qiu, j. yuan, e. ukwatta, y . sun, m. rajchl, and a. fenster, “prostate
segmentation: an efficient convex optimization approach with axial symmetry using 3-d trus
and mr images,” medical imaging, ieee transactions on , vol. 33, no. 4, pp. 947–960, april
2014.
    [23] [23] j. yuan, w. qiu, m. rajchl, e. ukwatta, x.-c. tai, and a. fenster, “efficient 3d
endfiring trus prostate segmentation with globally optimized rotational symmetry,” 2014
ieee conference on computer vision and pattern recognition , vol. 0, pp. 2211–2218, 2013.
    [24] [24] j. fotouhi, g. taylor, m. unberath, a. johnson, s. c. lee, g. osgood, m. armand, and
n. navab, “exploring partial intrinsic and extrinsic symmetry in 3d medical imaging,”
medical image analysis , vol. 72, p. 102127, 2021.
    [25] [25] j. li, k. xu, s. chaudhuri, e. yumer, h. zhang, and l. guibas, “grass: generative
recursive autoencoders for shape structures,” acm trans. graph. , vol. 36, no. 4, jul.
2017.
    [26] [26] c. zhu, k. xu, s. chaudhuri, r. yi, and h. zhang, “scores: shape composition with
recursive substructure priors,” acm trans. graph. , vol. 37, no. 6, dec. 2018.
    [27] [27] k. mo, p. guerrero, l. yi, h. su, p. wonka, n. j. mitra, and l. j. guibas,
“structurenet: hierarchical graph networks for 3d shape generation,” acm trans. graph. ,
vol. 38, no. 6, nov. 2019.
    [28] [28] j. li, c. niu, and k. xu, “learning part generation and assembly for structure-aware
shape synthesis,” in the thirty-fourth aaai conference on artificial intelligence, aaai
2020, the thirty-second innovative applications of artificial intelligence conference,
iaai 2020, the tenth aaai symposium on educational advances in artificial intelligence,
eaai 2020, new york, ny, usa, february 7-12, 2020 . aaai press, 2020, pp. 11 362–11 369.
    [29] [29] y . he, q. fang, z. zhang, t. dai, k. wu, l. liu, and x.-m. fu, “symmetric piecewise
developable approximations,” computer graph- ics forum , vol. 43, no. 7, p. e15242, 2024.
    [30] [30] a. martinet, c. soler, n. holzschuch, and f. x. sillion, “accurate detection of
symmetries in 3d shapes,” acm trans. graph. , vol. 25, no. 2, pp. 439–464, apr. 2006.
    [31] [31] b. li, h. johan, y . ye, and y . lu, “efficient view-based 3d reflection symmetry
detection,” in siggraph asia 2014 creative shape mod- eling and design , ser. sa ’14. new
york, ny , usa: acm, 2014, pp. 2:1–2:8.
    [32] [32] c. grushko, d. raviv, and r. kimmel, “intrinsic local symmetries: a computational
framework,” in proceedings of the 5th eurographics conference on 3d object retrieval ,
ser. eg 3dor’12. aire-la-ville, switzerland, switzerland: eurographics association, 2012,
pp. 33–38.
    [33] [33] r. kakarala, p. kaliamoorthi, and v . premachandran, “three- dimensional bilateral
symmetry plane estimation in the phase do- main,” in computer vision and pattern
recognition (cvpr), 2013 ieee conference on , june 2013, pp. 249–256.
    [34] [34] m. ovsjanikov, q. m ´erigot, v . p ˘atr˘aucean, and l. guibas, “shape matching via
quotient spaces,” in proceedings of the eleventh eu- rographics/acmsiggraph symposium on
geometry processing , ser. sgp ’13. aire-la-ville, switzerland, switzerland: eurographics
asso- ciation, 2013, pp. 1–11.
    [35] [35] z. zhang, k. yin, and k. w. c. foong, “symmetry robust descriptor for non-rigid
surface matching.” comput. graph. forum , vol. 32, no. 7, pp. 355–362, 2013.
    [36] [36] x. jiang, j. sun, and l. guibas, “a fourier-theoretic approach for inferring
symmetries,” comput. geom. theory appl. , vol. 47, no. 2, pp. 164–174, feb. 2014.
    [37] [37] h. wang, p. simari, z. su, and h. zhang, “spectral global intrinsic symmetry
invariant functions,” in proceedings of graphics interface 2014 , ser. gi ’14. toronto,
ont., canada, canada: canadian information processing society, 2014, pp. 209–215.
    [38] [38] x. liu, s. li, r. liu, j. wang, h. wang, and j. cao, “properly constrained
orthonormal functional maps for intrinsic symmetries,” computers & graphics , vol. 46, pp.
198–208, 2015, shape modeling international 2014.
    [39] [39] t. liu, v . g. kim, and t. funkhouser, “finding surface correspon- dences using
symmetry axis curves,” comp. graph. forum , vol. 31, no. 5, pp. 1607–1616, aug. 2012.
    [40] [40] v . g. kim, y . lipman, and t. funkhouser, “blended intrinsic maps,” acm trans.
graph. , vol. 30, no. 4, pp. 79:1–79:12, jul. 2011.
    [41] [41] a. tevs, q. huang, m. wand, h.-p. seidel, and l. guibas, “relat- ing shapes via
geometric symmetries and regularities,” acm trans. graph. , vol. 33, no. 4, pp.
119:1–119:12, jul. 2014.
    [42] [42] n. mitra, a. bronstein, and m. bronstein, “intrinsic regularity detec- tion in 3d
geometry,” in computer vision – eccv 2010 , ser. lecture notes in computer science, k.
daniilidis, p. maragos, and n. paragios, eds. springer berlin heidelberg, 2010, vol. 6313,
pp. 398–410.
    [43] [43] d. raviv, a. m. bronstein, m. m. bronstein, and r. kimmel, “full and partial
symmetries of non-rigid shapes,” int. j. comput. vision , vol. 89, no. 1, pp. 18–39, aug.
2010.
    [44] [44] d. raviv, m. m. bronstein, g. sapiro, a. m. bronstein, and r. kimmel, “diffusion
symmetries of non-rigid shapes,” in in proc. 3dpvt , 2010.
    [45] [45] a. berner, m. wand, n. j. mitra, d. mewes, and h. seidel, “shape analysis with
subspace symmetries,” comput. graph. forum , vol. 30, no. 2, pp. 277–286, 2011.
    [46] [46] y . wang, k. xu, j. li, h. zhang, a. shamir, l. liu, z. cheng, and y . xiong,
“symmetry hierarchy of man-made objects,” comput. graph. forum , vol. 30, no. 2, pp.
287–296, 2011.
    [47] [47] a. shehu, a. brunton, s. wuhrer, and m. wand, “characterization of partial intrinsic
symmetries,” in computer vision - eccv 2014 workshops , ser. lecture notes in computer
science, l. agapito, m. m. bronstein, and c. rother, eds. springer international
publishing, 2015, vol. 8928, pp. 267–282.
    [48] [48] y . yoshiyasu, e. yoshida, k. yokoi, and r. sagawa, “symmetry-aware nonrigid matching
of incomplete 3d surfaces,” in computer vision and pattern recognition (cvpr), 2014 ieee
conference on , june 2014, pp. 4193–4200.
    [49] [49] r. nagar, “robust extrinsic symmetry estimation in 3d point clouds,” vis. comput. ,
vol. 41, no. 1, p. 115–128, mar. 2024.
    [50] [50] b. tosyalı and y . sahillio ˘glu, “intrinsic reflective symmetry axis curve
generation for meshes,” in proceedings of computer graphics inter- national 2025 . new
york, ny , usa: association for computing machinery, 2025.
    [51] [51] y . lipman, x. chen, i. daubechies, and t. funkhouser, “symmetry factored embedding
and distance,” acm trans. graph. , vol. 29, no. 4, pp. 103:1–103:12, jul. 2010.
    [52] [52] w. jiang, k. xu, z.-q. cheng, and h. zhang, “skeleton-based intrinsic symmetry
detection on point clouds,” graphical models , vol. 75, no. 4, pp. 177–188, 2013.
    [53] [53] n. j. mitra, l. j. guibas, and m. pauly, “partial and approximate symmetry detection
for 3d geometry,” acm trans. graph. , vol. 25, no. 3, pp. 560–568, jul. 2006.
    [54] [54] m. pauly, n. j. mitra, j. wallner, h. pottmann, and l. j. guibas, “discovering
structural regularity in 3d geometry,” acm trans. graph. , vol. 27, no. 3, 2008.
    [55] [55] q. zheng, a. sharf, g. wan, y . li, n. j. mitra, d. cohen-or, and b. chen, “non-local
scan consolidation for 3d urban scenes,” acm trans. graph. , vol. 29, no. 4, pp.
94:1–94:9, jul. 2010.
    [56] [56] k. xu, h. zhang, w. jiang, r. dyer, z. cheng, l. liu, and b. chen, “multi-scale
partial intrinsic symmetry detection,” acm trans. graph. , vol. 31, no. 6, pp.
181:1–181:11, nov. 2012.
    [57] [57] s. korman, r. litman, s. avidan, and a. bronstein, “probably ap- proximately
symmetric: fast rigid symmetry detection with global guarantees,” comput. graph. forum ,
vol. 34, no. 1, pp. 2–13, feb. 2015.
    [58] [58] r. nagar and s. raman, “detecting approximate reflection symmetry in a point set
using optimization on manifold,” ieee transactions on signal processing , vol. 67, no. 6,
pp. 1582–1595, 2019.
    [59] [59] a. c. pablo speciale, martin r. oswald and m. pollefeys, “a symmetry prior for convex
variational 3d reconstruction,” in european conference on computer vision (eccv) , 2016.
    [60] [60] a. ecins, c. ferm ¨uller, and y . aloimonos, “detecting reflectional symmetries in 3d
data through symmetrical fitting,” in 2017 ieee international conference on computer
vision workshops (iccvw) , 2017, pp. 1779–1783.
    [61] [61] m. cicconet, d. g. c. hildebrand, and h. elliott, “finding mirror symmetry via
registration and optimal symmetric pairwise assignment of curves,” in 2017 ieee
international conference on computer vision workshops (iccvw) , 2017, pp. 1749–1758.
    [62] [62] r. nagar and s. raman, “3dsymm: robust and accurate 3d reflection symmetry
detection,” pattern recognition , vol. 107, p. 107483, 2020.
    [63] [63] l. hruda, i. kolingerov ´a, m. l ´aviˇcka, and m. ma ˇn´ak, “rotational symmetry
detection in 3d using reflectional symmetry candidates and quaternion-based rotation
parameterization,” computer aided geometric design , vol. 98, p. 102138, 2022.
    [64] [64] t. p. nguyen and t. t. nguyen, “robust detectors of rotationally symmetric shapes
based on novel semi-shape signatures,” pattern recog- nition , vol. 138, p. 109336, 2023.
    [65] [65] m. bizzarri, l. hruda, m. l ´aviˇcka, and j. vr ˇsek, “symmetry group detection of
point clouds in 3d via a decomposition method,” computer aided geometric design , vol.
113, p. 102376, 2024.
    [66] [66] s. bu, p. han, z. liu, j. han, and h. lin, “local deep feature learning framework for
3d shapes,” computers and graphics , vol. 46, pp. 117– 129, 2015, shape modeling
international 2014.
    [67] [67] p. ji and x. liu, “a fast and efficient 3d reflection symmetry detector based on
neural networks,” multimedia tools and applications , vol. 78, pp. 35 471 – 35 492, 2019.
    [68] [68] l. gao, l. x. zhang, h. y . meng, y . h. ren, y . k. lai, and l. kobbelt, “prs-net:
planar reflective symmetry detection net for 3d models,” ieee transactions on
visualization and computer graphics , pp. 1–1, 2020.
    [69] [69] y . shi, j. huang, h. zhang, x. xu, s. rusinkiewicz, and k. xu, “sym- metrynet:
learning to predict reflectional and rotational symmetries of 3d shapes from single-view
rgb-d images,” acm trans. graph. , vol. 39, no. 6, nov. 2020.
    [70] [70] y . shi, x. xu, j. xi, x. hu, d. hu, and k. xu, “learning to detect 3d symmetry from
single-view rgb-d images with weak supervision,” ieee transactions on pattern analysis and
machine intelligence , vol. 45, no. 4, pp. 4882–4896, 2023.
    [71] [71] r.-w. li, l.-x. zhang, c. li, y .-k. lai, and l. gao, “e3sym: lever- aging e(3)
invariance for unsupervised 3d planar reflective symmetry detection,” in proceedings of
the ieee/cvf international conference on computer vision (iccv) , october 2023, pp. 14
543–14 553.
    [72] [72] j. je, j. liu, g. yang, b. deng, s. cai, g. wetzstein, o. litany, and l. guibas,
“robust symmetry detection via riemannian langevin dynamics,” in siggraph asia 2024
conference papers , ser. sa ’24. new york, ny , usa: association for computing machinery,
2024.
    [73] [73] i. aguirre, i. sipiran, and g. monta ˜nana, “a dataset-free approach for
self-supervised learning of 3d reflectional symmetries,” 2025.
    [74] [74] i. aguirre and i. sipiran, “training-free zero-shot 3d symmetry detection with visual
features back-projected to geometry,” 2025.
    [75] [75] a. x. chang, t. funkhouser, l. guibas, p. hanrahan, q. huang, z. li, s. savarese, m.
savva, s. song, h. su, j. xiao, l. yi, and f. yu, “shapenet: an information-rich 3d model
repository,” arxiv preprint, tech. rep. 1512.03012, dec. 2015.
    [76] [76] i. sipiran, c. romanengo, b. falcidieno, s. biasotti, g. arvanitis, c. chen, v .
fotis, j. he, x. lv, k. moustakas et al. , “shrec 2023: detection of symmetries on 3d
point clouds representing simple shapes,” ineurographics workshop on 3d object retrieval .
the eurographics association, 2023, pp. 17–237.
    [77] [77] n. caytuiro and i. sipiran, “3d shape generation: a survey,” 2025.
    [78] [78] d. levy, s. s. panigrahi, s.-o. kaba, q. zhu, k. l. k. lee, m. galkin, s. miret, and
s. ravanbakhsh, “symmcd: symmetry- preserving crystal generation with diffusion models,”
2025. [online]. available: https://arxiv.org/abs/2502.03638
    [79] [79] f. e. kelvinius, o. b. andersson, a. s. parackal, d. qian, r. armiento, and f.
lindsten, “wyckoffdiff – a generative diffusion model for crystal symmetry,” 2025.
[online]. available: https://arxiv.org/abs/2502.06485
    [80] [80] k. sareen, d. levy, a. k. mondal, s.-o. kaba, t. akhound- sadegh, and s. ravanbakhsh,
“symmetry-aware generative modeling through learned canonicalization,” 2025. [online].
available: https://arxiv.org/abs/2501.07773

3. PARÁGRAFOS RELEVANTES (TOP-1):
  > OBJETIVO:
    Score: 2.000
        symmetry shape analysis ivan sipiran department of computer science university of chile santiago, chile isipiran@dcc.uchile.cl
        abstract —symmetry is a fundamental and pervasive property found in both natural and man-made objects, playing a key role in
        aesthetics, structure, and function. in computational domains, symmetry serves as a powerful cue for data compression, struc- ture
        inference, and shape understanding. this work presents a comprehensive overview of symmetry analysis in 3d shapes, with a
        particular focus on computational methods for symmetry detection and their applications in diverse fields such as cad, computer
        vision, medicine, archaeology, and 3d modeling. we provide formal definitions of exact, approximate, and partial symmetries in the
        context of rigid transformations, and we survey five major categories of detection approaches: transformation- based,
        correspondence-based, voting-based, optimization-based, and learning-based methods. special emphasis is placed on recent deep
        learning techniques, which have significantly advanced the state of the art yet face challenges in generalization and robust-
        ness. finally, we identify key open problems and future directions, including the need for richer and more varied datasets, better
        generalization of learning-based models, effective formulations for symmetry detection in incomplete data, and the integration of
        symmetry priors in generative modeling. our analysis highlights both the progress and the limitations of current methods and aims
        to guide future research toward more principled and capable symmetry-aware systems. index terms —symmetry analysis, shape
        analysis, geometry processing i. i ntroduction symmetry is a ubiquitous feature in the world. its mani- festation is present in
        natural objects (e.g., animals, plants, and even humans) and man-made artificial objects. its almost generalized presence in
        man-made objects is due to the asso- ciation between symmetry and beauty. even more, symmetry has influenced everything from art
        to engineering. given this importance, it is necessary to understand the concept of symmetry from different points of view and
        thus be able to use this understanding to solve problems. symmetry is also a complexity-reducing concept that makes it appealing
        since it allows us to reduce the amount of information with which we represent an entity. this reductive feature makes the
        analysis of symmetries interesting to search for more compact representations of objects in the computer, especially in computing.
        for example, suppose an image is symmetric. in that case, we do not this work is supported by anid chile—fondecyt n° 1251263 and
        national center for artificial intelligence cenia fb210017, basal anid, chile.need to store the whole image but only the part that
        is not repeated and thus be able to reproduce the original image with the knowledge of symmetries. the same applies to a 3d
        object. however, computational representations do not bring information about the possible symmetries they may contain, so it
        becomes necessary to analyze these representations and search for symmetries based on the available information. from the
        computational perspective, this task of symmetry detection is challenging and has received much attention recently by communities
        from different research areas such as computer vision and geometric processing. in particular, we are interested in proposals made
        for three-dimensional representations. for that reason, this section summarizes state of the art in symmetry analysis on 3d
        objects. countless applications have made use of the concept of symmetries in 3d objects to solve problems. the following are some
        applications: •computer-aided design (cad) [1]–[5]: these applica- tions seek to reduce the complexity of storing computer-
        designed parts. •computer vision [6]–[9]: these applications seek to take advantage of the symmetries to facilitate processes such
        as object and structure recognition from motion. •computational modeling [10]: this application uses 3d face symmetry to enhance
        the features of 3d modeled faces. •archaeology [11]–[21]: these applications use symme- tries to reconstruct or improve the
        representation of 3d cultural heritage objects. •medicine [22]–[24]: these applications seek to leverage symmetries to segment the
        shape of prostates and thus improve the diagnosis of diseases. •modeling in graphics [25]–[29]: these applications use the concept
        of symmetry to enforce good modeling properties in 3d objects. given the broad relevance of symmetry across domains and its
        potential to simplify and enrich 3d shape understanding, it is essential to develop computational methods that can effec- tively
        detect and characterize symmetries from geometric data. this paper provides a comprehensive overview of existing ap- proaches to
        symmetry analysis in three-dimensional represen- tations, highlighting both classical and modern techniques. we organize these
        methods according to their underlying strategies and emphasize recent trends in learning-based approaches. by
        979-8-3315-8951-6/25/$31.00 ©2025 ieee doing so, we aim to lay the groundwork for identifying current limitations and motivating
        future research directions in this area. ii. b ackground in this section, we summarize the main definitions required to understand
        the paper. as we are devoted to analyzing symmetries in rigid bodies, we focus our attention on the definitions for this specific
        case. definition 1: a symmetry is a non-trivial transformation t such that when we apply this transformation to a 3d object o, the
        result is the same object. formally, tis a symmetry if t(o) =o. by non-trivial, we mean that tis not the identity. note also that
        the previous definition is strict concerning the required equality. in practice, ois a discrete representation of the continuous
        surface of a 3d object, so the sampling introduces errors that we should take into account when defining the symmetry. next, we
        introduce an alternative approximated definition: definition 2: letsbe the space of 3d objects and let d:s×s→rbe a function that
        measures the congru- ence between two 3d objects. a transformation tis an α- approximated symmetry of an object oifd(t(o),o)≤α.
        note that this definition is more general than the exact symmetry. the exact symmetry can be obtained when α= 0. note also that
        these definitions only hold when the symmetry applies to the overall object, commonly known as global symmetry . nevertheless,
        objects often are not globally sym- metric, but they contain symmetric parts. the next definition formalizes this idea: definition
        3: letobe a 3d object. a transformation tis a partial symmetry if there exist two regions oi⊆ o yoj⊆ o , such that d(t(oi),oj)≤α.
        the definition of partial symmetry is more general than a global symmetry. if we have oi=oj=o, we have the definition of the
        global symmetry. in our case, we are interested in transformations in the rigid world. in this scenario, the transformation tis
        extrinsic because it preserves the euclidean metric in the 3d space. given two points pi, pj∈ o, a transformation tis extrinsic if
        ∥pi−pj∥2=∥t(pi)−t(pj)∥2. in other words, transformation tpreserves the pairwise euclidean distances between points ino. examples
        of extrinsic transformations are rotations, re- flections, and translations. in this work, we focus our attention on rotations and
        reflections. the rotational symmetry can be characterized by the vector of the rotational axis and a point within the vector’s
        direction. the reflective symmetry can be characterized by the normal of the reflective plane and the plane’s point. in both
        cases, the symmetry can be characterized by six floating-point numbers. iii. m ethods for symmetry analysis in this section, we
        show the main approaches proposed to detect symmetries in 3d objects. we classify the methods according to the approach used to
        tackle the problem ofdetection. due to the limited space, we do not give details for every method. instead, we describe the main
        characteristics of each approach and highlight the features of some methods. we do provide details about the learning-based
        methods, which are interesting in the context of this project. 1) transformation-based methods: in this approach, the symmetry
        detection is formulated in a transformed domain, different from the original 3d space. the idea is to compute an intermediate
        representation for a 3d object such that the symmetries are easier to find. table i lists methods in this approach. for example,
        martinet et al. [30] represent a shape with functions called generalized moments . a key property of the generalized moments is
        that the direction of these functions’ vanishing gradients reveals the presence of symmetry. the method consists of evaluating
        candidate directions, transform the moments back to transformation matrices, and verify if the detected symmetry holds in 3d. on
        the other hand, li et al. [31] detect symmetry by analyzing the entropy distribution of 3d viewpoints. the method computes a
        function over a sphere, where each point is the entropy related to observing the object from that point. the algorithm then checks
        the symmetric distribution over the sphere using an image-based method. reference name martinet et al. 2006 [30] generalized
        moments grushko et al. 2012 [32] intrinsic local symmetries kakarala et al. 2013 [33] bilateral symmetry in phase domain
        ovsjanikov et al. 2013 [34] quotient spaces zhang et al. 2013 [35] symmetry robust descriptor jiang et al. 2014 [36]
        fourier-theoretic approach wang et al. 2014 [37] global intrinsic symmetry functions li et al. 2015 [31] view-based symmetry
        detection liu et al. 2015 [38] orthonormal functional maps table i methods with the transformation -based approach . 2)
        correspondence-based methods: in this approach, sym- metry detection is based on determining symmetric candidate correspondences
        (points or regions) in the 3d objects. in general, this approach relies on solving the self-matching problem in a 3d shape. table
        ii lists some methods in this approach. for example, liu et al. [39] formulates the symmetry detec- tion problem as finding the
        stationary points in the symmetric transformation. the idea to find some evidence of symmetric points over the surface is solved
        by applying the blended intrinsic maps method [40]. the method detects potential key points in the 3d shape and computes a matrix
        of geodesic distances between the key points and the remaining points on the surface. the blended maps are computed using the
        geodesic distances as constraints. the zero-level curves of the blended maps are considered as the potential curve axis of the
        symmetry. on the other hand, tevs et al. [41] rely on the analysis of edges in a 3d surface to find potential candidates of
        symmetric correspondences. the potential symmetric rela- tionships are used to find high-level geometric relationships between
        objects in the same class. reference name mitra y bronstein 2010 [42] intrinsic regularity detection raviv et al. 2010 [43] full
        and partial symmetries in non-rigid raviv et al. 2010 [44] diffusion symmetries berner et al. 2011 [45] subspace symmetries wang
        et al. 2011 [46] symmetry hierarchy liu et al. 2012 [39] symmetry axis curves shehu et al. 2014 [47] partial intrinsic symm. tevs
        et al. 2014 [41] geometric symmetries and regularities yoshiyasu et al.2014 [48] symmetry-aware non-rigid matching nagar et
        al.2025 [49] symmetry in point clouds tosyali et al.2025 [50] symmetry axis curve generation table ii methods with the
        correspondence -based approach . 3) voting-based methods: the methods in this approach are based on the accumulation of evidence
        (votes) for symmetries. in general, these methods encode transformations generated from points with common geometric
        characteristics. then, these transformations need to be verified to find the final set of symmetries. table iii shows some methods
        in this category. for example, lipman et al. [51] builds a matrix of corre- spondences that resembles a graph of symmetric
        relationships. the initial matrix is built by accumulating votes for potential transformations. subsequently, the
        eigendecomposition of this matrix leads to a spectral formulation of symmetry detection. on the other hand, jiang et al. [52]
        address the problem of symmetry detection by analyzing the skeletal representation of a 3d shape. the computation of symmetry
        support for the components of the skeleton is performed via voting. reference name mitra et al. 2006 [53] partial and approximate
        symmetries pauly et al. 2008 [54] structural regularity detection lipman et al. 2010 [51] symmetry factored embedding zheng et al.
        2010 [55] non-local scan consolidation xu et al. 2012 [56] multi-scale partial intrinsic symmetry jiang et al. 2013 [52]
        skeleton-based intrinsic symmetry sipiran et al. 2014 [15] approximate symmetry in meshes table iii method with the voting -based
        approach . 4) optimization-based methods: in this approach, the sym- metry detection problem is an optimization problem where the
        symmetry is the best transformation that holds the optimization constraints. table iv lists methods in this approach. for example,
        korman et al. [57] propose to characterize the space of solutions for reflective and rotational symmetries. then, the authors
        formally prove that one can sample this space to make an exhaustive analysis of symmetries. the method assumes that the centroid
        of the object is a fixed point of symmetry, so it only works with global symmetries. on the other hand, nagar et al. [58]
        formulates the problem as a linear programming problem where potential symmetric correspondences are used to build an affinity
        matrix with symmetric constraints. 5) learning-based methods: in this approach, the meth- ods take advantage of the recent
        progress in deep learningreference name korman et al. 2015 [57] provably approximately symmetries mavridis et al. 2015 [17]
        k-sparse optimization speciale et al. 2016 [59] convex variational ecins et al. 2017 [60] symmetrical fitting cicconet et al. 2017
        [61] pairwise alignment of curves nagar et al. 2019 [58] symmetry by manifold optimization nagar et al. 2020 [62] 3dsymm:
        reflection symmetry detection hruda et al. 2022 [63] rotational symmetry detection nguyen et al. 2023 [64] symmetric semi-shape
        signatures bizarri et al. 2024 [65] group symmetry by decomposition table iv method with the optimization -based approach .
        approaches to formulate a learning problem’s symmetry de- tection problem. in general, these methods rely on training a neural
        network that receives a 3d shape and delivers a symmetry representation. reference name bu et al. 2015 [66] local deep feature
        learning ji et al. 2019 [67] 3d reflectional detector with neural network gao et al. 2020 [68] prs-net shi et al. 2020 [69]
        symmetrynet shi et al. 2023 [70] detection with weak supervision li et al. 2023 [71] equivariant symmetry detection je et al. 2024
        [72] langevin dynamics for symmetry detection aguirre et al. 2025 [73] self-prior symmetry detection aguirre et al. 2025 [74]
        training-free zero-shot symmetry detection table v method with the learning -based approach . bu et al. [66] use a deep belief
        network to compute learned features for key points in a 3d shape. the neural network receives a vector quantization descriptor for
        every key point and computes a deep local feature as a new descriptor for the keypoint. these key points are thus evaluated in
        finding symmetric correspondences in non-rigid objects. ji et al. [67] propose a neural network based on pointnet++ to classify
        points as symmetric or non-symmetric. given an input point cloud, the neural network infers a binary label for each point: points
        with label one are considered to belong to the reflective plane. after the classification, the inferred positive points are used
        to compute the symmetric plane using ransac. more recently, gao et al. [68] propose a neural network to predict the planar
        reflective symmetry of objects. the representation is voxelization. this method detects three potential reflective symmetries and
        three potential rotational symmetries, which are subsequently validated in a post-processing stage. the method is self-supervised
        because it uses symmetry distance loss that controls input shape congruence with the symmetric counterpart. a regularization term
        controls the similarity be- tween output symmetries, adding variability to the result. the experiments use the shapenet dataset
        [75] and take advantage of the known alignment of objects to have the ground truth for evaluation. similarly, shi et al. [69]
        describe a multi- task approach to detect reflective and rotational symmetries in rgb-d images. the model learns to find the
        symmetries and symmetric correspondences to avoid overfitting and enable good generalization. the ground truth is built
        automatically by an optimization-based symmetry detection method, so the proposed method learns to simulate the ground method’s
        answer. it is also notorious that rgb information provides essential information for the prediction, so the method is not purely
        geometric. iv. o pen problems and future directions we identify several promising avenues for future research in this area, which
        we detail below: a. datasets and benchmarking a major bottleneck in this domain is the lack of standardized datasets for
        evaluating the effectiveness of methods across diverse scenarios, including both synthetic and real-world settings. while recent
        approaches increasingly rely on deep learning techniques that achieve strong performance, they are often trained and evaluated on
        a limited set of popular bench- marks such as shapenet [75]. these datasets, although useful, may already exhibit saturation
        effects, making it difficult to assess performance on more challenging tasks or generalize to unseen domains. one potential
        direction is to leverage real-world data, such as point clouds from lidar sensors. however, the need for high-quality ground truth
        labels remains a significant hurdle, especially given the cost and complexity of manual annotation. an alternative lies in the
        generation of synthetic datasets. initial efforts in this direction, such as sipiran et al. [76], have demonstrated promise, but
        further research is needed to explore the scalability and variability of synthetically generated data, as well as their alignment
        with real-world distributions. b. generalization in learning-based methods state-of-the-art performance in symmetry detection and
        related tasks is currently driven by deep learning models. despite their success, these models often struggle to generalize to
        unseen objects, limiting their robustness and applicability in open-world scenarios. we argue that self-supervised learning
        paradigms, in combination with geometry-aware regularization techniques, offer a promising path to overcoming this limi- tation.
        embedding prior knowledge about geometric structure into the learning process could enable models to infer symme- try and other
        structural properties from minimal supervision. this fusion of data-driven and structure-driven approaches remains underexplored
        and may lead to more generalizable and interpretable models. c. formulating solutions for partial and incomplete data another open
        challenge lies in the formulation and resolu- tion of tasks involving highly partial or incomplete data—cases where only small
        fragments of the object are available, of- ten insufficient to reveal global symmetries. even advanced learning-based methods fail
        to cope with such extreme cases of partiality. we hypothesize that a general problem formulation exists for this setting, one that
        could be tackled with an end-to-end learning framework designed specifically to infer symmetries under severe data incompleteness.
        developingsuch methods could significantly broaden the applicability of symmetry detection algorithms in real-world conditions,
        such as robotics, archaeology, and autonomous mapping. d. symmetry-aware generative models 3d generative models have recently
        gained substantial trac- tion, producing increasingly high-quality results across various tasks [77]. however, symmetry—a
        pervasive and meaningful property in man-made and natural objects—is rarely used as an explicit inductive bias or quality
        criterion during training. we believe that incorporating symmetry awareness into the generative process could enhance the
        plausibility, regularity, and aesthetic quality of generated 3d shapes. there is prece- dent for this idea in crystallography
        [78], [79] and molecular design [80], where symmetry constraints are crucial for gen- erating physically valid structures.
        imposing such structural priors in generative modeling could pave the way for higher- quality 3d data synthesis, particularly in
        applications where geometric consistency is critical. v. f inal remarks symmetry remains a central concept in the understanding
        and representation of 3d shapes, offering both aesthetic and structural insights across a wide range of disciplines. over the past
        two decades, the field has evolved from handcrafted geometric algorithms to learning-based methods capable of capturing complex
        symmetries from data. despite these ad- vances, several key challenges remain unresolved. the lack of standardized and diverse
        datasets continues to limit fair comparison and generalization. deep learning models, while powerful, often struggle with
        out-of-distribution generaliza- tion and incomplete inputs. moreover, symmetry—a highly structured and ubiquitous property—is
        still underutilized in generative modeling pipelines. in this work, we have presented a unified view of the com- putational
        approaches for symmetry detection in 3d shapes, emphasizing their motivations, methodologies, and applica- tions. we believe that
        future progress will depend on develop- ing methods that are not only accurate but also data-efficient, interpretable, and robust
        to real-world conditions. in particular, bridging geometric structure and data-driven learning holds great promise for creating
        models that better understand and leverage symmetry. ultimately, symmetry is more than a geometric property—it is a powerful
        organizational principle. harnessing it effectively may lead to more compact representations, better reconstruc- tions, and more
        meaningful generations of 3d content. as such, it continues to offer fertile ground for fundamental research and impactful
        applications. vi. a cknowledgments this work was funded by anid - fondecyt regular - project, chile 1251263 and by national center
        for artificial intelligence cenia fb210017, basal anid, chile. references [1] m. li, f. c. langbein, and r. r. martin, “detecting
        approximate symmetries of discrete point subsets,” comput. aided des. , vol. 40, no. 1, pp. 76–93, jan. 2008. [2] m. chang and s.
        c. park, “reverse engineering of a symmetric object,” computers & industrial engineering , vol. 55, no. 2, pp. 311–320, 2008. [3]
        j. jiang, z. chen, and k. he, “a feature-based method of rapidly detecting global exact symmetries in {cad }models,”
        computer-aided design , vol. 45, no. 8–9, pp. 1081–1094, 2013. [4] k. li, g. foucault, j.-c. l ´eon, and m. trlin, “fast global
        and partial reflective symmetry analyses using boundary surfaces of mechanical components,” computer-aided design , vol. 53, pp.
        70–89, 2014. [5] a. mu, z. liu, g. duan, and j. tan, “structural regularity detection and enhancement for surface mesh
        reconstruction in reverse engineering,” computer-aided design , vol. 177, p. 103780, 2024. [6] a. cohen, c. zach, s. sinha, and m.
        pollefeys, “discovering and ex- ploiting 3d symmetries in structure from motion,” in cvpr . computer vision and patter
        recognition, june 2012. [7] d. ceylan, n. j. mitra, y . zheng, and m. pauly, “coupled structure- from-motion and 3d symmetry
        detection for urban facades,” acm trans. graph. , vol. 33, no. 1, pp. 2:1–2:15, feb. 2014. [8] r. p. de figueiredo, p. moreno, and
        a. bernardino, “efficient pose estimation of rotationally symmetric objects,” neurocomputing , vol. 150, part a, pp. 126–135,
        2015. [9] s. wu, c. rupprecht, and a. vedaldi, “unsupervised learning of probably symmetric deformable 3d objects from images in
        the wild,” in proceedings of the ieee conference on computer vision and pattern recognition (cvpr) , 2020. [10] q. liao, x. jin,
        and w. zeng, “enhancing the symmetry and propor- tion of 3d face geometry,” ieee transactions on visualization and computer
        graphics , vol. 18, no. 10, pp. 1704–1716, 2012. [11] k. son, e. almeida, and d. cooper, “axially symmetric 3d pots config-
        uration system using axis of symmetry and break curve,” in computer vision and pattern recognition (cvpr), 2013 ieee conference on
        , june 2013, pp. 257–264. [12] b. xia, b. ben amor, h. drira, m. daoudi, and l. ballihi, “gender and 3d facial symmetry: what’s
        the relationship?” in automatic face and gesture recognition (fg), 2013 10th ieee international conference and workshops on ,
        april 2013, pp. 1–6. [13] g. harary, a. tal, and e. grinspun, “context-based coherent surface completion,” acm trans. graph. ,
        vol. 33, no. 1, pp. 5:1–5:12, feb. 2014. [14] e. li, x. zhang, and y . chen, “symmetry based chinese ancient architecture
        reconstruction from incomplete point cloud,” in digital home (icdh), 2014 5th international conference on , nov 2014, pp. 157–161.
        [15] i. sipiran, r. gregor, and t. schreck, “approximate symmetry detection in partial 3d meshes,” comput. graph. forum , vol. 33,
        no. 7, pp. 131– 140, oct. 2014. [16] s. mansouri and h. ebrahimnezhad, “efficient axial symmetry aware mesh approximation with
        application to 3d pottery models,” multimedia tools and applications , pp. 1–33, 2015. [17] p. mavridis, i. sipiran, a. andreadis,
        and g. papaioannou, “object completion using k-sparse optimization,” computer graphics forum , vol. 34, no. 7, pp. 13–21, 2015.
        [18] w. shui and f. gao, “a geometric completion and shape analysis method for damaged bilaterally symmetrical artifacts,” journal
        of cultural heritage , vol. 52, pp. 118–127, 2021. [19] j. xu, w. cao, b. liu, and k. jiang, “object restoration based on
        extrinsic reflective symmetry plane detection,” vis. comput. , vol. 38, no. 11, p. 3627–3642, nov. 2022. [20] w. shui, p. wei, x.
        zheng, and s. geng, “a landmark-free approach for surface asymmetry detection and profile drawings from bilaterally symmetrical
        geometry,” j. comput. cult. herit. , vol. 16, no. 2, jun. 2023. [21] i. sipiran, “the role of computing in the study of latin
        american cultural heritage,” commun. acm , vol. 67, no. 8, p. 58–62, aug. 2024. [22] w. qiu, j. yuan, e. ukwatta, y . sun, m.
        rajchl, and a. fenster, “prostate segmentation: an efficient convex optimization approach with axial symmetry using 3-d trus and
        mr images,” medical imaging, ieee transactions on , vol. 33, no. 4, pp. 947–960, april 2014.[23] j. yuan, w. qiu, m. rajchl, e.
        ukwatta, x.-c. tai, and a. fenster, “efficient 3d endfiring trus prostate segmentation with globally optimized rotational
        symmetry,” 2014 ieee conference on computer vision and pattern recognition , vol. 0, pp. 2211–2218, 2013. [24] j. fotouhi, g.
        taylor, m. unberath, a. johnson, s. c. lee, g. osgood, m. armand, and n. navab, “exploring partial intrinsic and extrinsic
        symmetry in 3d medical imaging,” medical image analysis , vol. 72, p. 102127, 2021. [25] j. li, k. xu, s. chaudhuri, e. yumer, h.
        zhang, and l. guibas, “grass: generative recursive autoencoders for shape structures,” acm trans. graph. , vol. 36, no. 4, jul.
        2017. [26] c. zhu, k. xu, s. chaudhuri, r. yi, and h. zhang, “scores: shape composition with recursive substructure priors,” acm
        trans. graph. , vol. 37, no. 6, dec. 2018. [27] k. mo, p. guerrero, l. yi, h. su, p. wonka, n. j. mitra, and l. j. guibas,
        “structurenet: hierarchical graph networks for 3d shape generation,” acm trans. graph. , vol. 38, no. 6, nov. 2019. [28] j. li, c.
        niu, and k. xu, “learning part generation and assembly for structure-aware shape synthesis,” in the thirty-fourth aaai conference
        on artificial intelligence, aaai 2020, the thirty-second innovative applications of artificial intelligence conference, iaai 2020,
        the tenth aaai symposium on educational advances in artificial intelligence, eaai 2020, new york, ny, usa, february 7-12, 2020 .
        aaai press, 2020, pp. 11 362–11 369. [29] y . he, q. fang, z. zhang, t. dai, k. wu, l. liu, and x.-m. fu, “symmetric piecewise
        developable approximations,” computer graph- ics forum , vol. 43, no. 7, p. e15242, 2024. [30] a. martinet, c. soler, n.
        holzschuch, and f. x. sillion, “accurate detection of symmetries in 3d shapes,” acm trans. graph. , vol. 25, no. 2, pp. 439–464,
        apr. 2006. [31] b. li, h. johan, y . ye, and y . lu, “efficient view-based 3d reflection symmetry detection,” in siggraph asia
        2014 creative shape mod- eling and design , ser. sa ’14. new york, ny , usa: acm, 2014, pp. 2:1–2:8. [32] c. grushko, d. raviv,
        and r. kimmel, “intrinsic local symmetries: a computational framework,” in proceedings of the 5th eurographics conference on 3d
        object retrieval , ser. eg 3dor’12. aire-la-ville, switzerland, switzerland: eurographics association, 2012, pp. 33–38. [33] r.
        kakarala, p. kaliamoorthi, and v . premachandran, “three- dimensional bilateral symmetry plane estimation in the phase do- main,”
        in computer vision and pattern recognition (cvpr), 2013 ieee conference on , june 2013, pp. 249–256. [34] m. ovsjanikov, q. m
        ´erigot, v . p ˘atr˘aucean, and l. guibas, “shape matching via quotient spaces,” in proceedings of the eleventh eu-
        rographics/acmsiggraph symposium on geometry processing , ser. sgp ’13. aire-la-ville, switzerland, switzerland: eurographics
        asso- ciation, 2013, pp. 1–11. [35] z. zhang, k. yin, and k. w. c. foong, “symmetry robust descriptor for non-rigid surface
        matching.” comput. graph. forum , vol. 32, no. 7, pp. 355–362, 2013. [36] x. jiang, j. sun, and l. guibas, “a fourier-theoretic
        approach for inferring symmetries,” comput. geom. theory appl. , vol. 47, no. 2, pp. 164–174, feb. 2014. [37] h. wang, p. simari,
        z. su, and h. zhang, “spectral global intrinsic symmetry invariant functions,” in proceedings of graphics interface 2014 , ser. gi
        ’14. toronto, ont., canada, canada: canadian information processing society, 2014, pp. 209–215. [38] x. liu, s. li, r. liu, j.
        wang, h. wang, and j. cao, “properly constrained orthonormal functional maps for intrinsic symmetries,” computers & graphics ,
        vol. 46, pp. 198–208, 2015, shape modeling international 2014. [39] t. liu, v . g. kim, and t. funkhouser, “finding surface
        correspon- dences using symmetry axis curves,” comp. graph. forum , vol. 31, no. 5, pp. 1607–1616, aug. 2012. [40] v . g. kim, y .
        lipman, and t. funkhouser, “blended intrinsic maps,” acm trans. graph. , vol. 30, no. 4, pp. 79:1–79:12, jul. 2011. [41] a. tevs,
        q. huang, m. wand, h.-p. seidel, and l. guibas, “relat- ing shapes via geometric symmetries and regularities,” acm trans. graph. ,
        vol. 33, no. 4, pp. 119:1–119:12, jul. 2014. [42] n. mitra, a. bronstein, and m. bronstein, “intrinsic regularity detec- tion in
        3d geometry,” in computer vision – eccv 2010 , ser. lecture notes in computer science, k. daniilidis, p. maragos, and n. paragios,
        eds. springer berlin heidelberg, 2010, vol. 6313, pp. 398–410. [43] d. raviv, a. m. bronstein, m. m. bronstein, and r. kimmel,
        “full and partial symmetries of non-rigid shapes,” int. j. comput. vision , vol. 89, no. 1, pp. 18–39, aug. 2010. [44] d. raviv,
        m. m. bronstein, g. sapiro, a. m. bronstein, and r. kimmel, “diffusion symmetries of non-rigid shapes,” in in proc. 3dpvt , 2010.
        [45] a. berner, m. wand, n. j. mitra, d. mewes, and h. seidel, “shape analysis with subspace symmetries,” comput. graph. forum ,
        vol. 30, no. 2, pp. 277–286, 2011. [46] y . wang, k. xu, j. li, h. zhang, a. shamir, l. liu, z. cheng, and y . xiong, “symmetry
        hierarchy of man-made objects,” comput. graph. forum , vol. 30, no. 2, pp. 287–296, 2011. [47] a. shehu, a. brunton, s. wuhrer,
        and m. wand, “characterization of partial intrinsic symmetries,” in computer vision - eccv 2014 workshops , ser. lecture notes in
        computer science, l. agapito, m. m. bronstein, and c. rother, eds. springer international publishing, 2015, vol. 8928, pp.
        267–282. [48] y . yoshiyasu, e. yoshida, k. yokoi, and r. sagawa, “symmetry-aware nonrigid matching of incomplete 3d surfaces,” in
        computer vision and pattern recognition (cvpr), 2014 ieee conference on , june 2014, pp. 4193–4200. [49] r. nagar, “robust
        extrinsic symmetry estimation in 3d point clouds,” vis. comput. , vol. 41, no. 1, p. 115–128, mar. 2024. [50] b. tosyalı and y .
        sahillio ˘glu, “intrinsic reflective symmetry axis curve generation for meshes,” in proceedings of computer graphics inter-
        national 2025 . new york, ny , usa: association for computing machinery, 2025. [51] y . lipman, x. chen, i. daubechies, and t.
        funkhouser, “symmetry factored embedding and distance,” acm trans. graph. , vol. 29, no. 4, pp. 103:1–103:12, jul. 2010. [52] w.
        jiang, k. xu, z.-q. cheng, and h. zhang, “skeleton-based intrinsic symmetry detection on point clouds,” graphical models , vol.
        75, no. 4, pp. 177–188, 2013. [53] n. j. mitra, l. j. guibas, and m. pauly, “partial and approximate symmetry detection for 3d
        geometry,” acm trans. graph. , vol. 25, no. 3, pp. 560–568, jul. 2006. [54] m. pauly, n. j. mitra, j. wallner, h. pottmann, and l.
        j. guibas, “discovering structural regularity in 3d geometry,” acm trans. graph. , vol. 27, no. 3, 2008. [55] q. zheng, a. sharf,
        g. wan, y . li, n. j. mitra, d. cohen-or, and b. chen, “non-local scan consolidation for 3d urban scenes,” acm trans. graph. ,
        vol. 29, no. 4, pp. 94:1–94:9, jul. 2010. [56] k. xu, h. zhang, w. jiang, r. dyer, z. cheng, l. liu, and b. chen, “multi-scale
        partial intrinsic symmetry detection,” acm trans. graph. , vol. 31, no. 6, pp. 181:1–181:11, nov. 2012. [57] s. korman, r. litman,
        s. avidan, and a. bronstein, “probably ap- proximately symmetric: fast rigid symmetry detection with global guarantees,” comput.
        graph. forum , vol. 34, no. 1, pp. 2–13, feb. 2015. [58] r. nagar and s. raman, “detecting approximate reflection symmetry in a
        point set using optimization on manifold,” ieee transactions on signal processing , vol. 67, no. 6, pp. 1582–1595, 2019. [59] a.
        c. pablo speciale, martin r. oswald and m. pollefeys, “a symmetry prior for convex variational 3d reconstruction,” in european
        conference on computer vision (eccv) , 2016. [60] a. ecins, c. ferm ¨uller, and y . aloimonos, “detecting reflectional symmetries
        in 3d data through symmetrical fitting,” in 2017 ieee international conference on computer vision workshops (iccvw) , 2017, pp.
        1779–1783. [61] m. cicconet, d. g. c. hildebrand, and h. elliott, “finding mirror symmetry via registration and optimal symmetric
        pairwise assignment of curves,” in 2017 ieee international conference on computer vision workshops (iccvw) , 2017, pp. 1749–1758.
        [62] r. nagar and s. raman, “3dsymm: robust and accurate 3d reflection symmetry detection,” pattern recognition , vol. 107, p.
        107483, 2020. [63] l. hruda, i. kolingerov ´a, m. l ´aviˇcka, and m. ma ˇn´ak, “rotational symmetry detection in 3d using
        reflectional symmetry candidates and quaternion-based rotation parameterization,” computer aided geometric design , vol. 98, p.
        102138, 2022. [64] t. p. nguyen and t. t. nguyen, “robust detectors of rotationally symmetric shapes based on novel semi-shape
        signatures,” pattern recog- nition , vol. 138, p. 109336, 2023. [65] m. bizzarri, l. hruda, m. l ´aviˇcka, and j. vr ˇsek,
        “symmetry group detection of point clouds in 3d via a decomposition method,” computer aided geometric design , vol. 113, p.
        102376, 2024.[66] s. bu, p. han, z. liu, j. han, and h. lin, “local deep feature learning framework for 3d shapes,” computers and
        graphics , vol. 46, pp. 117– 129, 2015, shape modeling international 2014. [67] p. ji and x. liu, “a fast and efficient 3d
        reflection symmetry detector based on neural networks,” multimedia tools and applications , vol. 78, pp. 35 471 – 35 492, 2019.
        [68] l. gao, l. x. zhang, h. y . meng, y . h. ren, y . k. lai, and l. kobbelt, “prs-net: planar reflective symmetry detection net
        for 3d models,” ieee transactions on visualization and computer graphics , pp. 1–1, 2020. [69] y . shi, j. huang, h. zhang, x. xu,
        s. rusinkiewicz, and k. xu, “sym- metrynet: learning to predict reflectional and rotational symmetries of 3d shapes from
        single-view rgb-d images,” acm trans. graph. , vol. 39, no. 6, nov. 2020. [70] y . shi, x. xu, j. xi, x. hu, d. hu, and k. xu,
        “learning to detect 3d symmetry from single-view rgb-d images with weak supervision,” ieee transactions on pattern analysis and
        machine intelligence , vol. 45, no. 4, pp. 4882–4896, 2023. [71] r.-w. li, l.-x. zhang, c. li, y .-k. lai, and l. gao, “e3sym:
        lever- aging e(3) invariance for unsupervised 3d planar reflective symmetry detection,” in proceedings of the ieee/cvf
        international conference on computer vision (iccv) , october 2023, pp. 14 543–14 553. [72] j. je, j. liu, g. yang, b. deng, s.
        cai, g. wetzstein, o. litany, and l. guibas, “robust symmetry detection via riemannian langevin dynamics,” in siggraph asia 2024
        conference papers , ser. sa ’24. new york, ny , usa: association for computing machinery, 2024. [73] i. aguirre, i. sipiran, and
        g. monta ˜nana, “a dataset-free approach for self-supervised learning of 3d reflectional symmetries,” 2025. [74] i. aguirre and i.
        sipiran, “training-free zero-shot 3d symmetry detection with visual features back-projected to geometry,” 2025. [75] a. x. chang,
        t. funkhouser, l. guibas, p. hanrahan, q. huang, z. li, s. savarese, m. savva, s. song, h. su, j. xiao, l. yi, and f. yu,
        “shapenet: an information-rich 3d model repository,” arxiv preprint, tech. rep. 1512.03012, dec. 2015. [76] i. sipiran, c.
        romanengo, b. falcidieno, s. biasotti, g. arvanitis, c. chen, v . fotis, j. he, x. lv, k. moustakas et al. , “shrec 2023:
        detection of symmetries on 3d point clouds representing simple shapes,” ineurographics workshop on 3d object retrieval . the
        eurographics association, 2023, pp. 17–237. [77] n. caytuiro and i. sipiran, “3d shape generation: a survey,” 2025. [78] d. levy,
        s. s. panigrahi, s.-o. kaba, q. zhu, k. l. k. lee, m. galkin, s. miret, and s. ravanbakhsh, “symmcd: symmetry- preserving crystal
        generation with diffusion models,” 2025. [online]. available: https://arxiv.org/abs/2502.03638 [79] f. e. kelvinius, o. b.
        andersson, a. s. parackal, d. qian, r. armiento, and f. lindsten, “wyckoffdiff – a generative diffusion model for crystal
        symmetry,” 2025. [online]. available: https://arxiv.org/abs/2502.06485 [80] k. sareen, d. levy, a. k. mondal, s.-o. kaba, t.
        akhound- sadegh, and s. ravanbakhsh, “symmetry-aware generative modeling through learned canonicalization,” 2025. [online].
        available: https://arxiv.org/abs/2501.07773
  > PALAVRAS-CHAVES:
    Não encontrado.
  > PROBLEMA:
    Score: 2.000
        symmetry shape analysis ivan sipiran department of computer science university of chile santiago, chile isipiran@dcc.uchile.cl
        abstract —symmetry is a fundamental and pervasive property found in both natural and man-made objects, playing a key role in
        aesthetics, structure, and function. in computational domains, symmetry serves as a powerful cue for data compression, struc- ture
        inference, and shape understanding. this work presents a comprehensive overview of symmetry analysis in 3d shapes, with a
        particular focus on computational methods for symmetry detection and their applications in diverse fields such as cad, computer
        vision, medicine, archaeology, and 3d modeling. we provide formal definitions of exact, approximate, and partial symmetries in the
        context of rigid transformations, and we survey five major categories of detection approaches: transformation- based,
        correspondence-based, voting-based, optimization-based, and learning-based methods. special emphasis is placed on recent deep
        learning techniques, which have significantly advanced the state of the art yet face challenges in generalization and robust-
        ness. finally, we identify key open problems and future directions, including the need for richer and more varied datasets, better
        generalization of learning-based models, effective formulations for symmetry detection in incomplete data, and the integration of
        symmetry priors in generative modeling. our analysis highlights both the progress and the limitations of current methods and aims
        to guide future research toward more principled and capable symmetry-aware systems. index terms —symmetry analysis, shape
        analysis, geometry processing i. i ntroduction symmetry is a ubiquitous feature in the world. its mani- festation is present in
        natural objects (e.g., animals, plants, and even humans) and man-made artificial objects. its almost generalized presence in
        man-made objects is due to the asso- ciation between symmetry and beauty. even more, symmetry has influenced everything from art
        to engineering. given this importance, it is necessary to understand the concept of symmetry from different points of view and
        thus be able to use this understanding to solve problems. symmetry is also a complexity-reducing concept that makes it appealing
        since it allows us to reduce the amount of information with which we represent an entity. this reductive feature makes the
        analysis of symmetries interesting to search for more compact representations of objects in the computer, especially in computing.
        for example, suppose an image is symmetric. in that case, we do not this work is supported by anid chile—fondecyt n° 1251263 and
        national center for artificial intelligence cenia fb210017, basal anid, chile.need to store the whole image but only the part that
        is not repeated and thus be able to reproduce the original image with the knowledge of symmetries. the same applies to a 3d
        object. however, computational representations do not bring information about the possible symmetries they may contain, so it
        becomes necessary to analyze these representations and search for symmetries based on the available information. from the
        computational perspective, this task of symmetry detection is challenging and has received much attention recently by communities
        from different research areas such as computer vision and geometric processing. in particular, we are interested in proposals made
        for three-dimensional representations. for that reason, this section summarizes state of the art in symmetry analysis on 3d
        objects. countless applications have made use of the concept of symmetries in 3d objects to solve problems. the following are some
        applications: •computer-aided design (cad) [1]–[5]: these applica- tions seek to reduce the complexity of storing computer-
        designed parts. •computer vision [6]–[9]: these applications seek to take advantage of the symmetries to facilitate processes such
        as object and structure recognition from motion. •computational modeling [10]: this application uses 3d face symmetry to enhance
        the features of 3d modeled faces. •archaeology [11]–[21]: these applications use symme- tries to reconstruct or improve the
        representation of 3d cultural heritage objects. •medicine [22]–[24]: these applications seek to leverage symmetries to segment the
        shape of prostates and thus improve the diagnosis of diseases. •modeling in graphics [25]–[29]: these applications use the concept
        of symmetry to enforce good modeling properties in 3d objects. given the broad relevance of symmetry across domains and its
        potential to simplify and enrich 3d shape understanding, it is essential to develop computational methods that can effec- tively
        detect and characterize symmetries from geometric data. this paper provides a comprehensive overview of existing ap- proaches to
        symmetry analysis in three-dimensional represen- tations, highlighting both classical and modern techniques. we organize these
        methods according to their underlying strategies and emphasize recent trends in learning-based approaches. by
        979-8-3315-8951-6/25/$31.00 ©2025 ieee doing so, we aim to lay the groundwork for identifying current limitations and motivating
        future research directions in this area. ii. b ackground in this section, we summarize the main definitions required to understand
        the paper. as we are devoted to analyzing symmetries in rigid bodies, we focus our attention on the definitions for this specific
        case. definition 1: a symmetry is a non-trivial transformation t such that when we apply this transformation to a 3d object o, the
        result is the same object. formally, tis a symmetry if t(o) =o. by non-trivial, we mean that tis not the identity. note also that
        the previous definition is strict concerning the required equality. in practice, ois a discrete representation of the continuous
        surface of a 3d object, so the sampling introduces errors that we should take into account when defining the symmetry. next, we
        introduce an alternative approximated definition: definition 2: letsbe the space of 3d objects and let d:s×s→rbe a function that
        measures the congru- ence between two 3d objects. a transformation tis an α- approximated symmetry of an object oifd(t(o),o)≤α.
        note that this definition is more general than the exact symmetry. the exact symmetry can be obtained when α= 0. note also that
        these definitions only hold when the symmetry applies to the overall object, commonly known as global symmetry . nevertheless,
        objects often are not globally sym- metric, but they contain symmetric parts. the next definition formalizes this idea: definition
        3: letobe a 3d object. a transformation tis a partial symmetry if there exist two regions oi⊆ o yoj⊆ o , such that d(t(oi),oj)≤α.
        the definition of partial symmetry is more general than a global symmetry. if we have oi=oj=o, we have the definition of the
        global symmetry. in our case, we are interested in transformations in the rigid world. in this scenario, the transformation tis
        extrinsic because it preserves the euclidean metric in the 3d space. given two points pi, pj∈ o, a transformation tis extrinsic if
        ∥pi−pj∥2=∥t(pi)−t(pj)∥2. in other words, transformation tpreserves the pairwise euclidean distances between points ino. examples
        of extrinsic transformations are rotations, re- flections, and translations. in this work, we focus our attention on rotations and
        reflections. the rotational symmetry can be characterized by the vector of the rotational axis and a point within the vector’s
        direction. the reflective symmetry can be characterized by the normal of the reflective plane and the plane’s point. in both
        cases, the symmetry can be characterized by six floating-point numbers. iii. m ethods for symmetry analysis in this section, we
        show the main approaches proposed to detect symmetries in 3d objects. we classify the methods according to the approach used to
        tackle the problem ofdetection. due to the limited space, we do not give details for every method. instead, we describe the main
        characteristics of each approach and highlight the features of some methods. we do provide details about the learning-based
        methods, which are interesting in the context of this project. 1) transformation-based methods: in this approach, the symmetry
        detection is formulated in a transformed domain, different from the original 3d space. the idea is to compute an intermediate
        representation for a 3d object such that the symmetries are easier to find. table i lists methods in this approach. for example,
        martinet et al. [30] represent a shape with functions called generalized moments . a key property of the generalized moments is
        that the direction of these functions’ vanishing gradients reveals the presence of symmetry. the method consists of evaluating
        candidate directions, transform the moments back to transformation matrices, and verify if the detected symmetry holds in 3d. on
        the other hand, li et al. [31] detect symmetry by analyzing the entropy distribution of 3d viewpoints. the method computes a
        function over a sphere, where each point is the entropy related to observing the object from that point. the algorithm then checks
        the symmetric distribution over the sphere using an image-based method. reference name martinet et al. 2006 [30] generalized
        moments grushko et al. 2012 [32] intrinsic local symmetries kakarala et al. 2013 [33] bilateral symmetry in phase domain
        ovsjanikov et al. 2013 [34] quotient spaces zhang et al. 2013 [35] symmetry robust descriptor jiang et al. 2014 [36]
        fourier-theoretic approach wang et al. 2014 [37] global intrinsic symmetry functions li et al. 2015 [31] view-based symmetry
        detection liu et al. 2015 [38] orthonormal functional maps table i methods with the transformation -based approach . 2)
        correspondence-based methods: in this approach, sym- metry detection is based on determining symmetric candidate correspondences
        (points or regions) in the 3d objects. in general, this approach relies on solving the self-matching problem in a 3d shape. table
        ii lists some methods in this approach. for example, liu et al. [39] formulates the symmetry detec- tion problem as finding the
        stationary points in the symmetric transformation. the idea to find some evidence of symmetric points over the surface is solved
        by applying the blended intrinsic maps method [40]. the method detects potential key points in the 3d shape and computes a matrix
        of geodesic distances between the key points and the remaining points on the surface. the blended maps are computed using the
        geodesic distances as constraints. the zero-level curves of the blended maps are considered as the potential curve axis of the
        symmetry. on the other hand, tevs et al. [41] rely on the analysis of edges in a 3d surface to find potential candidates of
        symmetric correspondences. the potential symmetric rela- tionships are used to find high-level geometric relationships between
        objects in the same class. reference name mitra y bronstein 2010 [42] intrinsic regularity detection raviv et al. 2010 [43] full
        and partial symmetries in non-rigid raviv et al. 2010 [44] diffusion symmetries berner et al. 2011 [45] subspace symmetries wang
        et al. 2011 [46] symmetry hierarchy liu et al. 2012 [39] symmetry axis curves shehu et al. 2014 [47] partial intrinsic symm. tevs
        et al. 2014 [41] geometric symmetries and regularities yoshiyasu et al.2014 [48] symmetry-aware non-rigid matching nagar et
        al.2025 [49] symmetry in point clouds tosyali et al.2025 [50] symmetry axis curve generation table ii methods with the
        correspondence -based approach . 3) voting-based methods: the methods in this approach are based on the accumulation of evidence
        (votes) for symmetries. in general, these methods encode transformations generated from points with common geometric
        characteristics. then, these transformations need to be verified to find the final set of symmetries. table iii shows some methods
        in this category. for example, lipman et al. [51] builds a matrix of corre- spondences that resembles a graph of symmetric
        relationships. the initial matrix is built by accumulating votes for potential transformations. subsequently, the
        eigendecomposition of this matrix leads to a spectral formulation of symmetry detection. on the other hand, jiang et al. [52]
        address the problem of symmetry detection by analyzing the skeletal representation of a 3d shape. the computation of symmetry
        support for the components of the skeleton is performed via voting. reference name mitra et al. 2006 [53] partial and approximate
        symmetries pauly et al. 2008 [54] structural regularity detection lipman et al. 2010 [51] symmetry factored embedding zheng et al.
        2010 [55] non-local scan consolidation xu et al. 2012 [56] multi-scale partial intrinsic symmetry jiang et al. 2013 [52]
        skeleton-based intrinsic symmetry sipiran et al. 2014 [15] approximate symmetry in meshes table iii method with the voting -based
        approach . 4) optimization-based methods: in this approach, the sym- metry detection problem is an optimization problem where the
        symmetry is the best transformation that holds the optimization constraints. table iv lists methods in this approach. for example,
        korman et al. [57] propose to characterize the space of solutions for reflective and rotational symmetries. then, the authors
        formally prove that one can sample this space to make an exhaustive analysis of symmetries. the method assumes that the centroid
        of the object is a fixed point of symmetry, so it only works with global symmetries. on the other hand, nagar et al. [58]
        formulates the problem as a linear programming problem where potential symmetric correspondences are used to build an affinity
        matrix with symmetric constraints. 5) learning-based methods: in this approach, the meth- ods take advantage of the recent
        progress in deep learningreference name korman et al. 2015 [57] provably approximately symmetries mavridis et al. 2015 [17]
        k-sparse optimization speciale et al. 2016 [59] convex variational ecins et al. 2017 [60] symmetrical fitting cicconet et al. 2017
        [61] pairwise alignment of curves nagar et al. 2019 [58] symmetry by manifold optimization nagar et al. 2020 [62] 3dsymm:
        reflection symmetry detection hruda et al. 2022 [63] rotational symmetry detection nguyen et al. 2023 [64] symmetric semi-shape
        signatures bizarri et al. 2024 [65] group symmetry by decomposition table iv method with the optimization -based approach .
        approaches to formulate a learning problem’s symmetry de- tection problem. in general, these methods rely on training a neural
        network that receives a 3d shape and delivers a symmetry representation. reference name bu et al. 2015 [66] local deep feature
        learning ji et al. 2019 [67] 3d reflectional detector with neural network gao et al. 2020 [68] prs-net shi et al. 2020 [69]
        symmetrynet shi et al. 2023 [70] detection with weak supervision li et al. 2023 [71] equivariant symmetry detection je et al. 2024
        [72] langevin dynamics for symmetry detection aguirre et al. 2025 [73] self-prior symmetry detection aguirre et al. 2025 [74]
        training-free zero-shot symmetry detection table v method with the learning -based approach . bu et al. [66] use a deep belief
        network to compute learned features for key points in a 3d shape. the neural network receives a vector quantization descriptor for
        every key point and computes a deep local feature as a new descriptor for the keypoint. these key points are thus evaluated in
        finding symmetric correspondences in non-rigid objects. ji et al. [67] propose a neural network based on pointnet++ to classify
        points as symmetric or non-symmetric. given an input point cloud, the neural network infers a binary label for each point: points
        with label one are considered to belong to the reflective plane. after the classification, the inferred positive points are used
        to compute the symmetric plane using ransac. more recently, gao et al. [68] propose a neural network to predict the planar
        reflective symmetry of objects. the representation is voxelization. this method detects three potential reflective symmetries and
        three potential rotational symmetries, which are subsequently validated in a post-processing stage. the method is self-supervised
        because it uses symmetry distance loss that controls input shape congruence with the symmetric counterpart. a regularization term
        controls the similarity be- tween output symmetries, adding variability to the result. the experiments use the shapenet dataset
        [75] and take advantage of the known alignment of objects to have the ground truth for evaluation. similarly, shi et al. [69]
        describe a multi- task approach to detect reflective and rotational symmetries in rgb-d images. the model learns to find the
        symmetries and symmetric correspondences to avoid overfitting and enable good generalization. the ground truth is built
        automatically by an optimization-based symmetry detection method, so the proposed method learns to simulate the ground method’s
        answer. it is also notorious that rgb information provides essential information for the prediction, so the method is not purely
        geometric. iv. o pen problems and future directions we identify several promising avenues for future research in this area, which
        we detail below: a. datasets and benchmarking a major bottleneck in this domain is the lack of standardized datasets for
        evaluating the effectiveness of methods across diverse scenarios, including both synthetic and real-world settings. while recent
        approaches increasingly rely on deep learning techniques that achieve strong performance, they are often trained and evaluated on
        a limited set of popular bench- marks such as shapenet [75]. these datasets, although useful, may already exhibit saturation
        effects, making it difficult to assess performance on more challenging tasks or generalize to unseen domains. one potential
        direction is to leverage real-world data, such as point clouds from lidar sensors. however, the need for high-quality ground truth
        labels remains a significant hurdle, especially given the cost and complexity of manual annotation. an alternative lies in the
        generation of synthetic datasets. initial efforts in this direction, such as sipiran et al. [76], have demonstrated promise, but
        further research is needed to explore the scalability and variability of synthetically generated data, as well as their alignment
        with real-world distributions. b. generalization in learning-based methods state-of-the-art performance in symmetry detection and
        related tasks is currently driven by deep learning models. despite their success, these models often struggle to generalize to
        unseen objects, limiting their robustness and applicability in open-world scenarios. we argue that self-supervised learning
        paradigms, in combination with geometry-aware regularization techniques, offer a promising path to overcoming this limi- tation.
        embedding prior knowledge about geometric structure into the learning process could enable models to infer symme- try and other
        structural properties from minimal supervision. this fusion of data-driven and structure-driven approaches remains underexplored
        and may lead to more generalizable and interpretable models. c. formulating solutions for partial and incomplete data another open
        challenge lies in the formulation and resolu- tion of tasks involving highly partial or incomplete data—cases where only small
        fragments of the object are available, of- ten insufficient to reveal global symmetries. even advanced learning-based methods fail
        to cope with such extreme cases of partiality. we hypothesize that a general problem formulation exists for this setting, one that
        could be tackled with an end-to-end learning framework designed specifically to infer symmetries under severe data incompleteness.
        developingsuch methods could significantly broaden the applicability of symmetry detection algorithms in real-world conditions,
        such as robotics, archaeology, and autonomous mapping. d. symmetry-aware generative models 3d generative models have recently
        gained substantial trac- tion, producing increasingly high-quality results across various tasks [77]. however, symmetry—a
        pervasive and meaningful property in man-made and natural objects—is rarely used as an explicit inductive bias or quality
        criterion during training. we believe that incorporating symmetry awareness into the generative process could enhance the
        plausibility, regularity, and aesthetic quality of generated 3d shapes. there is prece- dent for this idea in crystallography
        [78], [79] and molecular design [80], where symmetry constraints are crucial for gen- erating physically valid structures.
        imposing such structural priors in generative modeling could pave the way for higher- quality 3d data synthesis, particularly in
        applications where geometric consistency is critical. v. f inal remarks symmetry remains a central concept in the understanding
        and representation of 3d shapes, offering both aesthetic and structural insights across a wide range of disciplines. over the past
        two decades, the field has evolved from handcrafted geometric algorithms to learning-based methods capable of capturing complex
        symmetries from data. despite these ad- vances, several key challenges remain unresolved. the lack of standardized and diverse
        datasets continues to limit fair comparison and generalization. deep learning models, while powerful, often struggle with
        out-of-distribution generaliza- tion and incomplete inputs. moreover, symmetry—a highly structured and ubiquitous property—is
        still underutilized in generative modeling pipelines. in this work, we have presented a unified view of the com- putational
        approaches for symmetry detection in 3d shapes, emphasizing their motivations, methodologies, and applica- tions. we believe that
        future progress will depend on develop- ing methods that are not only accurate but also data-efficient, interpretable, and robust
        to real-world conditions. in particular, bridging geometric structure and data-driven learning holds great promise for creating
        models that better understand and leverage symmetry. ultimately, symmetry is more than a geometric property—it is a powerful
        organizational principle. harnessing it effectively may lead to more compact representations, better reconstruc- tions, and more
        meaningful generations of 3d content. as such, it continues to offer fertile ground for fundamental research and impactful
        applications. vi. a cknowledgments this work was funded by anid - fondecyt regular - project, chile 1251263 and by national center
        for artificial intelligence cenia fb210017, basal anid, chile. references [1] m. li, f. c. langbein, and r. r. martin, “detecting
        approximate symmetries of discrete point subsets,” comput. aided des. , vol. 40, no. 1, pp. 76–93, jan. 2008. [2] m. chang and s.
        c. park, “reverse engineering of a symmetric object,” computers & industrial engineering , vol. 55, no. 2, pp. 311–320, 2008. [3]
        j. jiang, z. chen, and k. he, “a feature-based method of rapidly detecting global exact symmetries in {cad }models,”
        computer-aided design , vol. 45, no. 8–9, pp. 1081–1094, 2013. [4] k. li, g. foucault, j.-c. l ´eon, and m. trlin, “fast global
        and partial reflective symmetry analyses using boundary surfaces of mechanical components,” computer-aided design , vol. 53, pp.
        70–89, 2014. [5] a. mu, z. liu, g. duan, and j. tan, “structural regularity detection and enhancement for surface mesh
        reconstruction in reverse engineering,” computer-aided design , vol. 177, p. 103780, 2024. [6] a. cohen, c. zach, s. sinha, and m.
        pollefeys, “discovering and ex- ploiting 3d symmetries in structure from motion,” in cvpr . computer vision and patter
        recognition, june 2012. [7] d. ceylan, n. j. mitra, y . zheng, and m. pauly, “coupled structure- from-motion and 3d symmetry
        detection for urban facades,” acm trans. graph. , vol. 33, no. 1, pp. 2:1–2:15, feb. 2014. [8] r. p. de figueiredo, p. moreno, and
        a. bernardino, “efficient pose estimation of rotationally symmetric objects,” neurocomputing , vol. 150, part a, pp. 126–135,
        2015. [9] s. wu, c. rupprecht, and a. vedaldi, “unsupervised learning of probably symmetric deformable 3d objects from images in
        the wild,” in proceedings of the ieee conference on computer vision and pattern recognition (cvpr) , 2020. [10] q. liao, x. jin,
        and w. zeng, “enhancing the symmetry and propor- tion of 3d face geometry,” ieee transactions on visualization and computer
        graphics , vol. 18, no. 10, pp. 1704–1716, 2012. [11] k. son, e. almeida, and d. cooper, “axially symmetric 3d pots config-
        uration system using axis of symmetry and break curve,” in computer vision and pattern recognition (cvpr), 2013 ieee conference on
        , june 2013, pp. 257–264. [12] b. xia, b. ben amor, h. drira, m. daoudi, and l. ballihi, “gender and 3d facial symmetry: what’s
        the relationship?” in automatic face and gesture recognition (fg), 2013 10th ieee international conference and workshops on ,
        april 2013, pp. 1–6. [13] g. harary, a. tal, and e. grinspun, “context-based coherent surface completion,” acm trans. graph. ,
        vol. 33, no. 1, pp. 5:1–5:12, feb. 2014. [14] e. li, x. zhang, and y . chen, “symmetry based chinese ancient architecture
        reconstruction from incomplete point cloud,” in digital home (icdh), 2014 5th international conference on , nov 2014, pp. 157–161.
        [15] i. sipiran, r. gregor, and t. schreck, “approximate symmetry detection in partial 3d meshes,” comput. graph. forum , vol. 33,
        no. 7, pp. 131– 140, oct. 2014. [16] s. mansouri and h. ebrahimnezhad, “efficient axial symmetry aware mesh approximation with
        application to 3d pottery models,” multimedia tools and applications , pp. 1–33, 2015. [17] p. mavridis, i. sipiran, a. andreadis,
        and g. papaioannou, “object completion using k-sparse optimization,” computer graphics forum , vol. 34, no. 7, pp. 13–21, 2015.
        [18] w. shui and f. gao, “a geometric completion and shape analysis method for damaged bilaterally symmetrical artifacts,” journal
        of cultural heritage , vol. 52, pp. 118–127, 2021. [19] j. xu, w. cao, b. liu, and k. jiang, “object restoration based on
        extrinsic reflective symmetry plane detection,” vis. comput. , vol. 38, no. 11, p. 3627–3642, nov. 2022. [20] w. shui, p. wei, x.
        zheng, and s. geng, “a landmark-free approach for surface asymmetry detection and profile drawings from bilaterally symmetrical
        geometry,” j. comput. cult. herit. , vol. 16, no. 2, jun. 2023. [21] i. sipiran, “the role of computing in the study of latin
        american cultural heritage,” commun. acm , vol. 67, no. 8, p. 58–62, aug. 2024. [22] w. qiu, j. yuan, e. ukwatta, y . sun, m.
        rajchl, and a. fenster, “prostate segmentation: an efficient convex optimization approach with axial symmetry using 3-d trus and
        mr images,” medical imaging, ieee transactions on , vol. 33, no. 4, pp. 947–960, april 2014.[23] j. yuan, w. qiu, m. rajchl, e.
        ukwatta, x.-c. tai, and a. fenster, “efficient 3d endfiring trus prostate segmentation with globally optimized rotational
        symmetry,” 2014 ieee conference on computer vision and pattern recognition , vol. 0, pp. 2211–2218, 2013. [24] j. fotouhi, g.
        taylor, m. unberath, a. johnson, s. c. lee, g. osgood, m. armand, and n. navab, “exploring partial intrinsic and extrinsic
        symmetry in 3d medical imaging,” medical image analysis , vol. 72, p. 102127, 2021. [25] j. li, k. xu, s. chaudhuri, e. yumer, h.
        zhang, and l. guibas, “grass: generative recursive autoencoders for shape structures,” acm trans. graph. , vol. 36, no. 4, jul.
        2017. [26] c. zhu, k. xu, s. chaudhuri, r. yi, and h. zhang, “scores: shape composition with recursive substructure priors,” acm
        trans. graph. , vol. 37, no. 6, dec. 2018. [27] k. mo, p. guerrero, l. yi, h. su, p. wonka, n. j. mitra, and l. j. guibas,
        “structurenet: hierarchical graph networks for 3d shape generation,” acm trans. graph. , vol. 38, no. 6, nov. 2019. [28] j. li, c.
        niu, and k. xu, “learning part generation and assembly for structure-aware shape synthesis,” in the thirty-fourth aaai conference
        on artificial intelligence, aaai 2020, the thirty-second innovative applications of artificial intelligence conference, iaai 2020,
        the tenth aaai symposium on educational advances in artificial intelligence, eaai 2020, new york, ny, usa, february 7-12, 2020 .
        aaai press, 2020, pp. 11 362–11 369. [29] y . he, q. fang, z. zhang, t. dai, k. wu, l. liu, and x.-m. fu, “symmetric piecewise
        developable approximations,” computer graph- ics forum , vol. 43, no. 7, p. e15242, 2024. [30] a. martinet, c. soler, n.
        holzschuch, and f. x. sillion, “accurate detection of symmetries in 3d shapes,” acm trans. graph. , vol. 25, no. 2, pp. 439–464,
        apr. 2006. [31] b. li, h. johan, y . ye, and y . lu, “efficient view-based 3d reflection symmetry detection,” in siggraph asia
        2014 creative shape mod- eling and design , ser. sa ’14. new york, ny , usa: acm, 2014, pp. 2:1–2:8. [32] c. grushko, d. raviv,
        and r. kimmel, “intrinsic local symmetries: a computational framework,” in proceedings of the 5th eurographics conference on 3d
        object retrieval , ser. eg 3dor’12. aire-la-ville, switzerland, switzerland: eurographics association, 2012, pp. 33–38. [33] r.
        kakarala, p. kaliamoorthi, and v . premachandran, “three- dimensional bilateral symmetry plane estimation in the phase do- main,”
        in computer vision and pattern recognition (cvpr), 2013 ieee conference on , june 2013, pp. 249–256. [34] m. ovsjanikov, q. m
        ´erigot, v . p ˘atr˘aucean, and l. guibas, “shape matching via quotient spaces,” in proceedings of the eleventh eu-
        rographics/acmsiggraph symposium on geometry processing , ser. sgp ’13. aire-la-ville, switzerland, switzerland: eurographics
        asso- ciation, 2013, pp. 1–11. [35] z. zhang, k. yin, and k. w. c. foong, “symmetry robust descriptor for non-rigid surface
        matching.” comput. graph. forum , vol. 32, no. 7, pp. 355–362, 2013. [36] x. jiang, j. sun, and l. guibas, “a fourier-theoretic
        approach for inferring symmetries,” comput. geom. theory appl. , vol. 47, no. 2, pp. 164–174, feb. 2014. [37] h. wang, p. simari,
        z. su, and h. zhang, “spectral global intrinsic symmetry invariant functions,” in proceedings of graphics interface 2014 , ser. gi
        ’14. toronto, ont., canada, canada: canadian information processing society, 2014, pp. 209–215. [38] x. liu, s. li, r. liu, j.
        wang, h. wang, and j. cao, “properly constrained orthonormal functional maps for intrinsic symmetries,” computers & graphics ,
        vol. 46, pp. 198–208, 2015, shape modeling international 2014. [39] t. liu, v . g. kim, and t. funkhouser, “finding surface
        correspon- dences using symmetry axis curves,” comp. graph. forum , vol. 31, no. 5, pp. 1607–1616, aug. 2012. [40] v . g. kim, y .
        lipman, and t. funkhouser, “blended intrinsic maps,” acm trans. graph. , vol. 30, no. 4, pp. 79:1–79:12, jul. 2011. [41] a. tevs,
        q. huang, m. wand, h.-p. seidel, and l. guibas, “relat- ing shapes via geometric symmetries and regularities,” acm trans. graph. ,
        vol. 33, no. 4, pp. 119:1–119:12, jul. 2014. [42] n. mitra, a. bronstein, and m. bronstein, “intrinsic regularity detec- tion in
        3d geometry,” in computer vision – eccv 2010 , ser. lecture notes in computer science, k. daniilidis, p. maragos, and n. paragios,
        eds. springer berlin heidelberg, 2010, vol. 6313, pp. 398–410. [43] d. raviv, a. m. bronstein, m. m. bronstein, and r. kimmel,
        “full and partial symmetries of non-rigid shapes,” int. j. comput. vision , vol. 89, no. 1, pp. 18–39, aug. 2010. [44] d. raviv,
        m. m. bronstein, g. sapiro, a. m. bronstein, and r. kimmel, “diffusion symmetries of non-rigid shapes,” in in proc. 3dpvt , 2010.
        [45] a. berner, m. wand, n. j. mitra, d. mewes, and h. seidel, “shape analysis with subspace symmetries,” comput. graph. forum ,
        vol. 30, no. 2, pp. 277–286, 2011. [46] y . wang, k. xu, j. li, h. zhang, a. shamir, l. liu, z. cheng, and y . xiong, “symmetry
        hierarchy of man-made objects,” comput. graph. forum , vol. 30, no. 2, pp. 287–296, 2011. [47] a. shehu, a. brunton, s. wuhrer,
        and m. wand, “characterization of partial intrinsic symmetries,” in computer vision - eccv 2014 workshops , ser. lecture notes in
        computer science, l. agapito, m. m. bronstein, and c. rother, eds. springer international publishing, 2015, vol. 8928, pp.
        267–282. [48] y . yoshiyasu, e. yoshida, k. yokoi, and r. sagawa, “symmetry-aware nonrigid matching of incomplete 3d surfaces,” in
        computer vision and pattern recognition (cvpr), 2014 ieee conference on , june 2014, pp. 4193–4200. [49] r. nagar, “robust
        extrinsic symmetry estimation in 3d point clouds,” vis. comput. , vol. 41, no. 1, p. 115–128, mar. 2024. [50] b. tosyalı and y .
        sahillio ˘glu, “intrinsic reflective symmetry axis curve generation for meshes,” in proceedings of computer graphics inter-
        national 2025 . new york, ny , usa: association for computing machinery, 2025. [51] y . lipman, x. chen, i. daubechies, and t.
        funkhouser, “symmetry factored embedding and distance,” acm trans. graph. , vol. 29, no. 4, pp. 103:1–103:12, jul. 2010. [52] w.
        jiang, k. xu, z.-q. cheng, and h. zhang, “skeleton-based intrinsic symmetry detection on point clouds,” graphical models , vol.
        75, no. 4, pp. 177–188, 2013. [53] n. j. mitra, l. j. guibas, and m. pauly, “partial and approximate symmetry detection for 3d
        geometry,” acm trans. graph. , vol. 25, no. 3, pp. 560–568, jul. 2006. [54] m. pauly, n. j. mitra, j. wallner, h. pottmann, and l.
        j. guibas, “discovering structural regularity in 3d geometry,” acm trans. graph. , vol. 27, no. 3, 2008. [55] q. zheng, a. sharf,
        g. wan, y . li, n. j. mitra, d. cohen-or, and b. chen, “non-local scan consolidation for 3d urban scenes,” acm trans. graph. ,
        vol. 29, no. 4, pp. 94:1–94:9, jul. 2010. [56] k. xu, h. zhang, w. jiang, r. dyer, z. cheng, l. liu, and b. chen, “multi-scale
        partial intrinsic symmetry detection,” acm trans. graph. , vol. 31, no. 6, pp. 181:1–181:11, nov. 2012. [57] s. korman, r. litman,
        s. avidan, and a. bronstein, “probably ap- proximately symmetric: fast rigid symmetry detection with global guarantees,” comput.
        graph. forum , vol. 34, no. 1, pp. 2–13, feb. 2015. [58] r. nagar and s. raman, “detecting approximate reflection symmetry in a
        point set using optimization on manifold,” ieee transactions on signal processing , vol. 67, no. 6, pp. 1582–1595, 2019. [59] a.
        c. pablo speciale, martin r. oswald and m. pollefeys, “a symmetry prior for convex variational 3d reconstruction,” in european
        conference on computer vision (eccv) , 2016. [60] a. ecins, c. ferm ¨uller, and y . aloimonos, “detecting reflectional symmetries
        in 3d data through symmetrical fitting,” in 2017 ieee international conference on computer vision workshops (iccvw) , 2017, pp.
        1779–1783. [61] m. cicconet, d. g. c. hildebrand, and h. elliott, “finding mirror symmetry via registration and optimal symmetric
        pairwise assignment of curves,” in 2017 ieee international conference on computer vision workshops (iccvw) , 2017, pp. 1749–1758.
        [62] r. nagar and s. raman, “3dsymm: robust and accurate 3d reflection symmetry detection,” pattern recognition , vol. 107, p.
        107483, 2020. [63] l. hruda, i. kolingerov ´a, m. l ´aviˇcka, and m. ma ˇn´ak, “rotational symmetry detection in 3d using
        reflectional symmetry candidates and quaternion-based rotation parameterization,” computer aided geometric design , vol. 98, p.
        102138, 2022. [64] t. p. nguyen and t. t. nguyen, “robust detectors of rotationally symmetric shapes based on novel semi-shape
        signatures,” pattern recog- nition , vol. 138, p. 109336, 2023. [65] m. bizzarri, l. hruda, m. l ´aviˇcka, and j. vr ˇsek,
        “symmetry group detection of point clouds in 3d via a decomposition method,” computer aided geometric design , vol. 113, p.
        102376, 2024.[66] s. bu, p. han, z. liu, j. han, and h. lin, “local deep feature learning framework for 3d shapes,” computers and
        graphics , vol. 46, pp. 117– 129, 2015, shape modeling international 2014. [67] p. ji and x. liu, “a fast and efficient 3d
        reflection symmetry detector based on neural networks,” multimedia tools and applications , vol. 78, pp. 35 471 – 35 492, 2019.
        [68] l. gao, l. x. zhang, h. y . meng, y . h. ren, y . k. lai, and l. kobbelt, “prs-net: planar reflective symmetry detection net
        for 3d models,” ieee transactions on visualization and computer graphics , pp. 1–1, 2020. [69] y . shi, j. huang, h. zhang, x. xu,
        s. rusinkiewicz, and k. xu, “sym- metrynet: learning to predict reflectional and rotational symmetries of 3d shapes from
        single-view rgb-d images,” acm trans. graph. , vol. 39, no. 6, nov. 2020. [70] y . shi, x. xu, j. xi, x. hu, d. hu, and k. xu,
        “learning to detect 3d symmetry from single-view rgb-d images with weak supervision,” ieee transactions on pattern analysis and
        machine intelligence , vol. 45, no. 4, pp. 4882–4896, 2023. [71] r.-w. li, l.-x. zhang, c. li, y .-k. lai, and l. gao, “e3sym:
        lever- aging e(3) invariance for unsupervised 3d planar reflective symmetry detection,” in proceedings of the ieee/cvf
        international conference on computer vision (iccv) , october 2023, pp. 14 543–14 553. [72] j. je, j. liu, g. yang, b. deng, s.
        cai, g. wetzstein, o. litany, and l. guibas, “robust symmetry detection via riemannian langevin dynamics,” in siggraph asia 2024
        conference papers , ser. sa ’24. new york, ny , usa: association for computing machinery, 2024. [73] i. aguirre, i. sipiran, and
        g. monta ˜nana, “a dataset-free approach for self-supervised learning of 3d reflectional symmetries,” 2025. [74] i. aguirre and i.
        sipiran, “training-free zero-shot 3d symmetry detection with visual features back-projected to geometry,” 2025. [75] a. x. chang,
        t. funkhouser, l. guibas, p. hanrahan, q. huang, z. li, s. savarese, m. savva, s. song, h. su, j. xiao, l. yi, and f. yu,
        “shapenet: an information-rich 3d model repository,” arxiv preprint, tech. rep. 1512.03012, dec. 2015. [76] i. sipiran, c.
        romanengo, b. falcidieno, s. biasotti, g. arvanitis, c. chen, v . fotis, j. he, x. lv, k. moustakas et al. , “shrec 2023:
        detection of symmetries on 3d point clouds representing simple shapes,” ineurographics workshop on 3d object retrieval . the
        eurographics association, 2023, pp. 17–237. [77] n. caytuiro and i. sipiran, “3d shape generation: a survey,” 2025. [78] d. levy,
        s. s. panigrahi, s.-o. kaba, q. zhu, k. l. k. lee, m. galkin, s. miret, and s. ravanbakhsh, “symmcd: symmetry- preserving crystal
        generation with diffusion models,” 2025. [online]. available: https://arxiv.org/abs/2502.03638 [79] f. e. kelvinius, o. b.
        andersson, a. s. parackal, d. qian, r. armiento, and f. lindsten, “wyckoffdiff – a generative diffusion model for crystal
        symmetry,” 2025. [online]. available: https://arxiv.org/abs/2502.06485 [80] k. sareen, d. levy, a. k. mondal, s.-o. kaba, t.
        akhound- sadegh, and s. ravanbakhsh, “symmetry-aware generative modeling through learned canonicalization,” 2025. [online].
        available: https://arxiv.org/abs/2501.07773
  > CONTRIBUIÇÃO:
    Não encontrado.

4. RESUMO GERAL:
    finally, we identify key open problems and future directions, including the need
    for richer and more varied datasets, better generalization of learning-based
    models, effective formulations for symmetry detection in incomplete data, and
    the integration of symmetry priors in generative modeling. in that case, we do
    not this work is supported by anid chile—fondecyt n° 1251263 and national center
    for artificial intelligence cenia fb210017, basal anid, chile.need to store the
    whole image but only the part that is not repeated and thus be able to reproduce
    the original image with the knowledge of symmetries. the method detects
    potential key points in the 3d shape and computes a matrix of geodesic distances
    between the key points and the remaining points on the surface. reference name
    mitra et al. 2006 [53] partial and approximate symmetries pauly et al. 2008 [54]
    structural regularity detection lipman et al. 2010 [51] symmetry factored
    embedding zheng et al. 2010 [55] non-local scan consolidation xu et al. 2012
    [56] multi-scale partial intrinsic symmetry jiang et al. 2013 [52]
    skeleton-based intrinsic symmetry sipiran et al. 2014 [15] approximate symmetry
    in meshes table iii method with the voting -based approach . 5) learning-based
    methods: in this approach, the meth- ods take advantage of the recent progress
    in deep learningreference name korman et al. 2015 [57] provably approximately
    symmetries mavridis et al. 2015 [17] k-sparse optimization speciale et al. 2016
    [59] convex variational ecins et al. 2017 [60] symmetrical fitting cicconet et
    al. 2017 [61] pairwise alignment of curves nagar et al. 2019 [58] symmetry by
    manifold optimization nagar et al. 2020 [62] 3dsymm: reflection symmetry
    detection hruda et al. 2022 [63] rotational symmetry detection nguyen et al.
    2023 [64] symmetric semi-shape signatures bizarri et al. 2024 [65] group
    symmetry by decomposition table iv method with the optimization -based approach
    . reference name bu et al. 2015 [66] local deep feature learning ji et al. 2019
    [67] 3d reflectional detector with neural network gao et al. 2020 [68] prs-net
    shi et al. 2020 [69] symmetrynet shi et al. 2023 [70] detection with weak
    supervision li et al. 2023 [71] equivariant symmetry detection je et al. 2024
    [72] langevin dynamics for symmetry detection aguirre et al. 2025 [73]
    self-prior symmetry detection aguirre et al. 2025 [74] training-free zero-shot
    symmetry detection table v method with the learning -based approach .

==================================================

--- ARTIGO: articles/The Flow of Creation A Tour of Flow Matching for Visuals.pdf ---

1. TOP 10 TERMOS:
    - x              : 64
    - flow           : 61
    - xi             : 52
    - matching       : 50
    - p              : 35
    - distribution   : 29
    - vector         : 28
    - generation     : 28
    - field          : 26
    - data           : 22

2. REFERÊNCIAS EXTRAÍDAS (16 total):
    [1] [1] y . lipman, r. t. chen, h. ben-hamu, m. nickel, and m. le, “flow matching for
generative modeling,” in the eleventh international con- ference on learning
representations , 2022.
    [2] [2] y . lipman, m. havasi, p. holderrieth, n. shaul, m. le, b. karrer, r. t. chen, d.
lopez-paz, h. ben-hamu, and i. gat, “flow matching guide and code,” arxiv preprint
arxiv:2412.06264 , 2024.
    [3] [3] p. holderrieth and e. erives, “introduction to flow matching and diffusion models,”
2025. [online]. available: https://diffusion.csail.mit. edu/
    [4] [4] l. perko, differential equations and dynamical systems . springer science & business
media, 2013, vol. 7.
    [5] [5] t. q. chen, y . rubanova, j. bettencourt, and d. duvenaud, “neural ordinary
differential equations,” corr , vol. abs/1806.07366, 2018. [online]. available:
http://arxiv.org/abs/1806.07366
    [6] [6] j. ho and t. salimans, “classifier-free diffusion guidance,” arxiv preprint
arxiv:2207.12598 , 2022.
    [7] [7] i. gat, t. remez, n. shaul, f. kreuk, r. t. chen, g. synnaeve, y . adi, and y .
lipman, “discrete flow matching,” advances in neural information processing systems , vol.
37, pp. 133 345–133 385, 2024.
    [8] [8] z. ye, t. zhong, y . ren, j. yang, w. li, j. huang, z. jiang, j. he, r. huang, j. liu,
c. zhang, x. yin, z. ma, and z. zhao, “mimictalk: mimicking a personalized and expressive
3d talking face in few min- utes,” 2024.
    [9] [9] a. chatziagapi, l.-p. morency, h. gong, m. zollh ¨ofer, d. samaras, and a. richard,
“av-flow: transforming text to audio-visual human-like interactions,” arxiv preprint
arxiv:2502.13133 , 2025.
    [10] [10] v . t. hu, w. yin, p. ma, y . chen, b. fernando, y . m. asano, e. gavves, p. mettes,
b. ommer, and c. g. snoek, “motion flow matching for human motion synthesis and editing,”
arxiv preprint arxiv:2312.08895 , 2023.
    [11] [11] m. canales cuba, v . do carmo mel ´ıcio, and j. p. gois, “flowmotion:
target-predictive conditional flow matching for jitter-reduced text- driven human motion
generation,” computers & graphics , vol. 132, p. 104374, 2025. [online]. available:
https://www.sciencedirect.com/ science/article/pii/s0097849325002158
    [12] [12] j. yan, z. cui, w. yan, y . chen, m. pu, s. li, and s. ye, “robust and reliable de
novo protein design: a flow-matching-based protein generative model achieves remarkably
high success rates,” biorxiv , pp. 2025–04, 2025.
    [13] [13] j. cremer, r. irwin, a. tibo, j. p. janet, s. olsson, and d.-a. clevert, “flowr: flow
matching for structure-aware de novo, interaction-and fragment-based ligand generation,”
arxiv preprint arxiv:2504.10564 , 2025.
    [14] [14] f. zhang and m. gienger, “affordance-based robot manipulation with flow matching,”
arxiv preprint arxiv:2409.01083 , 2024.
    [15] [15] n. funk, j. urain, j. carvalho, v . prasad, g. chalvatzaki, and j. peters,
“actionflow: equivariant, accurate, and efficient policies with spatially symmetric flow
matching,” arxiv preprint arxiv:2409.04576 , 2024.
    [16] [16] n. shaul, u. singer, i. gat, and y . lipman, “transition matching: scalable and
flexible generative modeling,” 2025. [online]. available: https://arxiv.org/abs/2506.23589

3. PARÁGRAFOS RELEVANTES (TOP-1):
  > OBJETIVO:
    Score: 5.005
        the flow of creation: a tour of flow matching for visuals manolo canales cuba universidade federal do abc santo andr ´e, brazil,
        09280-560 email: manolo.canales@ufabc.edu.brvin´ıcius do carmo mel ´ıcio universidade federal do abc santo andr ´e, brazil,
        09280-560 email: vinicius.melicio@ufabc.edu.brjo˜ao paulo gois universidade federal do abc santo andr ´e, brazil, 09280-560 email:
        joao.gois@ufabc.edu.br abstract —flow matching has recently emerged as an efficient alternative to the generative method
        paradigms. here we aim to provide researchers and practitioners with both the theoretical and the practical aspects of this
        technique. we delve into the con- tinuous formulation, where a neural network learns a vector field to transform noise into data
        via an ordinary differential equation, and also explore its discrete counterpart. the paper covers the entire workflow, from the
        core mathematical concepts and training objectives to sampling procedures, including classifier- free guidance and conditioning
        generation. by showcasing a diverse range of applications—from image synthesis and human motion generation to computational
        biology and robotics—this work equips readers with the essential knowledge to apply and innovate with the versatile and
        computationally efficient flow matching framework. index terms —flow matching, discrete generative models, deep learning. i. i
        ntroduction generative modeling has become a cornerstone of modern artificial intelligence, yielding state-of-the-art results that
        are highly relevant to many fields, including computer graphics and vision. we can quickly exemplify some very popular generative
        models that have been used in various fields: text- to-image synthesis, such as dall-e 3 and stable diffusion; large language
        models, including chatgpt and gemini; and video generation capabilities, like flux and veo. one of the predominant approaches that
        has produced successes is the denoising diffusion model, which iteratively transforms a noise distribution into a sample from a
        complex data distribu- tion, demonstrating effective performance across various data modalities, including images, audio, and 3d
        shapes. within this context of rapid innovation, flow matching emerges as a promising alternative to diffusion-based ap- proaches
        for generative models, featuring faster inference times and a simplified mathematical formulation. by simulat- ing an ordinary
        differential equation (ode) with deep neural networks, flow matching presents a computationally efficient and conceptually elegant
        approach to generative modeling. unlike denoising diffusion models, which rely on stochastic differential equations (sde) and thus
        introduce stochasticity during inference, flow matching enables deterministic infer- ence, contributing to a mathematically
        simpler process.this paper provides a practical and conceptual overview of flow matching, focusing on the continuous formulation
        introduced by lipman et al. [1], with a dedicated section on its discrete counterpart [2]. the objective is to offer an accessible
        entry point for researchers and practitioners interested in understanding and implementing flow matching methods. we present
        applications where flow matching has been successfully employed and conclude this document by high- lighting some challenges,
        future directions, and additional topics not covered here. ii. t heoretical foundations : flow matching the theoretical foundation
        for flow matching, presented here, is drawn from the seminal contributions of lipman et al. [1], [2], and the comprehensive
        materials of the online course provided by holderrieth and ezra [3]. the objective of flow matching is to transport points
        organized according to a simple and determined density p0 to a more complex density p1that approximates the data distribution q.
        this transport of points is achieved through a function ψt. an initial point x0=ψ0(x0)at time t= 0 is mapped to a final point
        x1=ψ1(x0)at time t= 1 by the transport function ψt. one approach to defining this function is to describe it using an ode. to this
        end, we assume the existence of a vector fieldut: d dtψt(x) =ut(ψt(x)), ψ0(x0) =x0.(1) given this ode, the existence and
        uniqueness of a solution ψtare guaranteed if certain regularity conditions are met by ut[4]. these conditions ensure that the ode
        is well-behaved, allowing for a stable and predictable solution. because we will parameterize this vector field using a neural
        network, we implicitly satisfy these conditions, as neural networks typically have bounded derivatives [3]. the solution ψtthen
        traces the path that carries x0tox1over time (fig. 1). consequently, ψt is a differentiable function with a differentiable
        inverse, called aflow. similarly, utis time-dependent, and both are defined in the data space rd, where dis the dimensionality of
        the data. at the same time, we want to ensure that the transport of these data maintains the existence of a density function ptfor
        979-8-3315-8951-6/25/$31.00 ©2025 ieee allt∈[0,1]. we consider initial points x0∼p0as elements of a random variable x0. our goal
        is to ensure that at any time t, the random variable xthas a distribution pt, thus x1∼p1. the set of functions {pt}t∈[0,1]is
        called a probability path (fig. 2). these time-dependent functions are also determined by the vector field ut, which ensures their
        existence through a continuity equation: d dtpt(x) + div( pt(x)ut(x)) = 0 . (2) when this condition is satisfied, we say that the
        vector field utgenerates pt[1]. the vector field, flow, and probability path are thus related and dependent. it is worth noting
        that the ode definition allows calculating the vector field from the flow, reinforcing the interconnectedness of these objects.
        fig. 1. illustration of a solution trajectory ψtof the ode defined by the vector field ut. when the ode is initialized with a
        point x0, the solution ψt represents the trajectory of that point through the vector field. in this example, a noisy color image
        with distribution p0is transformed into a defined, noise- free final image with distribution p1at time t= 1. following the
        proposal of chen et al. [5], we can pa- rameterize the vector field utusing deep neural networks and, in consequence, define the
        flow ψand the probability path. we denote this parameterized vector field as uθ t, where θ∈rℓrepresents its parameters. then, the
        optimal choice of parameters θcan be obtained by minimizing the loss function: lfm(θ) =et,x∼pt
  > PALAVRAS-CHAVES:
    Não encontrado.
  > PROBLEMA:
    Score: 1.002
        2 , (3) where t∼ u(0,1)is sampled from a uniform distribution. a key challenge arises from the fact that the true vector field
        utis unknown. furthermore, we only have an initial sample of points d={xi}n i=1,xi∈rd, from the data distribution q; that is,
        xi∼q. to address this challenge, lipman et al. [1] propose constructing a vector field conditioned on d, leveraging conditional
        probability paths and flows also constructed with respect to d. a. construction of the conditional vector field following lipman
        et al. [1], a conditional probability path pt(·|xi)is constructed for each data point xi∈ d . these fig. 2. illustration of the
        probability path ptshowing the evolution of a noisy image (distribution p0) through intermediate states to a clean image
        (distribution p1). paths are defined as gaussian functions. at the initial time t= 0, as we know p0(·|xi) =p0, where p0is
        considered a normal distribution, specifically p0=n(0, σ2i), with σ= 1. recalling that the goal of flow matching is to transform
        simple distributions into complex ones, the choice of a normal distribution as the initial distribution is coherent. similarly, at
        the final time t= 1, we have p1(·|xi) =n(xi, σ2 mini), where the mean is xiand the standard deviation σmin>0is chosen to be
        sufficiently small to isolate xifrom other values in d (fig. 3). thus, pt(·|xi)is defined as the interpolation of means and
        standard deviations between these two extremes, yielding: pt(x|xi) =n(x;µt(xi), σt(xi)2i), (4) where µt(xi) =txiandσt(xi) =
        1−(1−σmin)t. substituting into eq. 4 yields: pt(x|xi) =n(x;txi,(1−(1−σmin)t)2i). (5) from this conditional probability path, a
        corresponding conditional flow ψt(·|xi)can be constructed. this construction leverages the gaussian probability path to define a
        function for transporting points. by employing the reparameterization trick, which allows transforming samples from one gaussian
        distribution to another, we indirectly define this transport function. specifically, given a point x0sampled from a normal
        distribution x0∼ n(0, i) =p0, we obtain the parameters ( µt, σt) of the target distribution pt. the point σt(xi)x0+µt(xi) then
        constitutes a sample from the distribution pt. thus, for some x0, the conditional flow is generally defined as: ψt(x0|xi)
        =σt(xi)x0+µt(xi). (6) substituting the corresponding expressions for σtandµt, we have: ψt(x0|xi) = (1 −(1−σmin)t)x0+txi. (7) this
        function has distribution pt, is linear, and therefore differentiable with a differentiable inverse, meaning it is a
        diffeomorphism. fig. 3. flow matching as a transport from a normal distribution p0to a narrow gaussian target p1centered at a
        dataset sample xi(illustrated here by the cat). the intermediate distributions ptdescribe a conditional probability path
        connecting p0andp1. for each xi∈ d , we can define the conditional vector field ut(·|xi). given the diffeomorphism ψt(·|xi), we
        define an ode, similar to eq. 1, under which we can define ut(·|xi). given that xt=ψt(x0|xi), then: ut(xt|xi) =∂ ∂tψt(x0|xi) =∂
        ∂th σt(xi)x0+µt(xi)i =∂ ∂th (1−(1−σmin)t)x0+txii =−(1−σmin)x0+xi. under this definition of ut, we can define a parameterized deep
        neural network uθ t, such that the optimal parameter θis found by minimizing the loss function: lcfm(θ) =et,xt∼pt(·|xi),xi∼q
  > CONTRIBUIÇÃO:
    Score: 2.002
        the flow of creation: a tour of flow matching for visuals manolo canales cuba universidade federal do abc santo andr ´e, brazil,
        09280-560 email: manolo.canales@ufabc.edu.brvin´ıcius do carmo mel ´ıcio universidade federal do abc santo andr ´e, brazil,
        09280-560 email: vinicius.melicio@ufabc.edu.brjo˜ao paulo gois universidade federal do abc santo andr ´e, brazil, 09280-560 email:
        joao.gois@ufabc.edu.br abstract —flow matching has recently emerged as an efficient alternative to the generative method
        paradigms. here we aim to provide researchers and practitioners with both the theoretical and the practical aspects of this
        technique. we delve into the con- tinuous formulation, where a neural network learns a vector field to transform noise into data
        via an ordinary differential equation, and also explore its discrete counterpart. the paper covers the entire workflow, from the
        core mathematical concepts and training objectives to sampling procedures, including classifier- free guidance and conditioning
        generation. by showcasing a diverse range of applications—from image synthesis and human motion generation to computational
        biology and robotics—this work equips readers with the essential knowledge to apply and innovate with the versatile and
        computationally efficient flow matching framework. index terms —flow matching, discrete generative models, deep learning. i. i
        ntroduction generative modeling has become a cornerstone of modern artificial intelligence, yielding state-of-the-art results that
        are highly relevant to many fields, including computer graphics and vision. we can quickly exemplify some very popular generative
        models that have been used in various fields: text- to-image synthesis, such as dall-e 3 and stable diffusion; large language
        models, including chatgpt and gemini; and video generation capabilities, like flux and veo. one of the predominant approaches that
        has produced successes is the denoising diffusion model, which iteratively transforms a noise distribution into a sample from a
        complex data distribu- tion, demonstrating effective performance across various data modalities, including images, audio, and 3d
        shapes. within this context of rapid innovation, flow matching emerges as a promising alternative to diffusion-based ap- proaches
        for generative models, featuring faster inference times and a simplified mathematical formulation. by simulat- ing an ordinary
        differential equation (ode) with deep neural networks, flow matching presents a computationally efficient and conceptually elegant
        approach to generative modeling. unlike denoising diffusion models, which rely on stochastic differential equations (sde) and thus
        introduce stochasticity during inference, flow matching enables deterministic infer- ence, contributing to a mathematically
        simpler process.this paper provides a practical and conceptual overview of flow matching, focusing on the continuous formulation
        introduced by lipman et al. [1], with a dedicated section on its discrete counterpart [2]. the objective is to offer an accessible
        entry point for researchers and practitioners interested in understanding and implementing flow matching methods. we present
        applications where flow matching has been successfully employed and conclude this document by high- lighting some challenges,
        future directions, and additional topics not covered here. ii. t heoretical foundations : flow matching the theoretical foundation
        for flow matching, presented here, is drawn from the seminal contributions of lipman et al. [1], [2], and the comprehensive
        materials of the online course provided by holderrieth and ezra [3]. the objective of flow matching is to transport points
        organized according to a simple and determined density p0 to a more complex density p1that approximates the data distribution q.
        this transport of points is achieved through a function ψt. an initial point x0=ψ0(x0)at time t= 0 is mapped to a final point
        x1=ψ1(x0)at time t= 1 by the transport function ψt. one approach to defining this function is to describe it using an ode. to this
        end, we assume the existence of a vector fieldut: d dtψt(x) =ut(ψt(x)), ψ0(x0) =x0.(1) given this ode, the existence and
        uniqueness of a solution ψtare guaranteed if certain regularity conditions are met by ut[4]. these conditions ensure that the ode
        is well-behaved, allowing for a stable and predictable solution. because we will parameterize this vector field using a neural
        network, we implicitly satisfy these conditions, as neural networks typically have bounded derivatives [3]. the solution ψtthen
        traces the path that carries x0tox1over time (fig. 1). consequently, ψt is a differentiable function with a differentiable
        inverse, called aflow. similarly, utis time-dependent, and both are defined in the data space rd, where dis the dimensionality of
        the data. at the same time, we want to ensure that the transport of these data maintains the existence of a density function ptfor
        979-8-3315-8951-6/25/$31.00 ©2025 ieee allt∈[0,1]. we consider initial points x0∼p0as elements of a random variable x0. our goal
        is to ensure that at any time t, the random variable xthas a distribution pt, thus x1∼p1. the set of functions {pt}t∈[0,1]is
        called a probability path (fig. 2). these time-dependent functions are also determined by the vector field ut, which ensures their
        existence through a continuity equation: d dtpt(x) + div( pt(x)ut(x)) = 0 . (2) when this condition is satisfied, we say that the
        vector field utgenerates pt[1]. the vector field, flow, and probability path are thus related and dependent. it is worth noting
        that the ode definition allows calculating the vector field from the flow, reinforcing the interconnectedness of these objects.
        fig. 1. illustration of a solution trajectory ψtof the ode defined by the vector field ut. when the ode is initialized with a
        point x0, the solution ψt represents the trajectory of that point through the vector field. in this example, a noisy color image
        with distribution p0is transformed into a defined, noise- free final image with distribution p1at time t= 1. following the
        proposal of chen et al. [5], we can pa- rameterize the vector field utusing deep neural networks and, in consequence, define the
        flow ψand the probability path. we denote this parameterized vector field as uθ t, where θ∈rℓrepresents its parameters. then, the
        optimal choice of parameters θcan be obtained by minimizing the loss function: lfm(θ) =et,x∼pt

4. RESUMO GERAL:
    t heoretical foundations : flow matching the theoretical foundation for flow
    matching, presented here, is drawn from the seminal contributions of lipman et
    al. [1], [2], and the comprehensive materials of the online course provided by
    holderrieth and ezra [3]. the objective of flow matching is to transport points
    organized according to a simple and determined density p0 to a more complex
    density p1that approximates the data distribution q. this transport of points is
    achieved through a function ψt. in this example, a noisy color image with
    distribution p0is transformed into a defined, noise- free final image with
    distribution p1at time t= 1. following the proposal of chen et al. [5], we can
    pa- rameterize the vector field utusing deep neural networks and, in
    consequence, define the flow ψand the probability path. at the initial time t=
    0, as we know p0(·|xi) =p0, where p0is considered a normal distribution,
    specifically p0=n(0, σ2i), with σ= 1. recalling that the goal of flow matching
    is to transform simple distributions into complex ones, the choice of a normal
    distribution as the initial distribution is coherent. 2 ,(10) where xtis sampled
    from the conditional probability path pt(x|xi)as before, and uθ t(xt)now
    represents the neural network conditioned on the label y. following ho and
    salimans [6], we employ classifier-free guidance to improve the quality of the
    generated samples. the process starts at a state x0= (x1, x2)in the source
    distribution p0and follows a series of horizontal and vertical jumps (changing
    one token at a time) to reach a final state x1in the target distribution p1.

==================================================

--- ARTIGO: articles/When Art meets Computer Science a systematic review about technologies and user interaction in adaptive digital museums and archives.pdf ---

1. TOP 10 TERMOS:
    - digital        : 185
    - archives       : 86
    - user           : 80
    - interaction    : 69
    - works          : 59
    - studies        : 46
    - https          : 45
    - users          : 44
    - org            : 42
    - doi            : 40

2. REFERÊNCIAS EXTRAÍDAS (111 total):
    [1] [44] in digital archives is explicit. the researchers aimed at creating a digital
collection of indonesian customs, arts, and traditions to ensure these are not lost over
time. the “e-dayaknese” framework developed by the authors allows for the creation of
entirely new cultural products or the association of new items with existing ones. it
leverages a semantic structure based on the relationships between items, which facilitates
the discovery of related content. in the proposed architecture, the digital organization
of cultural data improves the consultation time and registration of new items. in addition
to that, one of its modules is responsible for collecting usertable 4: articles included
in this systematic review. # citation year rq1 rq2 rq3 1
    [2] [7] 2007 dis rs, peg vr 2
    [3] [9] 2009 dis rs, peg vr 3
    [4] [35] 2009 dis sq tp 4
    [5] [19] 2009 ava sq tp 5
    [6] [30] 2009 dis rs, folk tp 6
    [7] [12] 2010 ava do tp, vr 7
    [8] [2] 2010 dis chat tp 8
    [9] [43] 2012 dis rs, folk tp 9
    [10] [3] 2013 dis peg vr 10
    [11] [27] 2018 dis peg vr 11
    [12] [38] 2019 dis rs, peg vr 12
    [13] [39] 2019 dis rs, eye tp 13
    [14] [10] 2019 pre rs tp 14
    [15] [6] 2019 dis sq tp 15
    [16] [48] 2022 pre rs tp, vr 16
    [17] [49] 2023 dis rs, peg vr 17
    [18] [53] 2023 dis re vr 18
    [19] [23] 2023 dis re, eye, chat vr, voi 19
    [20] [45] 2023 dis rs, sq tp 20
    [21] [25] 2024 ava peg vr 21
    [22] [14] 2024 dis chat mr, voi caption: ava: availability, dis: dissemination, pre:
preservation, rs: recommendation systems, peg: personalized 3d environment generation,
folk: folksonomy, chat: chatbot, eye: eye-tracking, re: realistic environments, sq:
software quality analysis, do: data organization, vr: virtual reality, tp: traditional
page, mr: mixed reality, voi: voice interaction. information, enabling personalized
recommendations. the informa- tion is collected following the proposed 5r adaptation
framework. the acronym 5r stands for right timing, right location, right device, right
learner, and right contents, meaning that the rec- ommendation is made based on the user’s
context. in the validation process, a functional prototype of the proposed framework was
implemented, but user surveys, scalability tests, or discussions on software evolution
were not conducted. inturn,[ 45]presentsatoolthatstoresdigitalanddigitizedsculp- tures
from artists representing various cultures around the world. the tool uses fuzzy
logic-based resources to improve recommen- dations by taking into account user profiles
and the experience of accessing cultural heritage. the architecture created for sculpt-
mate contains three layers: the userinterfacelayer , which allows button configuration and
3d model visualization; the application logic layer , which includes the implementation of
content man- agement and personalization with fuzzy logic; and finally, the data storage
layer , which stores user information and structures. the article mentions that the focus
during development was on usabil- ity, adaptability, and performance, allowing for future
evolution of the framework due to its modular implementation. the main im- provements
discussed in the article are the implementation of more
sophisticatedmachinelearningalgorithmsandtechniquesformore accurate recommendations. the
paper also proposes the migration from local storage to a cloud server, with integration
with apis to access external resources and models. furthermore, the authors discuss the
possibility of implementing social functionalities, such as sharing preferences among
users, promoting a more connected community. 5.1.3 availability. another purpose of
digital archives is to make content available to the public, facilitating access to
digital cultural products, as discussed in 33% of the analyzed studies. some studies704
whenart meets computer science: a sr about technologies and user interaction in
adaptivedigital museums and archives webmedia’2025, rio de janeiro,brazil present models
that address the heterogeneity of digital resources, proposing strategies for making
content available in a way that improves user experience , whether by developing
user-centered and enjoyable interfaces [ 19], or by implementing recommendation systems to
guide access [ 12,53]. these approaches aim to make access to heritage more inclusive,
adapted to individual needs and, at the same time, increase interactivity and visitor
engagement, providingaricherandmorepersonalizedexperience.budimanetal .
    [23] [10]and strousopoulos et al .
    [24] [45]state that, in addition to acting as preservation tools, collections play a crucial
role in democratizing access to the heritage of socioethnic entities with limited
visibility on the global stage. these tools not only ensure digital preservation but also
expand access to the represented cultures. similarly, bollini
    [25] [6]proposes the centralization of information on cultural heritage, aiming to make content
available both to na- tives and to the non-specialized public in the milan region. that
strategy is intended to preserve the relationships between docu- ments during the process
of organizing and digitizing the works. this model aims to broaden access to cultural
resources, promoting greater understanding among diverse audiences and encouraging
engagement with local history. in the evaluation process, a survey was conducted with 24
participants, and the data were analyzed according to norman’s guidelines. based on the
findings, a second design cycle was launched to implement the necessary improve- ments.
the collection was evaluated within the field of hci, aiming
toverifyusabilityanduser-centereddesign.however,noeffortwas
madetoanalyzethecollection’spotentialforpopularization;thatis, metrics of reach or social
impact were not taken into consideration. 5.2 techniques and technologies digital archives
and museums are driven by a variety of technolo- gies aimed at providing immersive and
personalized experiences for users. this section discusses the main technological
approaches andtheirrelationtothearchivepurposesidentifiedintheliterature, seeking to
answer the research question rq2. 5.2.1 virtual environments. in digital museum studies,
virtual en- vironments can take on various forms and characteristics. in this article,
virtual environments are considered as 3d interfaces, which may or may not resemble the
physical spaces of real museums, allowing users to navigate, interact with, and explore
exhibitions. this type of system often uses 3d modeling and supports specific equipment,
such as vr headsets. svanaes
    [26] [46]argues that the meaning of something is generated from the physical interactions we
establish with the environment. thus, perception and interaction are directly linked to
how we see an artifact and what it represents – not statically, but dynamically and
generated at the moment of interaction. vr provides the envi- ronment through which the
user can interact and, consequently, create new meanings and perceptions of the
surrounding objects. therefore, it has become one of the most common resources in digital
museums, providing immersive experiences that allow users to explore exhibitions
intuitively. 3d virtual environments have been widely adopted in studies focusing on
adaptive enhancements to conventional museums. for example, komianos and oikonomou
    [27] [27], rajaonarivo et al .
    [28] [38], bonis et al .
    [29] [9], yang et al .
    [30] [49], zhao
    [31] [53],andkimetal .
    [32] [25]presentsolutionsthatadapttheuserexperi- ence to the context of traditional museums
through personalization and interaction enhancements within 3d virtual environments. these
studies represent approximately 28% of the publications in our slr. these studies focus on
different characteristics of virtual envi- ronments.forexample,in[
49]thedevelopmentoftheenvironment reflects a concern with realism in the rendering of 3d
models. the article describes the steps used for gamma correction, color, and tone
adjustments of images to create a more realistic and therefore more immersive environment.
zhao
    [33] [53]also address this concern bydiscussingthefollowingmodelingmethods:geometricmodeling,
based on mathematical models and computer graphics; and image- based modeling, using real
image capture. while the former offers many details in the 3d model, it is computationally
expensive for complex environments such as a digital museum. the latter offers many visual
details but has limitations regarding the interactivity of the 3d model. therefore, the
authors propose a hybrid modeling approach, leveraging the interactivity of the first
method and the realism of the second. in addition to the visual realism of 3d models in
the virtual envi- ronment,zhao
    [34] [53]alsodiscussesmorenaturalformsofnavigation. for example, algorithms are developed, to
ensure that movement occurs naturally, smoothly avoiding objects rather than passing
through them. other works discuss the effective arrangement of artworks within the space,
considering artistic categories [ 9], user preferences [ 38], and immersion time within
the virtual environ- ment
    [35] [27]. 5.2.2 traditional interfaces. while several adaptive works high- light a preference
for 3d virtual environments, in which the user is directly immersed in the exhibition
context, studies such as [ 2] proposeanalternativeapproach.inthisstudy,artworksarebrought
closer to the user through simplified interfaces focused on prior- itizing direct
interaction with displayed items, without the need for full immersion in a virtual
environment. in this case, the user interacts directly with the model of the artwork and
does not navi- gate through a virtual environment. this interaction is performed through
traditional visual commands, by clicking buttons on the archive’s interface. studies such
as [ 12] and
    [36] [6] also favor the use of traditional web pages due to the diversity of resources
available to users. this approach is common in contexts where resource heterogeneity de-
mands a more conventional interface, focused on user-centered curation. on the other hand,
studies aiming to enhance the user experience through interface adaptations, such as [ 35]
and
    [37] [19], opt for simplified and conventional traditional pages. this is be- cause the
inclusion of external elements, such as excessive menus,
disconnectedfunctionalities,orredundantinformation,wouldcom- promise the immersiveness of
the archive. in a context where immersion is not a priority, several studies are dedicated
to gathering and adapting artworks based on cultural and ethnic characteristics, without
the intention of replicating a real-world exhibition in a virtual environment. examples
can be found in studies such as [ 10,30,43,48], which adopt traditional page structures.
these works focus on curating and organizing artworks based on cultural and ethnic
categories.705 webmedia’2025, rio de janeiro,brazil oliveiraet al. 5.2.3
recommendationalgorithms. the literature highlights the growing adoption of recommendation
algorithms in different types of digital archives, both in 3d virtual environments and
traditional pages,aimingtoenhancethepersonalizationoftheuserexperience. in 3d
environments, recommendation involves various tech- niques. javdani rikhtehgar et al .
    [38] [23]and raptis et al .
    [39] [39]use eye-tracking to assist in analyzing user behavior and enable sug- gestions based
on their points of interest. for instance, in [ 23], users’ eye movements were tracked to
determine which elements within paintings most attracted their attention (buildings,
faces, and details). this information was used to make personalized rec- ommendations. the
study also reveals that gaze duration can serve as an indicator of user preference, but
this correlation comes with certain limitations. user surveys showed that the display
order of artworks, how detailed the artwork is, or whether it has a more or less
interesting description also impact gaze duration, but they do not necessarily define a
user profile. in contrast, folksonomy-based approaches, as seen in [ 43] and
    [40] [30], involve organizing content through collaboratively defined categories, and
traditional pages provide users with a familiar inter- face to perform this task. in [
30], users rated paintings (from 1 to 5) and added tags they deemed appropriate. the
interface provided access to the painting image, title, description, and other popular
tagscreatedbyusers.adatacollectionprocesswascarriedoutwith 40 individuals (30 general
users and 10 experts) to gather tags for training a multivariable poisson model. tags were
classified as (i) personaltags,providedbyaspecificuserforaspecificartwork;and (ii)
socialtags, assigned to the artwork by various users. the results showed a general
improvement in filtering accuracy with tags cre- ated by users. based on this, the authors
proposed a hybrid system that incorporates folksonomy into content-based recommendation.
to evaluate this framework, k-fold cross-validation and metrics
suchasprecisionandrecallwereused,tiedtodifferentexperimental combinations (permutations
between static content implementa- tion, personal tags, and social tags). the inclusion of
socialtags produced lower results than personaltags, and combining static information
(artwork descriptions) with personaltags achieved the highest filtering precision. the
main results of this study show that personal preferences are more relevant than general
consensus when making recommendations. moreover, models that adapt to user preferences are
present in both immersive environments and traditional pages. examples include the use of
machine learning for personalization, as in [ 49] and
    [41] [25], as well as genetic algorithms and fuzzy logic for more accurate recommendations, as
previously addressed in
    [42] [45]. the dynamic generation of 3d virtual spaces can also be tailored to user
characteristics and the curated selection of artworks to be displayed. in [ 8,9,38],
semantic graphs grouped artworks for users, optimizing the recommendation process. in [
53], recommendations are generated based on user profile, which includes demographic
attributes collected to associate new cases with similar past ones, using the case-based
reasoning technique. recommendations are generated in a ranked list of the best visitation
routes. likewise, in
    [43] [49] demographic data (age, profession, gender, education level) are collected to serve as
input for a deep learning model that can infer user preferences.in addition to these
approaches, other methods also deserve mention, such as calculating the proximity between
clusters of artworks and users, as described in [ 25]. in this case, artworks are divided
into thematic clusters, based on similarity in color, material, description, artist, and
creation date. once the groups are defined, distances between them are calculated,
representing how different theyarefromoneanother.thisinformationisthenusedtogenerate more
coherent thematic exhibitions. 5.2.4 chatbots. [2,14,23] implement chatbots and voice
inter- action to improve communication between users and the archive systems. those
systems are complementary to the standard ways of interaction, like mouse and keyboard,
and so not mandatory to the user. in [ 2], speech recognition is limited by the grammar
that the system can recognize, which restricts interaction with the user. in this type of
approach, questions outside the system’s predefined pattern are not understood, which
could frustrate users. through this system, users can obtain specific information about
artworks and also use specific voice commands for navigation. voice-guided navigation adds
an accessibility layer to the software, enabling use by people with motor or visual
impairments, in addition to offering a different form of interaction for users to acquire
knowledge of the artworks. nonetheless, this feature should be regarded as a complementary
interaction method, as reliance on voice guidance alone may pose accessibility barriers
for deaf users. 5.3 interaction features
interactionfeaturesplayafundamentalroleinuserengagementand satisfaction. from this
perspective, the studies revealed different forms of interactivity with digital archives,
which will be presented in the following topics, allowing us to address rq3. 5.3.1
interactioninvirtualandaugmentedrealityenvironments. vr is one of the technologies that
enables the creation of 3d virtual environments, where interaction can be either immersive
(through theuseofvrheadsetsorhapticgloves)ornon-immersive(typically via conventional
screens). in [ 9], vr allows the development of a more immersive and realistic experience
for the user, as it also enables more natural navigation. the construction of vr spaces
involves several stages, such as the arrangement of objects in the environment, texturing,
lighting, and, in some cases, animation. the works of [ 7,9,38,49,53] seek ways to
facilitate the con- struction of vr environments and represent 25% of the articles we
analyzed. in these studies, methods were developed to automate and simplify the creation
of vr environments through algorithms capable of arranging the items across the available
space, given a set of artworks – an otherwise time-consuming and repetitive manual task.
in [ 27], this arrangement also aims to optimize the user’s time by ensuring that artworks
are placed in appropriate locations with dynamically calculated spacing, minimizing unnec-
essary time spent during exploration. likewise, [ 53] also develops an algorithm to find
more natural paths that avoid obstacles in exhibitions, thereby improving the user’s
navigation experience. in
    [44] [53], interaction occurred in an intuitive and immersive man- ner, allowing users to
explore the digital archive through different modalities. sensors captured movements,
voice commands, and706 whenart meets computer science: a sr about technologies and user
interaction in adaptivedigital museums and archives webmedia’2025, rio de janeiro,brazil
gestures to enable fluid navigation through the virtual environ- ment, while an
intelligent roaming system automatically adjusted the trajectory to avoid obstacles,
making navigation faster. vari- ous media formats (text, image, animation, sound, and
video) were also integrated into the systems to find more user-friendly ways to convey
information. other articles, such as [ 53],
    [45] [9], and
    [46] [38], do not explicitly de- scribe how user interaction takes place – whether through
mouse, keyboard, or any special equipment. in contrast, [ 49] details how
interactionoccurs:thewasdkeysareusedtonavigatetheenviron- ment, the r key activates
automatic navigation to a user-defined point, the mouse sets the viewing direction, and
the right-click allows the user to rotate objects. strousopoulos et al .
    [47] [45]describe an alternative to standard devices: headsets compatible with 3d vision, which
provides greater immersion. an important point is that articles concerning archives using
vr demonstrateaconcernwithnavigationthroughspace,emphasizing naturalness and user’s
freedom. among the works analyzed, users were not suggested specific routes to follow;
guidance occurred throughthemuseum’sconstructionbasedonartworkselectiondur- ing curation
and automatic space creation. the only exception was
    [48] [3], in which a route is suggested to the user and adapted not only to their preferences
but also to their reactions while navigating the exhibition. it is worth noting that
navigation is a key challenge in any vr environment, particularly immersive ones requiring
head- sets, and not an issue exclusive to virtual archives, so that solutions and
challenges in vr from other domains might apply to digital archives as well. surprisingly,
the analyzed studies do not address motion sickness, a common concern in immersive vr
experiences. although most works include some form of user evaluation, these are often
limited to assessing curatorial aspects. they analyze, for
example,thepositioninganddistributionofartworks,orthequality of the rendering and
lighting, rather than comfort or discomfort during navigation. 5.3.2 voice interaction.
from another perspective, in [ 2,14,23], representing 14% of the studies, voice resources
permit a more per- sonalized and natural user interaction. with advancements in the
development of llms (large language models), such as llama or gpt, text generation has
become significantly more sophisticated and complex, allowing for advancements in voice
system imple- mentation for digital archives, as done in [ 14]. in this project, an
application was developed for microsoft hololens (1st generation) to present artworks to
visitors, integrated with a system using the gpt-3.5 model, which received the user’s
audio recording and gen- erated the desired responses. in the application evaluation
tests, a mixedrealityapproachwasused,displayingimagesoftheartworks to users through the
headset. the results of the study indicated that this technology has the potential to
captivate users. two metrics showed lower performance in the empirical test: immersion and
re- sponse credibility. although the metrics and tests that indicated the model’s
responses were accurate, users reported that they would not trust the information provided
in awkward responses. further- more, they mentioned that the interaction with the
conversational agent did not seem natural or realistic in the archive. 5.3.3 webpages.
webpagesarewidelyusedtodayasasolutionfor
digitalarchives.consideringthatoneofthegoalsofsuchcollectionsis to make archived material
available, web pages offer broad com-
patibilitywithcurrentdevices,easeofusethroughelementssuchas
menusandhyperlinks,andhighscalabilityforlargeaudiences.this formof interaction wasemployed
in [ 6,10,12,19,30,35,39,43,45], which represent 43% of the articles. some studies
implemented traditional-format web pages with- out incorporating any unconventional
interaction element. one noteworthy example is [ 19] which presents a study and heuristic
analysis of the interfaces of three different digital museums, aiming to identify the
design elements that are most important for creating effective interfaces of this kind.
the factors deemed most impor- tant were the usermodel and theinterpreter . this
emphasizes that the interface must have high usability and communicability, easily
conveying its purpose and content to the user and responding sat- isfactorily to user
interactions. aesthetics, although relevant, was not prioritized; the main aspects
mentioned were typography (font size and family choice) and the alignment of page
elements. in
    [49] [6], a different form of user interaction is addressed. their framework features a
map-based visualization that can be freely ex-
ploredbytheuser.foreachpointonthemap,historicalinformation is provided by the various
communities that lived there. 6 quantitative analysis figure 2 presents the temporal
evolution of publications related to the adaptation of digital archives and museums. the
graph shows that, despite a reduction in the number of publications in the years 2012,
2013, and 2018, the topic has been regaining prominence, indicating a renewed interest in
the field. vr is the most widely adopted technology in the studies, followed by
traditional web interfaces. other technologies, such as voice interaction and chat- bots,
appeared in 2010 but only resurfaced in 2023, likely due to recent advancements in ai. the
word cloud presented in figure 3 underscores the terms most frequently used in the
analyzed studies, revealing a prominent interest in personalization, vr, and immer- sive
experiences. complementing this discussion, figure 4, generated with the supportofthe
bibliometrix andhighcharts tools,showsthenumber of publications by country. greece is the
country with the highest number of publications, totaling 12 articles, followed by china,
which appears in 7 publications. the results highlight the absence of publications from
north or south american countries, revealing the need for broader discussions on
interaction aspects in digital archives and museums. figure 5 emphasizes the relationship
between the main interac- tion features employed in the papers analyzed and the purposes
of the archives, categorized into three strands: dissemination, preser- vation, and
availability. the strong interest in the use of vr stands out, as evidenced by its
widespread adoption in 50% of the works included in the figure. one example is the study
by [ 38], which proposes a model capable of generating a 3d virtual environment with the
user’s works of interest. moreover, vr shows a similarly significant presence in archives
aimed both at availability and dis- semination. a scarcity of works exploring other
approaches, such as ar, is also noticeable, suggesting that technological barriers or the
need for specific infrastructure may limit its application for navigation in digital
archives. additionally, although the number707 webmedia’2025, rio de janeiro,brazil
oliveiraet al. number of papers145 1 1 145 3 032 10 031 0 1 11 01 1 13 1 0 01 0 0 0 011 0
010 0 0 0 01traditional interfaces virtual reality chatbot voice interaction 2007 2009
2010 2012 2013 2018 2019 2023 20240246 figure2: trendsin the use of interaction features
in works on digital archive adaptation. figure 3: word cloud with terms used in the
studies. figure 4: publications by country. of studies implementing conversational agents
and voice interac- tion is limited, these technologies appear to be more present instudies
focused on archive availability, suggesting a possible rela- tionship between their
adoption and the facilitation of access to digital cultural products. with regard to
evaluation, 71% of the studies conducted experi- ments with users. notably, 100% of these
works aimed at dissem- ination or availability, suggesting a significant focus on aspects
of user interaction and access to archived materials. furthermore, there is a recurrence
of studies seeking to empirically validate their proposals. user participation in this
process is essential, as many of the developed solutions aim to meet individual
preferences and interests, making the experience more engaging and personalized. in
summary, by observing the focus on dissemination and avail- ability as purposes, the
analyzed data reveal that digital archives and museums perform the role of active agents
in the mediation of knowledge and collective memory in digital culture. the em- phasis on
vr highlights the concern with user immersion in the virtual environment; however, the low
application of ar indicates an opportunity to be explored. ultimately, empirical
evaluations involving users are essential to validate the proposed approaches.
oneoftherecurringissuesintherealmoftheartsconcernscopy- right. despite its relevance, only
two studies explicitly address this matter in a significant way. in [ 45], the quality of
3d digitization of artworks is limited by the difficulty of accessing artifacts protected
by copyright. in [ 12], copyright-related issues are discussed from a different
perspective: the protection of digital artworks. one of the features proposed for the
environment described in that study is the integration of a content management system
equipped with security mechanisms capable of efficiently protecting various digi- tal
artworks in their multiple multimedia formats (text, image, 3d model, among others). this
type of technology is particularly im- portant in digital collections, which aim not only
to provide access to content but also to ensure the preservation and respect of intel-
lectual property rights. thus, tools designed to prevent the misuse of images,
unauthorized copies, or non-consensual modifications
contributenotonlytolegalcompliancebutalsototheconsolidation of digital preservation
initiatives. 7 challenges and opportunities the analysis of research on digital archives
reveals both persistent challenges and opportunities to enhance the interaction
experience708 whenart meets computer science: a sr about technologies and user interaction
in adaptivedigital museums and archives webmedia’2025, rio de janeiro,brazil 77 4444 44
2222 1133 voice interaction chatbots traditional interfaces virtual environments0 2 4 6 8
10 12 14 16 18dissemination availability preservation figure 5: interaction features by
digital archive/museum purpose. within digital repositories. several studies have explored
adapta- tionsandpersonalizationsbasedonuserprofiles,asseenin[ 43]and
    [50] [23], and have proposed interactive features to improve navigation and content access.
however, there is a noticeable lack of effec- tive applications of these approaches in
natively digital archives. in many cases, the studies are limited to conceptual
development models. for example, in [ 27], the evaluation is conducted using only a
prototype, without implementing the results in an actual digital archive. this lack of a
comprehensive evaluation constrains the findings to a non-realistic context. moreover,
there is a clear scarcity of specific approaches in the construction and exploration of
digital archives. for example, no implementations of 2d virtual environments were found.
the main argument for implementing 3d virtual environments is that this interaction medium
allegedly promotes greater immersion. how- ever, immersion is also present in 2d, albeit
to a lesser degree. furthermore, hybrid adaptations that combine traditional pages with
virtual environments tend to be more acceptable in the 2d model, as interaction is
typically performed through devices that have become commonplace in users’ daily lives.
additionally, the integration of conventional elements is also facilitated, given that 2d
interfaces are common to many other applications, making the platform more intuitive and
familiar to users. it is also important to note that 3d virtual environment applica- tions
are commonly used in the digitization of physical collections belonging to institutions
whose buildings are, in themselves, works of art. this is the case for the louvre museum,
the tate museum, or the museu da vida fiocruz, which are digital archives that preserve
not only digitized works but also the physical architecture of the building that houses
them. however, in the studies analyzed in this
review,3dvirtualenvironmentsdidnotdemonstratethesamelevel of attention to architectural
preservation, as they were focused on facilitating the generation of the virtual
environments. althoughimmersiveandadaptivestrategies,asseenin[ 7,25,38], offer users
greater immersion and more engaging visits, the use of specific devices, such as vr
headsets, limits access to digital archives. as such, this should be an optional resource,
as proposed in
    [51] [45], where the use of headsets is not mandatory. also concerning the access to digital
archives, it is evident that there is a shortage of implementations focused on the
availability of works. javdani rikhtehgar et al .
    [52] [23]and constantinides et al .
    [53] [14]propose interaction methods that enhance the availability ofcontent to users; however,
these are exceptions among the articles in our sample. the remaining studies do not
address this issue, revealingaclearlimitationinthepotentialdisseminationandreach of
digital archives. furthermore, most systems are still based on traditional web pages and
do not implement innovative solutions. although this is not necessarily a problem, there
is a clear lack of standardization and guidelines for developing digital archives. the
studies by zhao
    [54] [53], geng yang
    [55] [19], and pedrero et al .
    [56] [35]go in this direction; however, there is no clear organizational structure that
provides consolidated guidelines for these implementations. another relevant aspect is the
difficulty to integrate different areas of knowledge. works such as [ 10] clearly state
that the cre- ation of digital archives is a multidisciplinary project, involving not only
the cultural elements to be preserved, but also the tech- niques and guidelines for
building robust software. studies in the field of computer science emphasize technological
aspects in the development of archives, neglecting certain unique characteristics of
digital works and interactions that arise from the digital world – elements that are, in
turn, highlighted and analyzed in case studies from the humanities. a strong association
between both fields is imperative for the development of the area and to meet the expecta-
tions for digital archives from both technical system aspects (such as
accessibility,usability,interactivity, etc.) and humanistic archival concerns (such as
curation, storytelling, and representativeness of the collection, for example).
additionally, the development and creation of digital archives are intrinsically linked to
the preservation of the archived works, meaning that they must endure over time. in this
regard, for the development of the software, its evolution in response to changes in
technology and social dynamics must be considered. some al- ternatives to this problem
have already been proposed and could be adapted and implemented, such as lehman’s laws. in
[ 45], this ideaispresent;however,itwasexpectedtobemorewidelyadopted in the development of
this type of platform. finally, it is important to highlight the development of plat-
forms that support the preservation of collections with limited resources. preservation
efforts should not be constrained by the broad availability of personnel, infrastructure,
and financial re- sources – conditions typically found in well-established physical
archives,orinstitutionssupportedbyexternalfunding.alternatives are explored in works such
as
    [57] [40], which proposes a paradigm of projects that incorporate minimal computing and,
therefore, reduce709 webmedia’2025, rio de janeiro,brazil oliveiraet al. development
costs. in parallel, there are also initiatives involving low-cost implementations that,
for example, incorporate social me-
diaortoolssuchastainacantoexpandaccessandthesustainability of digital preservation
    [58] [36]. 8 final remarks in this study, a systematic review was conducted with the objec-
tive of identifying the main technologies and forms of interaction employed in digital
archives. from this analysis, it is evident that there is a lack of standardization in the
field regarding guidelines and norms for the creation of such platforms. moreover, our
results show that there is limited use of software engineering practices for software
maintenance and preservation – essential aspects in the field of digital preservation
studies. finally, most of the works did not demonstrate concern with evaluating software
quality aspects, which reveals a significant gap as to human-computer interaction. as a
scope limitation, this review included only projects that develop digital archives
intended to host multiple works, excluding those focused on building technologies for
individual exhibitions or singleartworks.relevantfutureworkcouldfocusoninitiativesthat aim
to standardize the development processes of digital archives or, at the very least, the
systematic documentation of such practices. 9 ethical considerations this work presents a
systematic literature review, characterized as secondary research, since it does not
involve direct interaction with participants nor the exposure of individuals to
technologies or computational systems. therefore, according to cns resolution no. 510/2016
and cns resolution no. 674/2022, it is exempt from approval by the research ethics
committee involving human sub- jects.thedatausedreferexclusivelytothemetadataoftheanalyzed
articles, which are publicly available in the databases selected and described in section
4. acknowledgments thisstudywascarriedoutwiththesupportoffapematandcnpq, through the
granting of research scholarships. the english version of this article was produced with
the assistance of chatgpt and carefully revised by the authors. language correction tools,
such as writefull, were also employed during the writing process. all stages of data
selection, analysis, and discussion were conducted exclusively by the authors, with ai
tools used solely as writing aids. references
    [59] [1]r.ahmadandm.rafiq.2023. globalperspectiveondigitalpreservationpolicy:a systematic
review. journaloflibrarianship andinformation science 55, 3 (2023), 859–867.
https://doi.org/10.1177/09610006221111572
    [60] [2]salvatore andolina, antonella santangelo, and antonio gentile. 2010. adap- tive voice
interaction for 3d representation of cultural heritage site. in 2010international
conference oncomplex, intelligent andsoftware intensive systems . ieee, krakow, tbd,
poland, 729–733. https://doi.org/10.1109/cisis. 2010.139
    [61] [3]asma hanee ariffin and yu-n cheah. 2013. see what you want, feel what you see: the
personalized re-recommendation framework using hybrid strategies for fieldtripplan.in
2013thirdworldcongress oninformation andcommunication technologies (wict2013). ieee,
hanoi, vietnam, 262–267. https://doi.org/10. 1109/wict.2013.7113146
    [62] [4]sitaram asur, bernardo huberman, gábor szabó, and chunyan wang. 2011. trends in social
media : persistence and decay. 5thinternational aaaiconference onweblogs andsocialmedia(02
2011). https://doi.org/10.2139/ ssrn.1755748
    [63] [5]caroline bertini fernandes and márcia gomes marques. 2019. a publicação de poesia na
internet: a literatura de clarice freire. vista4 (july 2019), 175–197.
https://doi.org/10.21814/vista.3020
    [64] [6]letizia bollini. 2019. representing a space-based digital archive on historical
maps:auser-centereddesignapproach. in proceedings ofthe1stinternational
andinterdisciplinary conference ondigitalenvironments foreducation, arts andheritage ,
alessandro luigini (ed.). vol. 919. springer international publish- ing, cham, 599–607.
https://doi.org/10.1007/978-3-030-12240-9_62 series title: advances in intelligent systems
and computing.
    [65] [7]bill bonis, john stamos, spyros vosinakis, ioannis andreou, and themis panayiotopoulos.
2007. personalization ofcontent invirtual exhibitions . springer berlin heidelberg,
172–184. https://doi.org/10.1007/978-3-540-77051- 0_19
    [66] [8]bill bonis, john stamos, spyros vosinakis, ioannis andreou, and themis panayiotopoulos.
2007. personalization of content in virtual exhibitions. in semantic multimedia , bianca
falcidieno, michela spagnuolo, yannis avrithis, ioannis kompatsiaris, and paul buitelaar
(eds.). vol. 4816. springer berlin heidel- berg, berlin, heidelberg, 172–184.
https://doi.org/10.1007/978-3-540-77051-0_19 series title: lecture notes in computer
science.
    [67] [9]b. bonis, j. stamos, s. vosinakis, i. andreou, and t. panayiotopoulos. 2009. a platform
for virtual museums with personalized content. multimedia toolsand applications 42, 2
(april 2009), 139–159. https://doi.org/10.1007/s11042-008- 0231-2
    [68] [10]e budiman, m wati, and norhidayat. 2019. the 5r adaptation framework for cultural
heritage management information system of the dayak tribe borneo. journal ofphysics:
conference series1341, 4 (oct. 2019), 042016. https://doi.
org/10.1088/1742-6596/1341/4/042016
    [69] [11]manuel castells. 2005. sociedade emrede. paz e terra, são paulo.
    [70] [12]chengwei yang, rui wang, lu wang, chenglei yang, shijun liu, and xiangxu meng. 2010.
the personalized service customization based on multimedia re- sources in digital museum
grid. in 20103rdieeeinternational conference on ubi-media computing . ieee, jinhua, china,
298–304. https://doi.org/10.1109/ umedia.2010.5544439
    [71] [13]teixeira coelho. 2020. ecultura, autopia final:inteligência artificial e humanidades.
editora unesp, são paulo.
    [72] [14]nicolasconstantinides,argyrisconstantinides,dimitrioskoukopoulos,christos fidas, and
marios belk. 2024. culturai: exploring mixed reality art exhibitions
withlargelanguagemodelsforpersonalizedimmersiveexperiences.in adjunct proceedings
ofthe32ndacmconference onusermodeling, adaptation and personalization . acm, cagliari
italy, 102–105. https://doi.org/10.1145/3631700. 3664874
    [73] [15]jacqueline de araújo cunha and marcos galindo lima. 2024. preservação digital:
tendências atuais dos conceitos e técnicas. revistaanalisando emciência da informação 11,
2 (nov. 2024), 45–60. https://revista.uepb.edu.br/racin/article/ view/4069
    [74] [16]qiong dang. 2018. literature review on the digital museum in a chinese context.
communication, societyandmedia1, 2 (nov. 2018), 149. https://doi.
org/10.22158/csm.v1n2p149
    [75] [17]ioannis drivas and eftichia vraimaki. 2025. evaluating and enhancing museum websites:
unlocking insights for accessibility, usability, seo, and speed. metrics 2, 1 (jan. 2025),
1. https://doi.org/10.3390/metrics2010001
    [76] [18]danilo formenton and luciana de souza gracioso. 2020. preservação digital: desafios,
requisitos, estratégias e produção científica. rdbci: revista digital debiblioteconomia
eciência dainformação 18, 00 (jun. 2020), e020012. https:
//doi.org/10.20396/rdbci.v18i0.8659259
    [77] [19]geng yang. 2009. a study on the user-centered interface design for vir- tual museums.
in 2009ieee10thinternational conference oncomputer-aided industrial design &conceptual
design. ieee, wenzhou, china, 1647–1651. https://doi.org/10.1109/caidcd.2009.5374866
    [78] [20]pablo gobira and fernanda corrêa. 2019. a preservação digital da poesia: uma análise
do arquivo digital da po.ex. in amemória dodigitaleoutrasquestões dasartesemuseologia
(1ed.),pablogobira(ed.).vol.1.eduemg,belohorizonte, 165–188.
    [79] [21]katherine harris. 2014. archive. in thejohnshopkins guidetodigitalmedia, marie-laure
ryan, lori emerson, and benjamin j. robertson (eds.). johns hop- kins university press,
16–18.
    [80] [22]ahdab najib hijazi and ahmad hanif ahmad baharin. 2022. the effectiveness of digital
technologies used for the visitor’s experience in digital museums. a systematic literature
review from the last two decades. international journal ofinteractive mobiletechnologies
(ijim)16, 16 (aug. 2022), 142–159. https: //doi.org/10.3991/ijim.v16i16.31811
    [81] [23]delaram javdani rikhtehgar, shenghui wang, hester huitema, julia alvares, stefan
schlobach, carolien rieffe, and dirk heylen. 2023. personalizing cultural
heritageaccessinavirtualrealityexhibition:auserstudyonviewingbehavior
andcontentpreferences.in adjunct proceedings ofthe31stacmconference on usermodeling,
adaptation andpersonalization .acm,limassolcyprus,379–387.710 whenart meets computer
science: a sr about technologies and user interaction in adaptivedigital museums and
archives webmedia’2025, rio de janeiro,brazil https://doi.org/10.1145/3563359.3596666
    [82] [24]otim kayaga and kiu publication extension. 2024. digital archiving and preser- vation
of art: challenges and innovation. 3 (08 2024), 21–25.
    [83] [25]hayun kim, maryam shakeri, jae-eun shin, and woontack woo. 2024. space-
adaptiveartworkplacementbasedoncontentsimilaritiesforcuratingthematic spaces in a virtual
museum. journaloncomputing andcultural heritage 17, 1 (feb. 2024), 1–21.
https://doi.org/10.1145/3631134
    [84] [26]barbarakitchenham.2004. proceduresforperformingsystematicreviews. keele, uk,keeleuniv.
33 (08 2004).
    [85] [27]vasileios komianos and konstantinos oikonomou. 2018. adaptive exhibition topologies
for personalized virtual museums. iopconference series:materials science andengineering
364 (june 2018), 012011. https://doi.org/10.1088/1757- 899x/364/1/012011
    [86] [28]jin woo lee, yikyung kim, and soo hee lee. 2019. digital museum and user experience:
the case of google art & culture. in international symposium on electronic art.
international symposium on electronic art.
    [87] [29]jingjing li, xiaoyang zheng, ikumu watanabe, and yoichi ochiai. 2024. a systematic
review of digital transformation technologies in museum exhibition. computers inhuman
behavior 161 (dec. 2024), 108407. https://doi.org/10.1016/ j.chb.2024.108407
    [88] [30]pasquale lops, marco de gemmis, giovanni semeraro, cataldo musto, fedelucio
narducci,andmassimobux.2009. asemanticcontent-based recommendersys- tem integrating
folksonomies for personalized access. in webpersonalization inintelligent environments ,
janusz kacprzyk, giovanna castellano, lakhmi c. jain, and anna maria fanelli (eds.). vol.
229. springer berlin heidelberg, berlin, heidelberg, 27–47.
https://doi.org/10.1007/978-3-642-02794-9_2 series title: studies in computational
intelligence.
    [89] [31]lev manovich. 2001. thelanguage ofnewmedia. mit press, cambridge, ma.
    [90] [32]dalton lopes martins, josé eduardo santarém segundo, marcel ferrante silva, and joyce
siqueira. 2017. repositório digital com o software livre tainacan: revisão da ferramenta e
exemplo de implantação na área cultural com a re- vista filme cultura. in anaisdoencontro
nacional depesquisa emciência da informação (enancib). ancib.
    [91] [33]trevor owens and thomas padilla. 2020. digital sources and digital archives:
historicalevidenceinthedigitalage. international journalofdigitalhumanities 1 (2020),
325–341. https://doi.org/10.1007/s42803-020-00028-7
    [92] [34]dragana pavlović. 2022. digital tools in museum learning – a liter- ature review from
2000 to 2020. factauniversitatis, series:teaching, learning andteacher education (jan.
2022), 167. https://doi.org/10.22190/ futlte211104013p
    [93] [35]a. pedrero, v. alonso, m.a. villarroel, p. de la fuente, and a.s. cabaco. 2009.
presentation adaptation: results from a case study. in engineering theuser interface
,miguelredondo,crescenciobravo,andmanuelortega(eds.).springer london, london, 1–13.
https://doi.org/10.1007/978-1-84800-136-7_15
    [94] [36]vinícius carvalho pereira. 2024. poesia em flash na antología de liter- atura
electrónica latinoamericana y caribeña: questões de arquivo. acta scientiarum. language
andculture 46, 1 (may 2024), e65240. https://doi.org/10. 4025/actascilangcult.v46i1.65240
    [95] [37]isabella peters and wolfgang g. stock. 2007. folksonomy and information retrieval.
proceedings oftheamerican society forinformation science and technology 44, 1 (jan. 2007),
1–28. https://doi.org/10.1002/meet.1450440226
    [96] [38]landy rajaonarivo, eric maisel, and pierre de loor. 2019. an evolving museum metaphor
applied to cultural heritage for personalized content delivery. user modeling
anduser-adapted interaction 29, 1 (march 2019), 161–200. https:
//doi.org/10.1007/s11257-019-09222-x
    [97] [39]george e. raptis, christos fidas, christina katsini, and nikolaos avouris. 2019. a
cognition-centered personalization framework for cultural-heritage content. usermodeling
anduser-adapted interaction 29, 1 (march 2019), 9–65. https:
//doi.org/10.1007/s11257-019-09226-7
    [98] [40]roopika risam and alex gil. 2022. introduction: the questions of minimal com-
puting.digitalhumanities quarterly 16,2(2022). http://www.digitalhumanities.
org/dhq/vol/16/2/000620/000620.html
    [99] [41]rejane c. rocha. 2021. fora da estante: questões de arquivo e de preservação da
literatura digital. nuevarevistadelpacífico 74 (june 2021), 290–309. https:
//doi.org/10.4067/s0719-51762021000100290
    [100] [42]rejane c. rocha. 2023. a memória literária: arquivo em tempos de bases de
dados.universum (talca)38,1(jul2023),121–133. https://doi.org/10.4067/s0718-
23762023000100121
    [101] [43]giovanni semeraro, pasquale lops, marco de gemmis, cataldo musto, and fedelucio
narducci. 2012. a folksonomy-based recommender system for person- alized access to digital
artworks. journaloncomputing andcultural heritage 5, 3 (oct. 2012), 1–22.
https://doi.org/10.1145/2362402.2362405
    [102] [44]m. n. sitokdana and a. r. tanaamah. 2016. strategi pembangunan e-culture di indonesia.
jutisi 2, 2 (august 2016).
    [103] [45]panagiotis strousopoulos, christos papakostas, christos troussas, akrivi krouska,
phivos mylonas, and cleo sgouropoulou. 2023. sculptmate: personal- izing cultural heritage
experience using fuzzy weights. in adjunct proceedingsofthe31stacmconference
onusermodeling, adaptation andpersonalization . acm, limassol cyprus, 397–407.
https://doi.org/10.1145/3563359.3596667
    [104] [46]d. svanaes. 2013. interaction design for and with the lived body: some implica- tions
of merleau-ponty’s phenomenology. proceedings ofacmtransactions on computer-human
interaction (tochi) 20 (2013). special issue on the theory and practice of embodied
interaction in hci and interaction design.
    [105] [47]yantingtong,binyuecui,andyulinchen.2018. researchonuivisualdesignof intangible
cultural heritage digital museum based on user experience. in 2018 13thinternational
conference oncomputer science amp;education (iccse). ieee, 1–4.
https://doi.org/10.1109/iccse.2018.8468809
    [106] [48]qinwang.2022. theapplicationofpersonalizedrecommendationsysteminthe cross-regional
promotion of provincial intangible cultural heritage. advances inmultimedia 2022 (oct.
2022), 1–10. https://doi.org/10.1155/2022/5811341
    [107] [49]meng yang, jia-xiu zhang, yi shi, bo liu, le-xin guo, zhi-peng yu, bin sheng, and
li-zhuang ma. 2023. framework of personalized layout for a museum exhi- bition hall.
multimedia toolsandapplications 83, 8 (aug. 2023), 24563–24587.
https://doi.org/10.1007/s11042-023-16307-8
    [108] [50]jihyunyiandhaesunkim.2021. userexperienceresearch,experiencedesign, and evaluation
methods for museum mixed reality experience. j.comput. cult. herit. 14, 4, article 48
(sept. 2021), 28 pages. https://doi.org/10.1145/3462645
    [109] [51]li yifei and mohd kamal othman. 2024. investigating the behavioural intentions of
museum visitors towards vr: a systematic literature review. computers in human behavior
155 (june 2024), 108167. https://doi.org/10.1016/j.chb.2024. 108167
    [110] [52]namira rahmi zahara and tamara adriani salim. 2022. preservation of digital archives:
systematic literature review. recordandlibrary journal8, 2 (dec. 2022), 285–297.
https://doi.org/10.20473/rlj.v8-i2.2022.285-297
    [111] [53]lingzhao.2023. personalizedhealthcaremuseumexhibitionsystemdesignbased on vr and deep
learning driven multimedia and multimodal sensing. personal andubiquitous computing 27, 3
(june 2023), 973–988. https://doi.org/10.1007/ s00779-022-01672-2711

3. PARÁGRAFOS RELEVANTES (TOP-1):
  > OBJETIVO:
    Score: 4.000
        when art meets computer science: a systematic review about technologies and user interaction in adaptive digital museums and
        archives enzo rigazzo oliveira media lab universidade federal de mato grosso cuiabá, mato grosso, brasil
        enzo.oliveira@sou.ufmt.brgabriel josé do amaral schuina media lab universidade federal de mato grosso cuiabá, mato grosso, brasil
        gabriel.schuina@sou.ufmt.br vinícius carvalho pereira instituto de linguagens universidade federal de mato grosso cuiabá, mato
        grosso vinicius.pereira@ufmt.brrenan vinicius aranha media lab universidade federal de mato grosso cuiabá, mato grosso, brasil
        renan.aranha@ufmt.br abstract thedigitizationofartisticproductions,ortheircreationinanatively digital format, has expanded their
        scope beyond original intentions, bringing them into close interaction with software-related aspects. in this context, the
        dissemination, preservation, and access to such works, especially within digital museums and digital archives, are inevitably
        influenced by the quality of the underlying software. considering the inherent challenges at the intersection of digital
        humanitiesandcomputing,particularlytheneedforuser-centered andcustomizableexperiencestoeffectivelymanagelarge,heteroge-
        neouscollections,thisarticlepresentsasystematicliteraturereview focused on adaptive, personalized, and customizable digital muse-
        ums and archives. the review aims to identify the main purposes of these systems, the technologies employed in their construction
        and maintenance, and the interaction approaches proposed for users. using a systematic protocol, searches were conducted across
        acm digital library, ieee xplore, science direct, and scopus, result- ing in the analysis of 21 studies. based on the analysis of
        studies, we discuss trends, challenges, and opportunities for the design and development of adaptive digital museums and archives,
        such as the limited incorporation of human-computer interaction and software engineering principles and the need for greater
        standard- ization in the development of adaptive digital archives. keywords adaptive systems, digital museums, digital archives 1
        introduction digital transformation has brought diverse impacts across different sectors of society. in the field of the
        humanities, artistic production standsoutasoneofthedomainsaffectedbydigitaltechnologies.as evidence, it can be observed that,
        while efforts to preserve physical materials have intensified, ranging from manuscripts and paintings in: proceedings of the
        brazilian symposium on multimedia and the web (webme- dia’2025). rio de janeiro, brazil. porto alegre: brazilian computer society,
        2025. © 2025 sbc – brazilian computing society. issn 2966-2753to audiovisual records stored on videotapes, there has also been an
        increase in the production of digital-born content on platforms such as social media [5]. although these digital platforms
        facilitate the dissemination of arts, the ephemeral nature of online materials poses a potential risk to the preservation of
        cultural and artistic products. works published as posts on social networks such as instagram and x, for example, tend to be
        dispersed amid the large volume of new content continually posted [ 4]. furthermore, the discontinuation of certain platforms, as
        the social network orkut, can lead to the permanent loss of digital materials. preservation is also threatened when artistic works
        rely on specific technologies that become ob- solete, as occurred with creations developed in flash, which ceased to be supported
        by major web browsers at the end of 2020 [36]. without proper care for the preservation and cataloging of these digital works,
        they are subject to disappearance, technological ob- solescence, or even simple dispersal across the web [ 24]. the de-
        terioration process, although generally not caused by humidity, temperature, or light – as is the case with physical works – also
        appliesto digital creations,since theyaresubjectto data corruption and loss, as well as technological lag or discontinuation of
        propri- etary technologies. therefore, far from being a topic of exclusive interest to the digital humanities, the preservation of
        digital art is also an inherent subject of computer science. in this challenging context, the creation of digital archives rep-
        resents an effective conservation strategy for these works and has becomeanincreasinglyfrequentendeavorinthefieldofdigitalhu-
        manities [ 15]. these platforms, which combine archival, museologi- cal, and sometimes even educational purposes, may help
        overcome both geographical distances and certain socioeconomic barriers to accessing archived cultural products. although they
        share some goals and purposes with traditional museums, these platforms do not necessarily replicate the experience of visiting a
        physical space, and may instead employ different interaction resources. in the preservation of digital-born or digitized works,
        several projects have sought to provide solutions for the field. one such example is tainacan, a free software platform aimed at
        building collaborative digital archives [ 32], developed by the university of699 webmedia’2025, rio de janeiro,brazil oliveiraet
        al. brasília, with support from the federal university of goiás, the brazilian institute of information in science and technology,
        and the brazilian institute of museums. digital archives developed us-
        ingtainacangenerallypresentworkstovisitorsthroughtraditional web pages, as in the museu da casa de benjamin constant1. how-
        ever,thisisnottheonlyapproachadoptedbysuchplatforms.other initiatives, such as the museu do ipiranga virtual2and the museum of
        life3maintained by fiocruz, use virtual reality (vr) to cre- ate immersive experiences with digitally preserved works or even
        environments. giventheinterdisciplinarynatureofthetopicanditsfoundation in digital technologies, it is essential to examine key
        aspects from fields such as human-computer interaction (hci), multimedia and software engineering (se) in digital archives or
        museums. in the field of hci, there is room not only for improving the resources employed, but also for customizing and evaluating
        these tools from the users’ perspective, in order to offer a better user experience while interacting with the digital archive or
        museum. this includes analyzing how the modes of interaction with these platforms, such as through web pages or vr environments,
        can influence user inter- est, exploration of the archive, and overall experience quality. with regard to se, it is necessary to
        observe the development of tech- niques that ensure the efficient implementation of digital archives, with particular attention to
        the evolution of both the archives and the digital-born works over time. given the interdisciplinary nature of digital archives
        and the fragmented treatment they often receive across the digital hu- manities and computer science, this systematic literature
        review examines 21 studies to identify the primary purposes of such plat- forms, the technological strategies employed in their
        development, and the interaction modalities made available to users. by articulat- ing perspectives from both fields, the study
        contributes to a deeper understandingofcurrentpracticeswhilealsorevealingcriticalgaps, such as the limited incorporation of
        human-computer interaction and software engineering principles, the lack of standardization in development methodologies, and the
        insufficient attention to accessibility and long-term software evolution. 2 fundamental concepts given the interdisciplinary
        nature of this work, involving both the humanities and computer science, we present in this section some fundamental definitions
        for the discussions addressed in this study. 2.1 digital archives in this work, we use the term “archives” to refer to
        institutions that collect, systematize, preserve, and present cultural products to the
        public.withinthisscope,differenttypesofinstitutionsareincluded, suchas museums, archives,and libraries. theirfunctions may differ
        for specialists, but for the general public (and for the purposes of this study) they can all be understood as memory
        institutions. digital archives can be broadly defined as organized collections
        ofculturalproductsthatareeitheroriginallydigital(suchasebooks
        1https://museucasabenjaminconstant.acervos.museus.gov.br/pagina-acervo- museologico/ 2https://museudoipirangavirtual.com.br/
        3https://eravirtual.org/parque-da-ciencia/or images produced by generative algorithms) or digitized (such as images of books and
        photographs of oil paintings, among others). according to owens and padilla [33], a digitized collection may be a copy of a
        partial or complete collection of a physical archive, as in the case of the bnbdigital4, or thecentrodigitaldedocumen-
        taçãoepesquisamemóriasdosuldabahia5. both in digitized and digital archives, each collected item is described by metadata and, in
        general, the collections are accessed by the public through an online interface. the importance of digital archives for the
        construction of a memory of our present time is directly proportional to the chal- lenges they face. in addition to issues of
        funding, infrastructure, and archival methodology, which also affect physical collections, digital archives face issues such as
        technological obsolescence [ 42], archival instability, and the potential for infinite data accumulation [21]. 2.2 digital culture
        digital culture can be defined as the set of cultural practices that emerge from contexts in which interactions between two or
        more humans, between humans and the world, and between humans and their ideas are mediated by computational technologies. in his
        anal- ysis of the language of new media, [ 31] defines five characteristics of this language, which can also define the structural
        elements of digital culture: numerical representation, modularity, automation, variability, and cultural transcoding. other
        proposals for the semiotic characterization of digital cul- ture, such as that of [ 13], highlight features such as digitality,
        mo- bility, impermanence, disruption, connectivity, editability, combi- natorics, duplicability, exponentiality, and virtuality,
        among others. describing how we relate to information and communication tech- nologies (ict), these features are hallmarks of a
        culture in which data is transformed into information and gains prominence in eco- nomic, political, and social processes, in a
        dynamic that castells [11]called informationalism. generating data that multiply and circulate in accelerated global flows, the
        complexification of digital culture requires a complexification and evolution of digital archives as memory devices for the
        growing mass of data. 2.3 folksonomy folksonomy is a term that blends the words “folk” and “taxonomy” to describe the process of
        collaboratively tagging content. in this process, users evaluate the content and define tags that represent it, creating a form of
        categorization that evolves organically [ 43]. this can be done in two ways: if the tags are stored only once, we have a narrow
        folksonomy; however, if each new instance of the tag is recorded,itisconsideredabroadfolksonomy.inthelatterapproach, it is
        possible to conduct an in-depth analysis of the number of tags and the exposed content, ensuring greater fidelity to the tag [
        37]. by reflecting the way users organize and categorize information on the internet, folksonomy is deeply related to digital
        culture and digital archives. 4http://bnbdigital.cultura.df.gov.br/ 5https://memoriasulbahia.com.br/700 whenart meets computer
        science: a sr about technologies and user interaction in adaptivedigital museums and archives webmedia’2025, rio de janeiro,brazil
        3 state of the art due to its interdisciplinary nature, research involving the creation of digital works, museums, or archives may
        present different per- spectives on the artifacts produced and their use. thus, this section
        discussesworksthatrepresentthestateoftheartindigitalarchives from the perspective of each area. 3.1 digital humanities from the
        perspective of digital humanities, publications usually discuss aspects related to the definition of digital archives and their
        main characteristics. “anarchive”, for example, is a term used by rocha[41]torecognizetheinstability,ephemerality,andvariability
        of digital media, which define the characteristics of digital works. with the advancement of digital technologies, it is
        increasingly common for works to exist exclusively in digital archives. a central issue, therefore, is to find an effective means
        of preserving these works while respecting their unique characteristics. other studies discuss the effective preservation of
        digital works, whichrequiresnotonlyprotectingthemfromobsolescencebutalso maintaining their unique characteristics, including their
        ephemer- ality and technological dependence. rocha [41]argues that the intrinsic obsolescence of digital works also needs to be
        preserved. this ephemeral existence demands the preservation not only of the works themselves but also of their interaction with
        the reader. gobira and corrêa [20]describe the creation and development of the po.ex digital archive, focusing on the preservation
        of digi- tal poems. their preservation efforts ensured that the interactive features of the works were maintained. since these
        works were created through programming, they required servers for distribu- tion. to address this issue, the works were
        reimplemented on the platform’s own servers. alternatively, the implementation could be made available on multiple platforms,
        reinforcing the idea that dissemination itself is a form of preservation. while the po.ex digital archive focuses on preserving
        the in- teractivity of the works, pereira [36]discuss the decentralization of
        digitalpreservationandthevalorizationofworksfrommatogrosso, whilecataloginganddisseminatingregionalliteraryproductions.in the
        digital literature collection of mato grosso, works published on websites or social media platforms (instagram, wattpad, twit-
        ter, facebook, etc.) by artists born or residing in the state of mato grosso, brazil, are showcased. this collection serves as a
        refuge space for lesser-known works and proposes a means for the dissem- ination and conservation of regional works in a tool
        conceived in brazil: the open-source wordpress plugin tainacan. thus, accord- ing to pereira [36], the project fosters the
        independence of research and literary production delinked from eurocentric technological and aesthetic standards. 3.2 computer
        science from the perspective of computer science, many studies focus on the development of methodologies and technical guidelines
        aimed at digital preservation. in this line, formenton and gracioso [18] propose guidelines for the preservation of digital works,
        consider- ing the ephemerality of dissemination and storage media, for both digital-born and digitized works. their work outlines
        challenges of managerial, technical, legal, political, economic, and social nature.ahmad and rafiq [1]highlight that many
        organizations already have or are trying to develop digital preservation policies. how- ever, they argue that the development of
        such policies is generally considered an intrinsic responsibility of organizations, rather than an outsourced or globalized task.
        aspects related to hci, in turn, have been less explored in the context of digital museums and archives. tong et al . [47]propose
        visual interface design strategies for digital museums of intangible heritage based on user experience principles, focusing on
        color, typography, and layout, but without conducting user evaluations. similarly, lee et al . [28]analyze the google art &
        culture plat- form through the lens of remediation theory, identifying interface elements that foster both information delivery
        and user engage- ment.theirstudyprovidesconceptualinsights,butdoesnotinclude empirical testing with users. on the other hand, a
        broader and com- plementary perspective is provided by drivas and vraimaki [17], who evaluate 234 museum websites based on
        accessibility, usability, seo, and speed. the authors emphasized the relevance of user- centered metrics and highlighted
        disparities in user experience between mobile and desktop platforms. the proposed framework promotes inclusive design and supports
        non-technical staff in im- proving digital interfaces, reinforcing key hci principles such as usability, accessibility, and
        equity. 3.3 contributions of this paper thescientificliteraturepresentsreviewsdiscussingtheuseofdigital technologies, such as
        artificial intelligence (ai) and vr, within the scope of exhibitions, archives, and museums. for instance, [ 51] and [22] focus on
        visitor behavior and user experience with immersive technologies such as vr and augmented reality (ar) in museum contexts. their
        analyses, however, are predominantly limited to physical or hybrid exhibitions. li et al . [29]offers a comprehensive
        overviewofdigitaltransformationtechnologies(dtts),including ai, internet of things (iot), robotics, and 3d printing, but does not
        examine how these technologies relate to the communicative or functional objectives of digital collections. complementarily,
        studies such as [ 52] and [16] are more aligned with institutional and preservation-oriented concerns and do not explore user
        interaction in depth. pavlović [34]in contrast, dis- cusses digital tools for learning in museums but remains grounded in
        pedagogical theory without analyzing digital archives as plat- forms for broader cultural participation. however, these reviews
        consider the role of such technologies as part of an experience that is predominantly analog and often guided by professionals or
        instructions within the physical environment. with this literature review, we aim to investigate the technological decisions and
        in- teraction approaches that have been adopted in exclusively digital collections and museums with adaptation, personalization or
        cus- tomization. this investigation is important because, in such cases, the user’s entire interaction with artistic productions
        is mediated by interfaces, which may influence their experience, interest and appreciation of these works. 4 methodology in order
        to identify the characteristics, user interaction methods, and digital technologies used in digital museums and archives with701
        webmedia’2025, rio de janeiro,brazil oliveiraet al. adaptation, we conducted a systematic literature review (slr). this review was
        organized into three main stages, as presented in [26]:planning ,conducting , andreporting . the first stage ( planning ) involves
        defining the scope and the review protocol. the protocol adopted was picoc, which is detailed in table 1. through this protocol,
        the area and object of study were defined ( population , intervention ,comparison ), along with the expected objectives ( out-
        come)andthegroupsaffectedbythisreview( context).ourresearch questions (rqs) are the following: •rq1:for what purpose are digital
        archives developed? •rq2:what computational technologies can be observed in digital archives? how do these characteristics relate
        to the purpose of the archives? •rq3:how do users of digital archives interact with the platform and the works available there?
        our first research question (rq1) aims to explore the purpose of digital archives. while many of them were developed to digitalize
        physical museums, other digital archives were created aiming to enhance the availability of artworks. considering that the purpose
        of a digital archive can influence the interaction aspects and the technologies adopted, we addressed this topic in this review.
        then, in the second research question (rq2), we observed the technolo- gies adopted in each digital archived related in the
        papers, aiming to identify if there is any association between technologies and archives’ purposes. aspects related to users’
        interaction were dis- cussed in our third research question (rq3), aiming to identify challenges, limitations and opportunities
        for this context. in the second stage ( conducting ), some control articles were selected through a non-systematic search in the
        scielo and capes journal portal databases, aiming to identify relevant articles that could serve as a basis for the selection of
        keywords. the resulting search string, derived from these keywords, was: titlemustcontain: (personaliz* or adapt* or customiz* or
        user-center*); metadata must contain: (“digital archive” or “digital collection” or “digital
        museum”or“virtualmuseum”or“culturalheritage”or“digitalart gallery”) . the string was applied to four academic databases: acm
        digital library, ieee xplore, science direct, and scopus. to ensure robust and comprehensive coverage of the study’s
        interdisciplinary focus, the selection targeted databases prominent in computer science (e.g., hci and software engineering) and
        broader research fields(e.g.,digitalhumanitiesandculturalheritage).table2shows all versions of the strings. the search string was
        meticulously crafted to maximize the re- trieval of interdisciplinary works, combining terms for adaptation (e.g., adapt*,
        personaliz*) with context keywords (e.g., ”digital mu- seum”, ”cultural heritage”) to ensure all selected studies remained highly
        relevant to the review’s core focus. after the initial data col- lection using the search strings, the database filters were
        deemed insufficiently precise. to ensure the proper selection of articles, a python script was developed to automatically verify
        the presence of the correct keywords in the metadata and titles, as specified in the search strings. in order for articles to be
        selected within the scope defined by the review protocol, the inclusion and exclusion criteria were established and listed below:
        i1:the study addresses the development, maintenance, or use of a digital collection or digital museum.i2:the study describes
        technical aspects (interaction methods, technologies used) that support the understanding of com- putational elements.
        i3:thestudypresentsasolutionfocusedonabroadercollection, rather than on a single (art)work. e1:the study does not discuss the
        development, maintenance, or use of a digital collection/museum. e2:the study does not describe technical aspects (interaction
        methods, technology used) that enable understanding of computational aspects. e3:the study presents a solution related to a
        specific (art)work, without addressing a broader collection. astudyisconsideredeligiblewhennoneoftheexclusioncriteria apply.
        additionally, no restriction was placed on the publication date of the articles. subsequently, data extraction was divided into
        two stages: partial and full; and performed by two people. initially, titles and abstracts of all papers retrieved from the
        databases were read. only the articles that met the inclusion criteria were read in full, for detailed information extraction and
        the extraction was performed by using a structured form briefly described in table 3.
        also,whetherornotthestudyincludedauserevaluationwastaken into account during the extraction. this aspect was considered rel- evant
        for identifying works that go beyond technical or theoretical descriptionsandprovideevidenceofpracticalapplicationsanduser
        experience. at the end of the selection process, 21 articles were accepted. the selection process is shown in figure 1, while
        table 4 presents the data collected from the articles selected during this phase. 5 results and discussion in this section, we
        present the results obtained in our investigation, based on the data synthesized in table 4. next, we answer the previously
        formulated research questions and perform a critical analysis of the evidence found, highlighting the contributions and
        limitations. 5.1 purpose of digital archives the analysis of the selected articles reveals that the digital archives addressed in
        these studies are applied in different contexts, also involving different purposes in their conception. in this sense, to support
        the discussion of rq1, we chose to divide the purposes of the archives into three strands: i) dissemination , related to im-
        proving visitation; ii) preservation , aimed at the maintenance and care of digital works over time; iii) availability , related
        to the facil- itation of access to digital works. these categories are not mutually
        exclusive;therefore,anarchivedescribedinacertainstudymayfall into more than one category, highlighting the multifunctionality of
        digital archives. 5.1.1 dissemination. dissemination, which involves the concern with providing a more meaningful experience of
        exploring the worksinthearchives,isthemostrecurringpurpose,beingobserved in 57.14% of the studies. a significant point raised in
        the works with this purpose is the need to condense the content presented to the user [ 3,30,38,43], which include, among others,
        examples that employ recommender systems for this purpose. this stems from702 whenart meets computer science: a sr about
        technologies and user interaction in adaptivedigital museums and archives webmedia’2025, rio de janeiro,brazil table 1:
        descriptive table of picoc protocol elements. picoc protocol population studies that describe the development, evaluation, or
        analysis of digital archives and their impacts. intervention “innovative” approaches to exploring digital archives. comparison
        digital archives with traditional interaction approaches, such as static web pages. outcome experience with the works, user
        experience, interest in exploring the digital archive. context academic papers published in conferences or journals, as well as
        applications made publicly available. records identified through database searching (n = 431)additional records identified through
        other sources (n = 0) records after duplicates removed (n = 360) records screened (n = 360) records excluded (n = 317) full-text
        articles assessed for eligibility (n = 43)full-text articles excluded, with reasons (n = 11) - not relevant (n = 2) - not
        open/available paper (n = 9) studies included in qual- itative synthesis (n = 21) studies included in quantita- tive synthesis
        (meta-analysis)identification screening eligibility included figure 1: prisma flow diagram illustrating the identification,
        screening, eligibility,and inclusion of studies accordingto the defined criteria. the fact that many archives have large databases
        of works and a heterogeneous audience. thus, the task of presenting appropriate content for a certain user becomes much more
        complex in this situation. bonis et al . [9]mention that, due to the large volume of
        dataintheseplatforms,thereisaneedforcontentrecommendation to enable user interaction with these extensive data sets. according to
        this study, a common strategy is to subdivide large data sets, therebygeneratingsubsets.fromthesesubsets,contentsuggestions
        aregeneratedforusers.tothisend,theauthorsimplementsemantic graphs to better organize the works. since archives also play an active
        role in mediating knowledge, those designed with this purpose often adopt various strategies to encourage user interaction and the
        discovery of new cultural products, making the experience more immersive and engaging. our review found works involving catalog
        personalization accord- ing to user characteristics ([ 3,38]), encouragement of users’ active participation in exploring the
        collections ([ 39]), and the creation of more intuitive environments ([19]). geng yang [19]evaluated what design characteristics
        are most important to users of these tools. a form was used to collect data on which factors influence user comprehension while
        navigating the page of a digital archive. in the case of [ 53], implementation efficiency was evaluated through experimental
        testing. the authorsdeveloped an automatic path search algorithm and applied it to a digital collection. then, they incorporated
        the obstacle avoidance technique and compared the performance before and after the im- plementation. the result revealed
        improvements not only in more natural movement but also in processing performance and use of memory space. another approach
        adopted by researchers involved improving how additional information about the works is communicated to users. studies such as [
        2,14] investigate more natural means of communication between the user and the collection, promoting greater familiarity and,
        consequently, better learning. to evaluate communication, [ 14] led an experiment in which, after interacting with the tool, the
        users responded to a survey assessing mixed reality experiences, as proposed in [ 50]. the results of this study will be discussed
        in more detail in section 5.3.2. also from a social perspective, [ 9] developed a method to create communities with similar
        interests, thus increasing engagement and encouraging col- laborative exploration of digital archives. once the user modeling is
        established, it was possible to compare different users, and thus create groups with similar interests. personalized rooms were
        cre- ated and assigned to users with similar preferences, so that users could meet and communicate.703 webmedia’2025, rio de
        janeiro,brazil oliveiraet al. table 2: database search strings. database search string acm digital library [[title: personaliz*]
        or [title: adapt*] or [title: cus- tomiz*] or [title: user-center*]] and [[all: ”digital archive”] or [all: ”digital collection”]
        or [all: ”digital museum”] or [all: ”virtual museum”] or [all: ”cultural heritage”] or [all: ”digital art gallery”]] sciencedirect
        title, abstract, keywords: ”digital archive” or ”digital collection” or ”digital museum” or ”virtual museum” or ”cultural
        heritage” or ”digital art gallery” title: per- sonalizationorpersonalizedoradaptationoradaptive or customization or customized or
        user-centered scopus title ( personaliz* or adapt* or customiz* or user- center* ) and title ( ”digital archive” or ”digital col-
        lection” or ”digital museum” or ”virtual museum” or ”cultural heritage” or ”digital art gallery” ) ieee xplore (”document
        title”:personaliz* or ”document ti- tle”:adapt* or ”document title”:customiz* or ”doc- ument title”:user-center*) and (”all
        metadata”:”digital archive” or ”all metadata”:”digital collection” or ”all metadata”:”digital museum” or ”all metadata”:”virtual
        museum” or ”all metadata”:”cultural heritage” or ”all metadata”:”digital art gallery”) note:each string was adapted to each
        platform’s search syntax. table 3: summary of key categories extracted from the ana- lyzed articles. question main answers purpose
        of the archive availability, dissemination, preservation interaction techniques and their improvementrecommendation systems,
        personalized 3d environment generation, software quality (a, folksonomy, chatbot, realistic environments, data organization
        interaction resources virtual reality, traditional page, voice, mixed reality, social network creation tools unity, python,
        javascript, xml, wordpress media formats of the artwork images, text, 3d models, audio, video user evaluation? yes, no, not
        informed reported challenges lack of funding, technical problems, user education, hardware limitations, interdisciplinary
        integration 5.1.2 preservation. the preservation of works, whether digitized or digital-born, is a central motivation for the
        development of sev- eral digital archives. however, within the scope of this review, few articles have focused on preservation;
        instead, this concern arose secondarily. for this reason, only 9.52% of the articles fall into this category. in [ 10], the goal
        of conserving digital cultural products [44] in digital archives is explicit. the researchers aimed at creating a digital
        collection of indonesian customs, arts, and traditions to ensure these are not lost over time. the “e-dayaknese” framework
        developed by the authors allows for the creation of entirely new cultural products or the association of new items with existing
        ones. it leverages a semantic structure based on the relationships between items, which facilitates the discovery of related
        content. in the proposed architecture, the digital organization of cultural data improves the consultation time and registration
        of new items. in addition to that, one of its modules is responsible for collecting usertable 4: articles included in this
        systematic review. # citation year rq1 rq2 rq3 1 [7] 2007 dis rs, peg vr 2 [9] 2009 dis rs, peg vr 3 [35] 2009 dis sq tp 4 [19]
        2009 ava sq tp 5 [30] 2009 dis rs, folk tp 6 [12] 2010 ava do tp, vr 7 [2] 2010 dis chat tp 8 [43] 2012 dis rs, folk tp 9 [3] 2013
        dis peg vr 10 [27] 2018 dis peg vr 11 [38] 2019 dis rs, peg vr 12 [39] 2019 dis rs, eye tp 13 [10] 2019 pre rs tp 14 [6] 2019 dis
        sq tp 15 [48] 2022 pre rs tp, vr 16 [49] 2023 dis rs, peg vr 17 [53] 2023 dis re vr 18 [23] 2023 dis re, eye, chat vr, voi 19 [45]
        2023 dis rs, sq tp 20 [25] 2024 ava peg vr 21 [14] 2024 dis chat mr, voi caption: ava: availability, dis: dissemination, pre:
        preservation, rs: recommendation systems, peg: personalized 3d environment generation, folk: folksonomy, chat: chatbot, eye:
        eye-tracking, re: realistic environments, sq: software quality analysis, do: data organization, vr: virtual reality, tp:
        traditional page, mr: mixed reality, voi: voice interaction. information, enabling personalized recommendations. the informa- tion
        is collected following the proposed 5r adaptation framework. the acronym 5r stands for right timing, right location, right device,
        right learner, and right contents, meaning that the rec- ommendation is made based on the user’s context. in the validation
        process, a functional prototype of the proposed framework was implemented, but user surveys, scalability tests, or discussions on
        software evolution were not conducted. inturn,[ 45]presentsatoolthatstoresdigitalanddigitizedsculp- tures from artists
        representing various cultures around the world. the tool uses fuzzy logic-based resources to improve recommen- dations by taking
        into account user profiles and the experience of accessing cultural heritage. the architecture created for sculpt- mate contains
        three layers: the userinterfacelayer , which allows button configuration and 3d model visualization; the application logic layer ,
        which includes the implementation of content man- agement and personalization with fuzzy logic; and finally, the data storage
        layer , which stores user information and structures. the article mentions that the focus during development was on usabil- ity,
        adaptability, and performance, allowing for future evolution of the framework due to its modular implementation. the main im-
        provements discussed in the article are the implementation of more sophisticatedmachinelearningalgorithmsandtechniquesformore
        accurate recommendations. the paper also proposes the migration from local storage to a cloud server, with integration with apis
        to access external resources and models. furthermore, the authors discuss the possibility of implementing social functionalities,
        such as sharing preferences among users, promoting a more connected community. 5.1.3 availability. another purpose of digital
        archives is to make content available to the public, facilitating access to digital cultural products, as discussed in 33% of the
        analyzed studies. some studies704 whenart meets computer science: a sr about technologies and user interaction in adaptivedigital
        museums and archives webmedia’2025, rio de janeiro,brazil present models that address the heterogeneity of digital resources,
        proposing strategies for making content available in a way that improves user experience , whether by developing user-centered and
        enjoyable interfaces [ 19], or by implementing recommendation systems to guide access [ 12,53]. these approaches aim to make
        access to heritage more inclusive, adapted to individual needs and, at the same time, increase interactivity and visitor
        engagement, providingaricherandmorepersonalizedexperience.budimanetal . [10]and strousopoulos et al . [45]state that, in addition
        to acting as preservation tools, collections play a crucial role in democratizing access to the heritage of socioethnic entities
        with limited visibility on the global stage. these tools not only ensure digital preservation but also expand access to the
        represented cultures. similarly, bollini [6]proposes the centralization of information on cultural heritage, aiming to make
        content available both to na- tives and to the non-specialized public in the milan region. that strategy is intended to preserve
        the relationships between docu- ments during the process of organizing and digitizing the works. this model aims to broaden access
        to cultural resources, promoting greater understanding among diverse audiences and encouraging engagement with local history. in
        the evaluation process, a survey was conducted with 24 participants, and the data were analyzed according to norman’s guidelines.
        based on the findings, a second design cycle was launched to implement the necessary improve- ments. the collection was evaluated
        within the field of hci, aiming toverifyusabilityanduser-centereddesign.however,noeffortwas
        madetoanalyzethecollection’spotentialforpopularization;thatis, metrics of reach or social impact were not taken into
        consideration. 5.2 techniques and technologies digital archives and museums are driven by a variety of technolo- gies aimed at
        providing immersive and personalized experiences for users. this section discusses the main technological approaches
        andtheirrelationtothearchivepurposesidentifiedintheliterature, seeking to answer the research question rq2. 5.2.1 virtual
        environments. in digital museum studies, virtual en- vironments can take on various forms and characteristics. in this article,
        virtual environments are considered as 3d interfaces, which may or may not resemble the physical spaces of real museums, allowing
        users to navigate, interact with, and explore exhibitions. this type of system often uses 3d modeling and supports specific
        equipment, such as vr headsets. svanaes [46]argues that the meaning of something is generated from the physical interactions we
        establish with the environment. thus, perception and interaction are directly linked to how we see an artifact and what it
        represents – not statically, but dynamically and generated at the moment of interaction. vr provides the envi- ronment through
        which the user can interact and, consequently, create new meanings and perceptions of the surrounding objects. therefore, it has
        become one of the most common resources in digital museums, providing immersive experiences that allow users to explore
        exhibitions intuitively. 3d virtual environments have been widely adopted in studies focusing on adaptive enhancements to
        conventional museums. for example, komianos and oikonomou [27], rajaonarivo et al . [38], bonis et al . [9], yang et al . [49],
        zhao[53],andkimetal .[25]presentsolutionsthatadapttheuserexperi- ence to the context of traditional museums through
        personalization and interaction enhancements within 3d virtual environments. these studies represent approximately 28% of the
        publications in our slr. these studies focus on different characteristics of virtual envi- ronments.forexample,in[
        49]thedevelopmentoftheenvironment reflects a concern with realism in the rendering of 3d models. the article describes the steps
        used for gamma correction, color, and tone adjustments of images to create a more realistic and therefore more immersive
        environment. zhao [53]also address this concern bydiscussingthefollowingmodelingmethods:geometricmodeling, based on mathematical
        models and computer graphics; and image- based modeling, using real image capture. while the former offers many details in the 3d
        model, it is computationally expensive for complex environments such as a digital museum. the latter offers many visual details
        but has limitations regarding the interactivity of the 3d model. therefore, the authors propose a hybrid modeling approach,
        leveraging the interactivity of the first method and the realism of the second. in addition to the visual realism of 3d models in
        the virtual envi- ronment,zhao [53]alsodiscussesmorenaturalformsofnavigation. for example, algorithms are developed, to ensure
        that movement occurs naturally, smoothly avoiding objects rather than passing through them. other works discuss the effective
        arrangement of artworks within the space, considering artistic categories [ 9], user preferences [ 38], and immersion time within
        the virtual environ- ment [27]. 5.2.2 traditional interfaces. while several adaptive works high- light a preference for 3d virtual
        environments, in which the user is directly immersed in the exhibition context, studies such as [ 2]
        proposeanalternativeapproach.inthisstudy,artworksarebrought closer to the user through simplified interfaces focused on prior-
        itizing direct interaction with displayed items, without the need for full immersion in a virtual environment. in this case, the
        user interacts directly with the model of the artwork and does not navi- gate through a virtual environment. this interaction is
        performed through traditional visual commands, by clicking buttons on the archive’s interface. studies such as [ 12] and [6] also
        favor the use of traditional web pages due to the diversity of resources available to users. this approach is common in contexts
        where resource heterogeneity de- mands a more conventional interface, focused on user-centered curation. on the other hand,
        studies aiming to enhance the user experience through interface adaptations, such as [ 35] and [19], opt for simplified and
        conventional traditional pages. this is be- cause the inclusion of external elements, such as excessive menus,
        disconnectedfunctionalities,orredundantinformation,wouldcom- promise the immersiveness of the archive. in a context where
        immersion is not a priority, several studies are dedicated to gathering and adapting artworks based on cultural and ethnic
        characteristics, without the intention of replicating a real-world exhibition in a virtual environment. examples can be found in
        studies such as [ 10,30,43,48], which adopt traditional page structures. these works focus on curating and organizing artworks
        based on cultural and ethnic categories.705 webmedia’2025, rio de janeiro,brazil oliveiraet al. 5.2.3 recommendationalgorithms.
        the literature highlights the growing adoption of recommendation algorithms in different types of digital archives, both in 3d
        virtual environments and traditional pages,aimingtoenhancethepersonalizationoftheuserexperience. in 3d environments,
        recommendation involves various tech- niques. javdani rikhtehgar et al . [23]and raptis et al . [39]use eye-tracking to assist in
        analyzing user behavior and enable sug- gestions based on their points of interest. for instance, in [ 23], users’ eye movements
        were tracked to determine which elements within paintings most attracted their attention (buildings, faces, and details). this
        information was used to make personalized rec- ommendations. the study also reveals that gaze duration can serve as an indicator
        of user preference, but this correlation comes with certain limitations. user surveys showed that the display order of artworks,
        how detailed the artwork is, or whether it has a more or less interesting description also impact gaze duration, but they do not
        necessarily define a user profile. in contrast, folksonomy-based approaches, as seen in [ 43] and [30], involve organizing content
        through collaboratively defined categories, and traditional pages provide users with a familiar inter- face to perform this task.
        in [ 30], users rated paintings (from 1 to 5) and added tags they deemed appropriate. the interface provided access to the
        painting image, title, description, and other popular tagscreatedbyusers.adatacollectionprocesswascarriedoutwith 40 individuals
        (30 general users and 10 experts) to gather tags for training a multivariable poisson model. tags were classified as (i)
        personaltags,providedbyaspecificuserforaspecificartwork;and (ii) socialtags, assigned to the artwork by various users. the results
        showed a general improvement in filtering accuracy with tags cre- ated by users. based on this, the authors proposed a hybrid
        system that incorporates folksonomy into content-based recommendation. to evaluate this framework, k-fold cross-validation and
        metrics suchasprecisionandrecallwereused,tiedtodifferentexperimental combinations (permutations between static content implementa-
        tion, personal tags, and social tags). the inclusion of socialtags produced lower results than personaltags, and combining static
        information (artwork descriptions) with personaltags achieved the highest filtering precision. the main results of this study show
        that personal preferences are more relevant than general consensus when making recommendations. moreover, models that adapt to
        user preferences are present in both immersive environments and traditional pages. examples include the use of machine learning
        for personalization, as in [ 49] and [25], as well as genetic algorithms and fuzzy logic for more accurate recommendations, as
        previously addressed in [45]. the dynamic generation of 3d virtual spaces can also be tailored to user characteristics and the
        curated selection of artworks to be displayed. in [ 8,9,38], semantic graphs grouped artworks for users, optimizing the
        recommendation process. in [ 53], recommendations are generated based on user profile, which includes demographic attributes
        collected to associate new cases with similar past ones, using the case-based reasoning technique. recommendations are generated
        in a ranked list of the best visitation routes. likewise, in [49] demographic data (age, profession, gender, education level) are
        collected to serve as input for a deep learning model that can infer user preferences.in addition to these approaches, other
        methods also deserve mention, such as calculating the proximity between clusters of artworks and users, as described in [ 25]. in
        this case, artworks are divided into thematic clusters, based on similarity in color, material, description, artist, and creation
        date. once the groups are defined, distances between them are calculated, representing how different
        theyarefromoneanother.thisinformationisthenusedtogenerate more coherent thematic exhibitions. 5.2.4 chatbots. [2,14,23] implement
        chatbots and voice inter- action to improve communication between users and the archive systems. those systems are complementary
        to the standard ways of interaction, like mouse and keyboard, and so not mandatory to the user. in [ 2], speech recognition is
        limited by the grammar that the system can recognize, which restricts interaction with the user. in this type of approach,
        questions outside the system’s predefined pattern are not understood, which could frustrate users. through this system, users can
        obtain specific information about artworks and also use specific voice commands for navigation. voice-guided navigation adds an
        accessibility layer to the software, enabling use by people with motor or visual impairments, in addition to offering a different
        form of interaction for users to acquire knowledge of the artworks. nonetheless, this feature should be regarded as a
        complementary interaction method, as reliance on voice guidance alone may pose accessibility barriers for deaf users. 5.3
        interaction features interactionfeaturesplayafundamentalroleinuserengagementand satisfaction. from this perspective, the studies
        revealed different forms of interactivity with digital archives, which will be presented in the following topics, allowing us to
        address rq3. 5.3.1 interactioninvirtualandaugmentedrealityenvironments. vr is one of the technologies that enables the creation of
        3d virtual environments, where interaction can be either immersive (through
        theuseofvrheadsetsorhapticgloves)ornon-immersive(typically via conventional screens). in [ 9], vr allows the development of a more
        immersive and realistic experience for the user, as it also enables more natural navigation. the construction of vr spaces
        involves several stages, such as the arrangement of objects in the environment, texturing, lighting, and, in some cases,
        animation. the works of [ 7,9,38,49,53] seek ways to facilitate the con- struction of vr environments and represent 25% of the
        articles we analyzed. in these studies, methods were developed to automate and simplify the creation of vr environments through
        algorithms capable of arranging the items across the available space, given a set of artworks – an otherwise time-consuming and
        repetitive manual task. in [ 27], this arrangement also aims to optimize the user’s time by ensuring that artworks are placed in
        appropriate locations with dynamically calculated spacing, minimizing unnec- essary time spent during exploration. likewise, [ 53]
        also develops an algorithm to find more natural paths that avoid obstacles in exhibitions, thereby improving the user’s navigation
        experience. in [53], interaction occurred in an intuitive and immersive man- ner, allowing users to explore the digital archive
        through different modalities. sensors captured movements, voice commands, and706 whenart meets computer science: a sr about
        technologies and user interaction in adaptivedigital museums and archives webmedia’2025, rio de janeiro,brazil gestures to enable
        fluid navigation through the virtual environ- ment, while an intelligent roaming system automatically adjusted the trajectory to
        avoid obstacles, making navigation faster. vari- ous media formats (text, image, animation, sound, and video) were also integrated
        into the systems to find more user-friendly ways to convey information. other articles, such as [ 53], [9], and [38], do not
        explicitly de- scribe how user interaction takes place – whether through mouse, keyboard, or any special equipment. in contrast, [
        49] details how interactionoccurs:thewasdkeysareusedtonavigatetheenviron- ment, the r key activates automatic navigation to a
        user-defined point, the mouse sets the viewing direction, and the right-click allows the user to rotate objects. strousopoulos et
        al . [45]describe an alternative to standard devices: headsets compatible with 3d vision, which provides greater immersion. an
        important point is that articles concerning archives using vr demonstrateaconcernwithnavigationthroughspace,emphasizing
        naturalness and user’s freedom. among the works analyzed, users were not suggested specific routes to follow; guidance occurred
        throughthemuseum’sconstructionbasedonartworkselectiondur- ing curation and automatic space creation. the only exception was [3],
        in which a route is suggested to the user and adapted not only to their preferences but also to their reactions while navigating
        the exhibition. it is worth noting that navigation is a key challenge in any vr environment, particularly immersive ones requiring
        head- sets, and not an issue exclusive to virtual archives, so that solutions and challenges in vr from other domains might apply
        to digital archives as well. surprisingly, the analyzed studies do not address motion sickness, a common concern in immersive vr
        experiences. although most works include some form of user evaluation, these are often limited to assessing curatorial aspects.
        they analyze, for example,thepositioninganddistributionofartworks,orthequality of the rendering and lighting, rather than comfort
        or discomfort during navigation. 5.3.2 voice interaction. from another perspective, in [ 2,14,23], representing 14% of the
        studies, voice resources permit a more per- sonalized and natural user interaction. with advancements in the development of llms
        (large language models), such as llama or gpt, text generation has become significantly more sophisticated and complex, allowing
        for advancements in voice system imple- mentation for digital archives, as done in [ 14]. in this project, an application was
        developed for microsoft hololens (1st generation) to present artworks to visitors, integrated with a system using the gpt-3.5
        model, which received the user’s audio recording and gen- erated the desired responses. in the application evaluation tests, a
        mixedrealityapproachwasused,displayingimagesoftheartworks to users through the headset. the results of the study indicated that
        this technology has the potential to captivate users. two metrics showed lower performance in the empirical test: immersion and
        re- sponse credibility. although the metrics and tests that indicated the model’s responses were accurate, users reported that
        they would not trust the information provided in awkward responses. further- more, they mentioned that the interaction with the
        conversational agent did not seem natural or realistic in the archive. 5.3.3 webpages. webpagesarewidelyusedtodayasasolutionfor
        digitalarchives.consideringthatoneofthegoalsofsuchcollectionsis to make archived material available, web pages offer broad com-
        patibilitywithcurrentdevices,easeofusethroughelementssuchas menusandhyperlinks,andhighscalabilityforlargeaudiences.this formof
        interaction wasemployed in [ 6,10,12,19,30,35,39,43,45], which represent 43% of the articles. some studies implemented
        traditional-format web pages with- out incorporating any unconventional interaction element. one noteworthy example is [ 19] which
        presents a study and heuristic analysis of the interfaces of three different digital museums, aiming to identify the design
        elements that are most important for creating effective interfaces of this kind. the factors deemed most impor- tant were the
        usermodel and theinterpreter . this emphasizes that the interface must have high usability and communicability, easily conveying
        its purpose and content to the user and responding sat- isfactorily to user interactions. aesthetics, although relevant, was not
        prioritized; the main aspects mentioned were typography (font size and family choice) and the alignment of page elements. in [6],
        a different form of user interaction is addressed. their framework features a map-based visualization that can be freely ex-
        ploredbytheuser.foreachpointonthemap,historicalinformation is provided by the various communities that lived there. 6 quantitative
        analysis figure 2 presents the temporal evolution of publications related to the adaptation of digital archives and museums. the
        graph shows that, despite a reduction in the number of publications in the years 2012, 2013, and 2018, the topic has been
        regaining prominence, indicating a renewed interest in the field. vr is the most widely adopted technology in the studies,
        followed by traditional web interfaces. other technologies, such as voice interaction and chat- bots, appeared in 2010 but only
        resurfaced in 2023, likely due to recent advancements in ai. the word cloud presented in figure 3 underscores the terms most
        frequently used in the analyzed studies, revealing a prominent interest in personalization, vr, and immer- sive experiences.
        complementing this discussion, figure 4, generated with the supportofthe bibliometrix andhighcharts tools,showsthenumber of
        publications by country. greece is the country with the highest number of publications, totaling 12 articles, followed by china,
        which appears in 7 publications. the results highlight the absence of publications from north or south american countries,
        revealing the need for broader discussions on interaction aspects in digital archives and museums. figure 5 emphasizes the
        relationship between the main interac- tion features employed in the papers analyzed and the purposes of the archives, categorized
        into three strands: dissemination, preser- vation, and availability. the strong interest in the use of vr stands out, as evidenced
        by its widespread adoption in 50% of the works included in the figure. one example is the study by [ 38], which proposes a model
        capable of generating a 3d virtual environment with the user’s works of interest. moreover, vr shows a similarly significant
        presence in archives aimed both at availability and dis- semination. a scarcity of works exploring other approaches, such as ar,
        is also noticeable, suggesting that technological barriers or the need for specific infrastructure may limit its application for
        navigation in digital archives. additionally, although the number707 webmedia’2025, rio de janeiro,brazil oliveiraet al. number of
        papers145 1 1 145 3 032 10 031 0 1 11 01 1 13 1 0 01 0 0 0 011 0 010 0 0 0 01traditional interfaces virtual reality chatbot voice
        interaction 2007 2009 2010 2012 2013 2018 2019 2023 20240246 figure2: trendsin the use of interaction features in works on digital
        archive adaptation. figure 3: word cloud with terms used in the studies. figure 4: publications by country. of studies
        implementing conversational agents and voice interac- tion is limited, these technologies appear to be more present instudies
        focused on archive availability, suggesting a possible rela- tionship between their adoption and the facilitation of access to
        digital cultural products. with regard to evaluation, 71% of the studies conducted experi- ments with users. notably, 100% of
        these works aimed at dissem- ination or availability, suggesting a significant focus on aspects of user interaction and access to
        archived materials. furthermore, there is a recurrence of studies seeking to empirically validate their proposals. user
        participation in this process is essential, as many of the developed solutions aim to meet individual preferences and interests,
        making the experience more engaging and personalized. in summary, by observing the focus on dissemination and avail- ability as
        purposes, the analyzed data reveal that digital archives and museums perform the role of active agents in the mediation of
        knowledge and collective memory in digital culture. the em- phasis on vr highlights the concern with user immersion in the virtual
        environment; however, the low application of ar indicates an opportunity to be explored. ultimately, empirical evaluations
        involving users are essential to validate the proposed approaches. oneoftherecurringissuesintherealmoftheartsconcernscopy- right.
        despite its relevance, only two studies explicitly address this matter in a significant way. in [ 45], the quality of 3d
        digitization of artworks is limited by the difficulty of accessing artifacts protected by copyright. in [ 12], copyright-related
        issues are discussed from a different perspective: the protection of digital artworks. one of the features proposed for the
        environment described in that study is the integration of a content management system equipped with security mechanisms capable of
        efficiently protecting various digi- tal artworks in their multiple multimedia formats (text, image, 3d model, among others). this
        type of technology is particularly im- portant in digital collections, which aim not only to provide access to content but also to
        ensure the preservation and respect of intel- lectual property rights. thus, tools designed to prevent the misuse of images,
        unauthorized copies, or non-consensual modifications contributenotonlytolegalcompliancebutalsototheconsolidation of digital
        preservation initiatives. 7 challenges and opportunities the analysis of research on digital archives reveals both persistent
        challenges and opportunities to enhance the interaction experience708 whenart meets computer science: a sr about technologies and
        user interaction in adaptivedigital museums and archives webmedia’2025, rio de janeiro,brazil 77 4444 44 2222 1133 voice
        interaction chatbots traditional interfaces virtual environments0 2 4 6 8 10 12 14 16 18dissemination availability preservation
        figure 5: interaction features by digital archive/museum purpose. within digital repositories. several studies have explored
        adapta- tionsandpersonalizationsbasedonuserprofiles,asseenin[ 43]and [23], and have proposed interactive features to improve
        navigation and content access. however, there is a noticeable lack of effec- tive applications of these approaches in natively
        digital archives. in many cases, the studies are limited to conceptual development models. for example, in [ 27], the evaluation
        is conducted using only a prototype, without implementing the results in an actual digital archive. this lack of a comprehensive
        evaluation constrains the findings to a non-realistic context. moreover, there is a clear scarcity of specific approaches in the
        construction and exploration of digital archives. for example, no implementations of 2d virtual environments were found. the main
        argument for implementing 3d virtual environments is that this interaction medium allegedly promotes greater immersion. how- ever,
        immersion is also present in 2d, albeit to a lesser degree. furthermore, hybrid adaptations that combine traditional pages with
        virtual environments tend to be more acceptable in the 2d model, as interaction is typically performed through devices that have
        become commonplace in users’ daily lives. additionally, the integration of conventional elements is also facilitated, given that
        2d interfaces are common to many other applications, making the platform more intuitive and familiar to users. it is also
        important to note that 3d virtual environment applica- tions are commonly used in the digitization of physical collections
        belonging to institutions whose buildings are, in themselves, works of art. this is the case for the louvre museum, the tate
        museum, or the museu da vida fiocruz, which are digital archives that preserve not only digitized works but also the physical
        architecture of the building that houses them. however, in the studies analyzed in this
        review,3dvirtualenvironmentsdidnotdemonstratethesamelevel of attention to architectural preservation, as they were focused on
        facilitating the generation of the virtual environments. althoughimmersiveandadaptivestrategies,asseenin[ 7,25,38], offer users
        greater immersion and more engaging visits, the use of specific devices, such as vr headsets, limits access to digital archives.
        as such, this should be an optional resource, as proposed in [45], where the use of headsets is not mandatory. also concerning the
        access to digital archives, it is evident that there is a shortage of implementations focused on the availability of works.
        javdani rikhtehgar et al . [23]and constantinides et al . [14]propose interaction methods that enhance the availability ofcontent
        to users; however, these are exceptions among the articles in our sample. the remaining studies do not address this issue,
        revealingaclearlimitationinthepotentialdisseminationandreach of digital archives. furthermore, most systems are still based on
        traditional web pages and do not implement innovative solutions. although this is not necessarily a problem, there is a clear lack
        of standardization and guidelines for developing digital archives. the studies by zhao [53], geng yang [19], and pedrero et al .
        [35]go in this direction; however, there is no clear organizational structure that provides consolidated guidelines for these
        implementations. another relevant aspect is the difficulty to integrate different areas of knowledge. works such as [ 10] clearly
        state that the cre- ation of digital archives is a multidisciplinary project, involving not only the cultural elements to be
        preserved, but also the tech- niques and guidelines for building robust software. studies in the field of computer science
        emphasize technological aspects in the development of archives, neglecting certain unique characteristics of digital works and
        interactions that arise from the digital world – elements that are, in turn, highlighted and analyzed in case studies from the
        humanities. a strong association between both fields is imperative for the development of the area and to meet the expecta- tions
        for digital archives from both technical system aspects (such as accessibility,usability,interactivity, etc.) and humanistic
        archival concerns (such as curation, storytelling, and representativeness of the collection, for example). additionally, the
        development and creation of digital archives are intrinsically linked to the preservation of the archived works, meaning that they
        must endure over time. in this regard, for the development of the software, its evolution in response to changes in technology and
        social dynamics must be considered. some al- ternatives to this problem have already been proposed and could be adapted and
        implemented, such as lehman’s laws. in [ 45], this ideaispresent;however,itwasexpectedtobemorewidelyadopted in the development of
        this type of platform. finally, it is important to highlight the development of plat- forms that support the preservation of
        collections with limited resources. preservation efforts should not be constrained by the broad availability of personnel,
        infrastructure, and financial re- sources – conditions typically found in well-established physical
        archives,orinstitutionssupportedbyexternalfunding.alternatives are explored in works such as [40], which proposes a paradigm of
        projects that incorporate minimal computing and, therefore, reduce709 webmedia’2025, rio de janeiro,brazil oliveiraet al.
        development costs. in parallel, there are also initiatives involving low-cost implementations that, for example, incorporate
        social me- diaortoolssuchastainacantoexpandaccessandthesustainability of digital preservation [36]. 8 final remarks in this study,
        a systematic review was conducted with the objec- tive of identifying the main technologies and forms of interaction employed in
        digital archives. from this analysis, it is evident that there is a lack of standardization in the field regarding guidelines and
        norms for the creation of such platforms. moreover, our results show that there is limited use of software engineering practices
        for software maintenance and preservation – essential aspects in the field of digital preservation studies. finally, most of the
        works did not demonstrate concern with evaluating software quality aspects, which reveals a significant gap as to human-computer
        interaction. as a scope limitation, this review included only projects that develop digital archives intended to host multiple
        works, excluding those focused on building technologies for individual exhibitions or
        singleartworks.relevantfutureworkcouldfocusoninitiativesthat aim to standardize the development processes of digital archives or,
        at the very least, the systematic documentation of such practices. 9 ethical considerations this work presents a systematic
        literature review, characterized as secondary research, since it does not involve direct interaction with participants nor the
        exposure of individuals to technologies or computational systems. therefore, according to cns resolution no. 510/2016 and cns
        resolution no. 674/2022, it is exempt from approval by the research ethics committee involving human sub-
        jects.thedatausedreferexclusivelytothemetadataoftheanalyzed articles, which are publicly available in the databases selected and
        described in section 4. acknowledgments thisstudywascarriedoutwiththesupportoffapematandcnpq, through the granting of research
        scholarships. the english version of this article was produced with the assistance of chatgpt and carefully revised by the
        authors. language correction tools, such as writefull, were also employed during the writing process. all stages of data
        selection, analysis, and discussion were conducted exclusively by the authors, with ai tools used solely as writing aids.
        references [1]r.ahmadandm.rafiq.2023. globalperspectiveondigitalpreservationpolicy:a systematic review. journaloflibrarianship
        andinformation science 55, 3 (2023), 859–867. https://doi.org/10.1177/09610006221111572 [2]salvatore andolina, antonella
        santangelo, and antonio gentile. 2010. adap- tive voice interaction for 3d representation of cultural heritage site. in
        2010international conference oncomplex, intelligent andsoftware intensive systems . ieee, krakow, tbd, poland, 729–733.
        https://doi.org/10.1109/cisis. 2010.139 [3]asma hanee ariffin and yu-n cheah. 2013. see what you want, feel what you see: the
        personalized re-recommendation framework using hybrid strategies for fieldtripplan.in 2013thirdworldcongress oninformation
        andcommunication technologies (wict2013). ieee, hanoi, vietnam, 262–267. https://doi.org/10. 1109/wict.2013.7113146 [4]sitaram
        asur, bernardo huberman, gábor szabó, and chunyan wang. 2011. trends in social media : persistence and decay. 5thinternational
        aaaiconference onweblogs andsocialmedia(02 2011). https://doi.org/10.2139/ ssrn.1755748 [5]caroline bertini fernandes and márcia
        gomes marques. 2019. a publicação de poesia na internet: a literatura de clarice freire. vista4 (july 2019), 175–197.
        https://doi.org/10.21814/vista.3020 [6]letizia bollini. 2019. representing a space-based digital archive on historical
        maps:auser-centereddesignapproach. in proceedings ofthe1stinternational andinterdisciplinary conference ondigitalenvironments
        foreducation, arts andheritage , alessandro luigini (ed.). vol. 919. springer international publish- ing, cham, 599–607.
        https://doi.org/10.1007/978-3-030-12240-9_62 series title: advances in intelligent systems and computing. [7]bill bonis, john
        stamos, spyros vosinakis, ioannis andreou, and themis panayiotopoulos. 2007. personalization ofcontent invirtual exhibitions .
        springer berlin heidelberg, 172–184. https://doi.org/10.1007/978-3-540-77051- 0_19 [8]bill bonis, john stamos, spyros vosinakis,
        ioannis andreou, and themis panayiotopoulos. 2007. personalization of content in virtual exhibitions. in semantic multimedia ,
        bianca falcidieno, michela spagnuolo, yannis avrithis, ioannis kompatsiaris, and paul buitelaar (eds.). vol. 4816. springer berlin
        heidel- berg, berlin, heidelberg, 172–184. https://doi.org/10.1007/978-3-540-77051-0_19 series title: lecture notes in computer
        science. [9]b. bonis, j. stamos, s. vosinakis, i. andreou, and t. panayiotopoulos. 2009. a platform for virtual museums with
        personalized content. multimedia toolsand applications 42, 2 (april 2009), 139–159. https://doi.org/10.1007/s11042-008- 0231-2
        [10]e budiman, m wati, and norhidayat. 2019. the 5r adaptation framework for cultural heritage management information system of
        the dayak tribe borneo. journal ofphysics: conference series1341, 4 (oct. 2019), 042016. https://doi.
        org/10.1088/1742-6596/1341/4/042016 [11]manuel castells. 2005. sociedade emrede. paz e terra, são paulo. [12]chengwei yang, rui
        wang, lu wang, chenglei yang, shijun liu, and xiangxu meng. 2010. the personalized service customization based on multimedia re-
        sources in digital museum grid. in 20103rdieeeinternational conference on ubi-media computing . ieee, jinhua, china, 298–304.
        https://doi.org/10.1109/ umedia.2010.5544439 [13]teixeira coelho. 2020. ecultura, autopia final:inteligência artificial e
        humanidades. editora unesp, são paulo. [14]nicolasconstantinides,argyrisconstantinides,dimitrioskoukopoulos,christos fidas, and
        marios belk. 2024. culturai: exploring mixed reality art exhibitions withlargelanguagemodelsforpersonalizedimmersiveexperiences.in
        adjunct proceedings ofthe32ndacmconference onusermodeling, adaptation and personalization . acm, cagliari italy, 102–105.
        https://doi.org/10.1145/3631700. 3664874 [15]jacqueline de araújo cunha and marcos galindo lima. 2024. preservação digital:
        tendências atuais dos conceitos e técnicas. revistaanalisando emciência da informação 11, 2 (nov. 2024), 45–60.
        https://revista.uepb.edu.br/racin/article/ view/4069 [16]qiong dang. 2018. literature review on the digital museum in a chinese
        context. communication, societyandmedia1, 2 (nov. 2018), 149. https://doi. org/10.22158/csm.v1n2p149 [17]ioannis drivas and
        eftichia vraimaki. 2025. evaluating and enhancing museum websites: unlocking insights for accessibility, usability, seo, and
        speed. metrics 2, 1 (jan. 2025), 1. https://doi.org/10.3390/metrics2010001 [18]danilo formenton and luciana de souza gracioso.
        2020. preservação digital: desafios, requisitos, estratégias e produção científica. rdbci: revista digital debiblioteconomia
        eciência dainformação 18, 00 (jun. 2020), e020012. https: //doi.org/10.20396/rdbci.v18i0.8659259 [19]geng yang. 2009. a study on
        the user-centered interface design for vir- tual museums. in 2009ieee10thinternational conference oncomputer-aided industrial
        design &conceptual design. ieee, wenzhou, china, 1647–1651. https://doi.org/10.1109/caidcd.2009.5374866 [20]pablo gobira and
        fernanda corrêa. 2019. a preservação digital da poesia: uma análise do arquivo digital da po.ex. in amemória
        dodigitaleoutrasquestões dasartesemuseologia (1ed.),pablogobira(ed.).vol.1.eduemg,belohorizonte, 165–188. [21]katherine harris.
        2014. archive. in thejohnshopkins guidetodigitalmedia, marie-laure ryan, lori emerson, and benjamin j. robertson (eds.). johns
        hop- kins university press, 16–18. [22]ahdab najib hijazi and ahmad hanif ahmad baharin. 2022. the effectiveness of digital
        technologies used for the visitor’s experience in digital museums. a systematic literature review from the last two decades.
        international journal ofinteractive mobiletechnologies (ijim)16, 16 (aug. 2022), 142–159. https:
        //doi.org/10.3991/ijim.v16i16.31811 [23]delaram javdani rikhtehgar, shenghui wang, hester huitema, julia alvares, stefan
        schlobach, carolien rieffe, and dirk heylen. 2023. personalizing cultural
        heritageaccessinavirtualrealityexhibition:auserstudyonviewingbehavior andcontentpreferences.in adjunct proceedings
        ofthe31stacmconference on usermodeling, adaptation andpersonalization .acm,limassolcyprus,379–387.710 whenart meets computer
        science: a sr about technologies and user interaction in adaptivedigital museums and archives webmedia’2025, rio de janeiro,brazil
        https://doi.org/10.1145/3563359.3596666 [24]otim kayaga and kiu publication extension. 2024. digital archiving and preser- vation
        of art: challenges and innovation. 3 (08 2024), 21–25. [25]hayun kim, maryam shakeri, jae-eun shin, and woontack woo. 2024. space-
        adaptiveartworkplacementbasedoncontentsimilaritiesforcuratingthematic spaces in a virtual museum. journaloncomputing andcultural
        heritage 17, 1 (feb. 2024), 1–21. https://doi.org/10.1145/3631134 [26]barbarakitchenham.2004.
        proceduresforperformingsystematicreviews. keele, uk,keeleuniv. 33 (08 2004). [27]vasileios komianos and konstantinos oikonomou.
        2018. adaptive exhibition topologies for personalized virtual museums. iopconference series:materials science andengineering 364
        (june 2018), 012011. https://doi.org/10.1088/1757- 899x/364/1/012011 [28]jin woo lee, yikyung kim, and soo hee lee. 2019. digital
        museum and user experience: the case of google art & culture. in international symposium on electronic art. international
        symposium on electronic art. [29]jingjing li, xiaoyang zheng, ikumu watanabe, and yoichi ochiai. 2024. a systematic review of
        digital transformation technologies in museum exhibition. computers inhuman behavior 161 (dec. 2024), 108407.
        https://doi.org/10.1016/ j.chb.2024.108407 [30]pasquale lops, marco de gemmis, giovanni semeraro, cataldo musto, fedelucio
        narducci,andmassimobux.2009. asemanticcontent-based recommendersys- tem integrating folksonomies for personalized access. in
        webpersonalization inintelligent environments , janusz kacprzyk, giovanna castellano, lakhmi c. jain, and anna maria fanelli
        (eds.). vol. 229. springer berlin heidelberg, berlin, heidelberg, 27–47. https://doi.org/10.1007/978-3-642-02794-9_2 series title:
        studies in computational intelligence. [31]lev manovich. 2001. thelanguage ofnewmedia. mit press, cambridge, ma. [32]dalton lopes
        martins, josé eduardo santarém segundo, marcel ferrante silva, and joyce siqueira. 2017. repositório digital com o software livre
        tainacan: revisão da ferramenta e exemplo de implantação na área cultural com a re- vista filme cultura. in anaisdoencontro
        nacional depesquisa emciência da informação (enancib). ancib. [33]trevor owens and thomas padilla. 2020. digital sources and
        digital archives: historicalevidenceinthedigitalage. international journalofdigitalhumanities 1 (2020), 325–341.
        https://doi.org/10.1007/s42803-020-00028-7 [34]dragana pavlović. 2022. digital tools in museum learning – a liter- ature review
        from 2000 to 2020. factauniversitatis, series:teaching, learning andteacher education (jan. 2022), 167. https://doi.org/10.22190/
        futlte211104013p [35]a. pedrero, v. alonso, m.a. villarroel, p. de la fuente, and a.s. cabaco. 2009. presentation adaptation:
        results from a case study. in engineering theuser interface ,miguelredondo,crescenciobravo,andmanuelortega(eds.).springer london,
        london, 1–13. https://doi.org/10.1007/978-1-84800-136-7_15 [36]vinícius carvalho pereira. 2024. poesia em flash na antología de
        liter- atura electrónica latinoamericana y caribeña: questões de arquivo. acta scientiarum. language andculture 46, 1 (may 2024),
        e65240. https://doi.org/10. 4025/actascilangcult.v46i1.65240 [37]isabella peters and wolfgang g. stock. 2007. folksonomy and
        information retrieval. proceedings oftheamerican society forinformation science and technology 44, 1 (jan. 2007), 1–28.
        https://doi.org/10.1002/meet.1450440226 [38]landy rajaonarivo, eric maisel, and pierre de loor. 2019. an evolving museum metaphor
        applied to cultural heritage for personalized content delivery. user modeling anduser-adapted interaction 29, 1 (march 2019),
        161–200. https: //doi.org/10.1007/s11257-019-09222-x [39]george e. raptis, christos fidas, christina katsini, and nikolaos
        avouris. 2019. a cognition-centered personalization framework for cultural-heritage content. usermodeling anduser-adapted
        interaction 29, 1 (march 2019), 9–65. https: //doi.org/10.1007/s11257-019-09226-7 [40]roopika risam and alex gil. 2022.
        introduction: the questions of minimal com- puting.digitalhumanities quarterly 16,2(2022). http://www.digitalhumanities.
        org/dhq/vol/16/2/000620/000620.html [41]rejane c. rocha. 2021. fora da estante: questões de arquivo e de preservação da literatura
        digital. nuevarevistadelpacífico 74 (june 2021), 290–309. https: //doi.org/10.4067/s0719-51762021000100290 [42]rejane c. rocha.
        2023. a memória literária: arquivo em tempos de bases de dados.universum (talca)38,1(jul2023),121–133.
        https://doi.org/10.4067/s0718- 23762023000100121 [43]giovanni semeraro, pasquale lops, marco de gemmis, cataldo musto, and
        fedelucio narducci. 2012. a folksonomy-based recommender system for person- alized access to digital artworks. journaloncomputing
        andcultural heritage 5, 3 (oct. 2012), 1–22. https://doi.org/10.1145/2362402.2362405 [44]m. n. sitokdana and a. r. tanaamah. 2016.
        strategi pembangunan e-culture di indonesia. jutisi 2, 2 (august 2016). [45]panagiotis strousopoulos, christos papakostas,
        christos troussas, akrivi krouska, phivos mylonas, and cleo sgouropoulou. 2023. sculptmate: personal- izing cultural heritage
        experience using fuzzy weights. in adjunct proceedingsofthe31stacmconference onusermodeling, adaptation andpersonalization . acm,
        limassol cyprus, 397–407. https://doi.org/10.1145/3563359.3596667 [46]d. svanaes. 2013. interaction design for and with the lived
        body: some implica- tions of merleau-ponty’s phenomenology. proceedings ofacmtransactions on computer-human interaction (tochi) 20
        (2013). special issue on the theory and practice of embodied interaction in hci and interaction design.
        [47]yantingtong,binyuecui,andyulinchen.2018. researchonuivisualdesignof intangible cultural heritage digital museum based on user
        experience. in 2018 13thinternational conference oncomputer science amp;education (iccse). ieee, 1–4.
        https://doi.org/10.1109/iccse.2018.8468809 [48]qinwang.2022. theapplicationofpersonalizedrecommendationsysteminthe cross-regional
        promotion of provincial intangible cultural heritage. advances inmultimedia 2022 (oct. 2022), 1–10.
        https://doi.org/10.1155/2022/5811341 [49]meng yang, jia-xiu zhang, yi shi, bo liu, le-xin guo, zhi-peng yu, bin sheng, and
        li-zhuang ma. 2023. framework of personalized layout for a museum exhi- bition hall. multimedia toolsandapplications 83, 8 (aug.
        2023), 24563–24587. https://doi.org/10.1007/s11042-023-16307-8 [50]jihyunyiandhaesunkim.2021.
        userexperienceresearch,experiencedesign, and evaluation methods for museum mixed reality experience. j.comput. cult. herit. 14, 4,
        article 48 (sept. 2021), 28 pages. https://doi.org/10.1145/3462645 [51]li yifei and mohd kamal othman. 2024. investigating the
        behavioural intentions of museum visitors towards vr: a systematic literature review. computers in human behavior 155 (june 2024),
        108167. https://doi.org/10.1016/j.chb.2024. 108167 [52]namira rahmi zahara and tamara adriani salim. 2022. preservation of digital
        archives: systematic literature review. recordandlibrary journal8, 2 (dec. 2022), 285–297.
        https://doi.org/10.20473/rlj.v8-i2.2022.285-297 [53]lingzhao.2023. personalizedhealthcaremuseumexhibitionsystemdesignbased on vr
        and deep learning driven multimedia and multimodal sensing. personal andubiquitous computing 27, 3 (june 2023), 973–988.
        https://doi.org/10.1007/ s00779-022-01672-2711
  > PALAVRAS-CHAVES:
    Não encontrado.
  > PROBLEMA:
    Score: 3.000
        when art meets computer science: a systematic review about technologies and user interaction in adaptive digital museums and
        archives enzo rigazzo oliveira media lab universidade federal de mato grosso cuiabá, mato grosso, brasil
        enzo.oliveira@sou.ufmt.brgabriel josé do amaral schuina media lab universidade federal de mato grosso cuiabá, mato grosso, brasil
        gabriel.schuina@sou.ufmt.br vinícius carvalho pereira instituto de linguagens universidade federal de mato grosso cuiabá, mato
        grosso vinicius.pereira@ufmt.brrenan vinicius aranha media lab universidade federal de mato grosso cuiabá, mato grosso, brasil
        renan.aranha@ufmt.br abstract thedigitizationofartisticproductions,ortheircreationinanatively digital format, has expanded their
        scope beyond original intentions, bringing them into close interaction with software-related aspects. in this context, the
        dissemination, preservation, and access to such works, especially within digital museums and digital archives, are inevitably
        influenced by the quality of the underlying software. considering the inherent challenges at the intersection of digital
        humanitiesandcomputing,particularlytheneedforuser-centered andcustomizableexperiencestoeffectivelymanagelarge,heteroge-
        neouscollections,thisarticlepresentsasystematicliteraturereview focused on adaptive, personalized, and customizable digital muse-
        ums and archives. the review aims to identify the main purposes of these systems, the technologies employed in their construction
        and maintenance, and the interaction approaches proposed for users. using a systematic protocol, searches were conducted across
        acm digital library, ieee xplore, science direct, and scopus, result- ing in the analysis of 21 studies. based on the analysis of
        studies, we discuss trends, challenges, and opportunities for the design and development of adaptive digital museums and archives,
        such as the limited incorporation of human-computer interaction and software engineering principles and the need for greater
        standard- ization in the development of adaptive digital archives. keywords adaptive systems, digital museums, digital archives 1
        introduction digital transformation has brought diverse impacts across different sectors of society. in the field of the
        humanities, artistic production standsoutasoneofthedomainsaffectedbydigitaltechnologies.as evidence, it can be observed that,
        while efforts to preserve physical materials have intensified, ranging from manuscripts and paintings in: proceedings of the
        brazilian symposium on multimedia and the web (webme- dia’2025). rio de janeiro, brazil. porto alegre: brazilian computer society,
        2025. © 2025 sbc – brazilian computing society. issn 2966-2753to audiovisual records stored on videotapes, there has also been an
        increase in the production of digital-born content on platforms such as social media [5]. although these digital platforms
        facilitate the dissemination of arts, the ephemeral nature of online materials poses a potential risk to the preservation of
        cultural and artistic products. works published as posts on social networks such as instagram and x, for example, tend to be
        dispersed amid the large volume of new content continually posted [ 4]. furthermore, the discontinuation of certain platforms, as
        the social network orkut, can lead to the permanent loss of digital materials. preservation is also threatened when artistic works
        rely on specific technologies that become ob- solete, as occurred with creations developed in flash, which ceased to be supported
        by major web browsers at the end of 2020 [36]. without proper care for the preservation and cataloging of these digital works,
        they are subject to disappearance, technological ob- solescence, or even simple dispersal across the web [ 24]. the de-
        terioration process, although generally not caused by humidity, temperature, or light – as is the case with physical works – also
        appliesto digital creations,since theyaresubjectto data corruption and loss, as well as technological lag or discontinuation of
        propri- etary technologies. therefore, far from being a topic of exclusive interest to the digital humanities, the preservation of
        digital art is also an inherent subject of computer science. in this challenging context, the creation of digital archives rep-
        resents an effective conservation strategy for these works and has becomeanincreasinglyfrequentendeavorinthefieldofdigitalhu-
        manities [ 15]. these platforms, which combine archival, museologi- cal, and sometimes even educational purposes, may help
        overcome both geographical distances and certain socioeconomic barriers to accessing archived cultural products. although they
        share some goals and purposes with traditional museums, these platforms do not necessarily replicate the experience of visiting a
        physical space, and may instead employ different interaction resources. in the preservation of digital-born or digitized works,
        several projects have sought to provide solutions for the field. one such example is tainacan, a free software platform aimed at
        building collaborative digital archives [ 32], developed by the university of699 webmedia’2025, rio de janeiro,brazil oliveiraet
        al. brasília, with support from the federal university of goiás, the brazilian institute of information in science and technology,
        and the brazilian institute of museums. digital archives developed us-
        ingtainacangenerallypresentworkstovisitorsthroughtraditional web pages, as in the museu da casa de benjamin constant1. how-
        ever,thisisnottheonlyapproachadoptedbysuchplatforms.other initiatives, such as the museu do ipiranga virtual2and the museum of
        life3maintained by fiocruz, use virtual reality (vr) to cre- ate immersive experiences with digitally preserved works or even
        environments. giventheinterdisciplinarynatureofthetopicanditsfoundation in digital technologies, it is essential to examine key
        aspects from fields such as human-computer interaction (hci), multimedia and software engineering (se) in digital archives or
        museums. in the field of hci, there is room not only for improving the resources employed, but also for customizing and evaluating
        these tools from the users’ perspective, in order to offer a better user experience while interacting with the digital archive or
        museum. this includes analyzing how the modes of interaction with these platforms, such as through web pages or vr environments,
        can influence user inter- est, exploration of the archive, and overall experience quality. with regard to se, it is necessary to
        observe the development of tech- niques that ensure the efficient implementation of digital archives, with particular attention to
        the evolution of both the archives and the digital-born works over time. given the interdisciplinary nature of digital archives
        and the fragmented treatment they often receive across the digital hu- manities and computer science, this systematic literature
        review examines 21 studies to identify the primary purposes of such plat- forms, the technological strategies employed in their
        development, and the interaction modalities made available to users. by articulat- ing perspectives from both fields, the study
        contributes to a deeper understandingofcurrentpracticeswhilealsorevealingcriticalgaps, such as the limited incorporation of
        human-computer interaction and software engineering principles, the lack of standardization in development methodologies, and the
        insufficient attention to accessibility and long-term software evolution. 2 fundamental concepts given the interdisciplinary
        nature of this work, involving both the humanities and computer science, we present in this section some fundamental definitions
        for the discussions addressed in this study. 2.1 digital archives in this work, we use the term “archives” to refer to
        institutions that collect, systematize, preserve, and present cultural products to the
        public.withinthisscope,differenttypesofinstitutionsareincluded, suchas museums, archives,and libraries. theirfunctions may differ
        for specialists, but for the general public (and for the purposes of this study) they can all be understood as memory
        institutions. digital archives can be broadly defined as organized collections
        ofculturalproductsthatareeitheroriginallydigital(suchasebooks
        1https://museucasabenjaminconstant.acervos.museus.gov.br/pagina-acervo- museologico/ 2https://museudoipirangavirtual.com.br/
        3https://eravirtual.org/parque-da-ciencia/or images produced by generative algorithms) or digitized (such as images of books and
        photographs of oil paintings, among others). according to owens and padilla [33], a digitized collection may be a copy of a
        partial or complete collection of a physical archive, as in the case of the bnbdigital4, or thecentrodigitaldedocumen-
        taçãoepesquisamemóriasdosuldabahia5. both in digitized and digital archives, each collected item is described by metadata and, in
        general, the collections are accessed by the public through an online interface. the importance of digital archives for the
        construction of a memory of our present time is directly proportional to the chal- lenges they face. in addition to issues of
        funding, infrastructure, and archival methodology, which also affect physical collections, digital archives face issues such as
        technological obsolescence [ 42], archival instability, and the potential for infinite data accumulation [21]. 2.2 digital culture
        digital culture can be defined as the set of cultural practices that emerge from contexts in which interactions between two or
        more humans, between humans and the world, and between humans and their ideas are mediated by computational technologies. in his
        anal- ysis of the language of new media, [ 31] defines five characteristics of this language, which can also define the structural
        elements of digital culture: numerical representation, modularity, automation, variability, and cultural transcoding. other
        proposals for the semiotic characterization of digital cul- ture, such as that of [ 13], highlight features such as digitality,
        mo- bility, impermanence, disruption, connectivity, editability, combi- natorics, duplicability, exponentiality, and virtuality,
        among others. describing how we relate to information and communication tech- nologies (ict), these features are hallmarks of a
        culture in which data is transformed into information and gains prominence in eco- nomic, political, and social processes, in a
        dynamic that castells [11]called informationalism. generating data that multiply and circulate in accelerated global flows, the
        complexification of digital culture requires a complexification and evolution of digital archives as memory devices for the
        growing mass of data. 2.3 folksonomy folksonomy is a term that blends the words “folk” and “taxonomy” to describe the process of
        collaboratively tagging content. in this process, users evaluate the content and define tags that represent it, creating a form of
        categorization that evolves organically [ 43]. this can be done in two ways: if the tags are stored only once, we have a narrow
        folksonomy; however, if each new instance of the tag is recorded,itisconsideredabroadfolksonomy.inthelatterapproach, it is
        possible to conduct an in-depth analysis of the number of tags and the exposed content, ensuring greater fidelity to the tag [
        37]. by reflecting the way users organize and categorize information on the internet, folksonomy is deeply related to digital
        culture and digital archives. 4http://bnbdigital.cultura.df.gov.br/ 5https://memoriasulbahia.com.br/700 whenart meets computer
        science: a sr about technologies and user interaction in adaptivedigital museums and archives webmedia’2025, rio de janeiro,brazil
        3 state of the art due to its interdisciplinary nature, research involving the creation of digital works, museums, or archives may
        present different per- spectives on the artifacts produced and their use. thus, this section
        discussesworksthatrepresentthestateoftheartindigitalarchives from the perspective of each area. 3.1 digital humanities from the
        perspective of digital humanities, publications usually discuss aspects related to the definition of digital archives and their
        main characteristics. “anarchive”, for example, is a term used by rocha[41]torecognizetheinstability,ephemerality,andvariability
        of digital media, which define the characteristics of digital works. with the advancement of digital technologies, it is
        increasingly common for works to exist exclusively in digital archives. a central issue, therefore, is to find an effective means
        of preserving these works while respecting their unique characteristics. other studies discuss the effective preservation of
        digital works, whichrequiresnotonlyprotectingthemfromobsolescencebutalso maintaining their unique characteristics, including their
        ephemer- ality and technological dependence. rocha [41]argues that the intrinsic obsolescence of digital works also needs to be
        preserved. this ephemeral existence demands the preservation not only of the works themselves but also of their interaction with
        the reader. gobira and corrêa [20]describe the creation and development of the po.ex digital archive, focusing on the preservation
        of digi- tal poems. their preservation efforts ensured that the interactive features of the works were maintained. since these
        works were created through programming, they required servers for distribu- tion. to address this issue, the works were
        reimplemented on the platform’s own servers. alternatively, the implementation could be made available on multiple platforms,
        reinforcing the idea that dissemination itself is a form of preservation. while the po.ex digital archive focuses on preserving
        the in- teractivity of the works, pereira [36]discuss the decentralization of
        digitalpreservationandthevalorizationofworksfrommatogrosso, whilecataloginganddisseminatingregionalliteraryproductions.in the
        digital literature collection of mato grosso, works published on websites or social media platforms (instagram, wattpad, twit-
        ter, facebook, etc.) by artists born or residing in the state of mato grosso, brazil, are showcased. this collection serves as a
        refuge space for lesser-known works and proposes a means for the dissem- ination and conservation of regional works in a tool
        conceived in brazil: the open-source wordpress plugin tainacan. thus, accord- ing to pereira [36], the project fosters the
        independence of research and literary production delinked from eurocentric technological and aesthetic standards. 3.2 computer
        science from the perspective of computer science, many studies focus on the development of methodologies and technical guidelines
        aimed at digital preservation. in this line, formenton and gracioso [18] propose guidelines for the preservation of digital works,
        consider- ing the ephemerality of dissemination and storage media, for both digital-born and digitized works. their work outlines
        challenges of managerial, technical, legal, political, economic, and social nature.ahmad and rafiq [1]highlight that many
        organizations already have or are trying to develop digital preservation policies. how- ever, they argue that the development of
        such policies is generally considered an intrinsic responsibility of organizations, rather than an outsourced or globalized task.
        aspects related to hci, in turn, have been less explored in the context of digital museums and archives. tong et al . [47]propose
        visual interface design strategies for digital museums of intangible heritage based on user experience principles, focusing on
        color, typography, and layout, but without conducting user evaluations. similarly, lee et al . [28]analyze the google art &
        culture plat- form through the lens of remediation theory, identifying interface elements that foster both information delivery
        and user engage- ment.theirstudyprovidesconceptualinsights,butdoesnotinclude empirical testing with users. on the other hand, a
        broader and com- plementary perspective is provided by drivas and vraimaki [17], who evaluate 234 museum websites based on
        accessibility, usability, seo, and speed. the authors emphasized the relevance of user- centered metrics and highlighted
        disparities in user experience between mobile and desktop platforms. the proposed framework promotes inclusive design and supports
        non-technical staff in im- proving digital interfaces, reinforcing key hci principles such as usability, accessibility, and
        equity. 3.3 contributions of this paper thescientificliteraturepresentsreviewsdiscussingtheuseofdigital technologies, such as
        artificial intelligence (ai) and vr, within the scope of exhibitions, archives, and museums. for instance, [ 51] and [22] focus on
        visitor behavior and user experience with immersive technologies such as vr and augmented reality (ar) in museum contexts. their
        analyses, however, are predominantly limited to physical or hybrid exhibitions. li et al . [29]offers a comprehensive
        overviewofdigitaltransformationtechnologies(dtts),including ai, internet of things (iot), robotics, and 3d printing, but does not
        examine how these technologies relate to the communicative or functional objectives of digital collections. complementarily,
        studies such as [ 52] and [16] are more aligned with institutional and preservation-oriented concerns and do not explore user
        interaction in depth. pavlović [34]in contrast, dis- cusses digital tools for learning in museums but remains grounded in
        pedagogical theory without analyzing digital archives as plat- forms for broader cultural participation. however, these reviews
        consider the role of such technologies as part of an experience that is predominantly analog and often guided by professionals or
        instructions within the physical environment. with this literature review, we aim to investigate the technological decisions and
        in- teraction approaches that have been adopted in exclusively digital collections and museums with adaptation, personalization or
        cus- tomization. this investigation is important because, in such cases, the user’s entire interaction with artistic productions
        is mediated by interfaces, which may influence their experience, interest and appreciation of these works. 4 methodology in order
        to identify the characteristics, user interaction methods, and digital technologies used in digital museums and archives with701
        webmedia’2025, rio de janeiro,brazil oliveiraet al. adaptation, we conducted a systematic literature review (slr). this review was
        organized into three main stages, as presented in [26]:planning ,conducting , andreporting . the first stage ( planning ) involves
        defining the scope and the review protocol. the protocol adopted was picoc, which is detailed in table 1. through this protocol,
        the area and object of study were defined ( population , intervention ,comparison ), along with the expected objectives ( out-
        come)andthegroupsaffectedbythisreview( context).ourresearch questions (rqs) are the following: •rq1:for what purpose are digital
        archives developed? •rq2:what computational technologies can be observed in digital archives? how do these characteristics relate
        to the purpose of the archives? •rq3:how do users of digital archives interact with the platform and the works available there?
        our first research question (rq1) aims to explore the purpose of digital archives. while many of them were developed to digitalize
        physical museums, other digital archives were created aiming to enhance the availability of artworks. considering that the purpose
        of a digital archive can influence the interaction aspects and the technologies adopted, we addressed this topic in this review.
        then, in the second research question (rq2), we observed the technolo- gies adopted in each digital archived related in the
        papers, aiming to identify if there is any association between technologies and archives’ purposes. aspects related to users’
        interaction were dis- cussed in our third research question (rq3), aiming to identify challenges, limitations and opportunities
        for this context. in the second stage ( conducting ), some control articles were selected through a non-systematic search in the
        scielo and capes journal portal databases, aiming to identify relevant articles that could serve as a basis for the selection of
        keywords. the resulting search string, derived from these keywords, was: titlemustcontain: (personaliz* or adapt* or customiz* or
        user-center*); metadata must contain: (“digital archive” or “digital collection” or “digital
        museum”or“virtualmuseum”or“culturalheritage”or“digitalart gallery”) . the string was applied to four academic databases: acm
        digital library, ieee xplore, science direct, and scopus. to ensure robust and comprehensive coverage of the study’s
        interdisciplinary focus, the selection targeted databases prominent in computer science (e.g., hci and software engineering) and
        broader research fields(e.g.,digitalhumanitiesandculturalheritage).table2shows all versions of the strings. the search string was
        meticulously crafted to maximize the re- trieval of interdisciplinary works, combining terms for adaptation (e.g., adapt*,
        personaliz*) with context keywords (e.g., ”digital mu- seum”, ”cultural heritage”) to ensure all selected studies remained highly
        relevant to the review’s core focus. after the initial data col- lection using the search strings, the database filters were
        deemed insufficiently precise. to ensure the proper selection of articles, a python script was developed to automatically verify
        the presence of the correct keywords in the metadata and titles, as specified in the search strings. in order for articles to be
        selected within the scope defined by the review protocol, the inclusion and exclusion criteria were established and listed below:
        i1:the study addresses the development, maintenance, or use of a digital collection or digital museum.i2:the study describes
        technical aspects (interaction methods, technologies used) that support the understanding of com- putational elements.
        i3:thestudypresentsasolutionfocusedonabroadercollection, rather than on a single (art)work. e1:the study does not discuss the
        development, maintenance, or use of a digital collection/museum. e2:the study does not describe technical aspects (interaction
        methods, technology used) that enable understanding of computational aspects. e3:the study presents a solution related to a
        specific (art)work, without addressing a broader collection. astudyisconsideredeligiblewhennoneoftheexclusioncriteria apply.
        additionally, no restriction was placed on the publication date of the articles. subsequently, data extraction was divided into
        two stages: partial and full; and performed by two people. initially, titles and abstracts of all papers retrieved from the
        databases were read. only the articles that met the inclusion criteria were read in full, for detailed information extraction and
        the extraction was performed by using a structured form briefly described in table 3.
        also,whetherornotthestudyincludedauserevaluationwastaken into account during the extraction. this aspect was considered rel- evant
        for identifying works that go beyond technical or theoretical descriptionsandprovideevidenceofpracticalapplicationsanduser
        experience. at the end of the selection process, 21 articles were accepted. the selection process is shown in figure 1, while
        table 4 presents the data collected from the articles selected during this phase. 5 results and discussion in this section, we
        present the results obtained in our investigation, based on the data synthesized in table 4. next, we answer the previously
        formulated research questions and perform a critical analysis of the evidence found, highlighting the contributions and
        limitations. 5.1 purpose of digital archives the analysis of the selected articles reveals that the digital archives addressed in
        these studies are applied in different contexts, also involving different purposes in their conception. in this sense, to support
        the discussion of rq1, we chose to divide the purposes of the archives into three strands: i) dissemination , related to im-
        proving visitation; ii) preservation , aimed at the maintenance and care of digital works over time; iii) availability , related
        to the facil- itation of access to digital works. these categories are not mutually
        exclusive;therefore,anarchivedescribedinacertainstudymayfall into more than one category, highlighting the multifunctionality of
        digital archives. 5.1.1 dissemination. dissemination, which involves the concern with providing a more meaningful experience of
        exploring the worksinthearchives,isthemostrecurringpurpose,beingobserved in 57.14% of the studies. a significant point raised in
        the works with this purpose is the need to condense the content presented to the user [ 3,30,38,43], which include, among others,
        examples that employ recommender systems for this purpose. this stems from702 whenart meets computer science: a sr about
        technologies and user interaction in adaptivedigital museums and archives webmedia’2025, rio de janeiro,brazil table 1:
        descriptive table of picoc protocol elements. picoc protocol population studies that describe the development, evaluation, or
        analysis of digital archives and their impacts. intervention “innovative” approaches to exploring digital archives. comparison
        digital archives with traditional interaction approaches, such as static web pages. outcome experience with the works, user
        experience, interest in exploring the digital archive. context academic papers published in conferences or journals, as well as
        applications made publicly available. records identified through database searching (n = 431)additional records identified through
        other sources (n = 0) records after duplicates removed (n = 360) records screened (n = 360) records excluded (n = 317) full-text
        articles assessed for eligibility (n = 43)full-text articles excluded, with reasons (n = 11) - not relevant (n = 2) - not
        open/available paper (n = 9) studies included in qual- itative synthesis (n = 21) studies included in quantita- tive synthesis
        (meta-analysis)identification screening eligibility included figure 1: prisma flow diagram illustrating the identification,
        screening, eligibility,and inclusion of studies accordingto the defined criteria. the fact that many archives have large databases
        of works and a heterogeneous audience. thus, the task of presenting appropriate content for a certain user becomes much more
        complex in this situation. bonis et al . [9]mention that, due to the large volume of
        dataintheseplatforms,thereisaneedforcontentrecommendation to enable user interaction with these extensive data sets. according to
        this study, a common strategy is to subdivide large data sets, therebygeneratingsubsets.fromthesesubsets,contentsuggestions
        aregeneratedforusers.tothisend,theauthorsimplementsemantic graphs to better organize the works. since archives also play an active
        role in mediating knowledge, those designed with this purpose often adopt various strategies to encourage user interaction and the
        discovery of new cultural products, making the experience more immersive and engaging. our review found works involving catalog
        personalization accord- ing to user characteristics ([ 3,38]), encouragement of users’ active participation in exploring the
        collections ([ 39]), and the creation of more intuitive environments ([19]). geng yang [19]evaluated what design characteristics
        are most important to users of these tools. a form was used to collect data on which factors influence user comprehension while
        navigating the page of a digital archive. in the case of [ 53], implementation efficiency was evaluated through experimental
        testing. the authorsdeveloped an automatic path search algorithm and applied it to a digital collection. then, they incorporated
        the obstacle avoidance technique and compared the performance before and after the im- plementation. the result revealed
        improvements not only in more natural movement but also in processing performance and use of memory space. another approach
        adopted by researchers involved improving how additional information about the works is communicated to users. studies such as [
        2,14] investigate more natural means of communication between the user and the collection, promoting greater familiarity and,
        consequently, better learning. to evaluate communication, [ 14] led an experiment in which, after interacting with the tool, the
        users responded to a survey assessing mixed reality experiences, as proposed in [ 50]. the results of this study will be discussed
        in more detail in section 5.3.2. also from a social perspective, [ 9] developed a method to create communities with similar
        interests, thus increasing engagement and encouraging col- laborative exploration of digital archives. once the user modeling is
        established, it was possible to compare different users, and thus create groups with similar interests. personalized rooms were
        cre- ated and assigned to users with similar preferences, so that users could meet and communicate.703 webmedia’2025, rio de
        janeiro,brazil oliveiraet al. table 2: database search strings. database search string acm digital library [[title: personaliz*]
        or [title: adapt*] or [title: cus- tomiz*] or [title: user-center*]] and [[all: ”digital archive”] or [all: ”digital collection”]
        or [all: ”digital museum”] or [all: ”virtual museum”] or [all: ”cultural heritage”] or [all: ”digital art gallery”]] sciencedirect
        title, abstract, keywords: ”digital archive” or ”digital collection” or ”digital museum” or ”virtual museum” or ”cultural
        heritage” or ”digital art gallery” title: per- sonalizationorpersonalizedoradaptationoradaptive or customization or customized or
        user-centered scopus title ( personaliz* or adapt* or customiz* or user- center* ) and title ( ”digital archive” or ”digital col-
        lection” or ”digital museum” or ”virtual museum” or ”cultural heritage” or ”digital art gallery” ) ieee xplore (”document
        title”:personaliz* or ”document ti- tle”:adapt* or ”document title”:customiz* or ”doc- ument title”:user-center*) and (”all
        metadata”:”digital archive” or ”all metadata”:”digital collection” or ”all metadata”:”digital museum” or ”all metadata”:”virtual
        museum” or ”all metadata”:”cultural heritage” or ”all metadata”:”digital art gallery”) note:each string was adapted to each
        platform’s search syntax. table 3: summary of key categories extracted from the ana- lyzed articles. question main answers purpose
        of the archive availability, dissemination, preservation interaction techniques and their improvementrecommendation systems,
        personalized 3d environment generation, software quality (a, folksonomy, chatbot, realistic environments, data organization
        interaction resources virtual reality, traditional page, voice, mixed reality, social network creation tools unity, python,
        javascript, xml, wordpress media formats of the artwork images, text, 3d models, audio, video user evaluation? yes, no, not
        informed reported challenges lack of funding, technical problems, user education, hardware limitations, interdisciplinary
        integration 5.1.2 preservation. the preservation of works, whether digitized or digital-born, is a central motivation for the
        development of sev- eral digital archives. however, within the scope of this review, few articles have focused on preservation;
        instead, this concern arose secondarily. for this reason, only 9.52% of the articles fall into this category. in [ 10], the goal
        of conserving digital cultural products [44] in digital archives is explicit. the researchers aimed at creating a digital
        collection of indonesian customs, arts, and traditions to ensure these are not lost over time. the “e-dayaknese” framework
        developed by the authors allows for the creation of entirely new cultural products or the association of new items with existing
        ones. it leverages a semantic structure based on the relationships between items, which facilitates the discovery of related
        content. in the proposed architecture, the digital organization of cultural data improves the consultation time and registration
        of new items. in addition to that, one of its modules is responsible for collecting usertable 4: articles included in this
        systematic review. # citation year rq1 rq2 rq3 1 [7] 2007 dis rs, peg vr 2 [9] 2009 dis rs, peg vr 3 [35] 2009 dis sq tp 4 [19]
        2009 ava sq tp 5 [30] 2009 dis rs, folk tp 6 [12] 2010 ava do tp, vr 7 [2] 2010 dis chat tp 8 [43] 2012 dis rs, folk tp 9 [3] 2013
        dis peg vr 10 [27] 2018 dis peg vr 11 [38] 2019 dis rs, peg vr 12 [39] 2019 dis rs, eye tp 13 [10] 2019 pre rs tp 14 [6] 2019 dis
        sq tp 15 [48] 2022 pre rs tp, vr 16 [49] 2023 dis rs, peg vr 17 [53] 2023 dis re vr 18 [23] 2023 dis re, eye, chat vr, voi 19 [45]
        2023 dis rs, sq tp 20 [25] 2024 ava peg vr 21 [14] 2024 dis chat mr, voi caption: ava: availability, dis: dissemination, pre:
        preservation, rs: recommendation systems, peg: personalized 3d environment generation, folk: folksonomy, chat: chatbot, eye:
        eye-tracking, re: realistic environments, sq: software quality analysis, do: data organization, vr: virtual reality, tp:
        traditional page, mr: mixed reality, voi: voice interaction. information, enabling personalized recommendations. the informa- tion
        is collected following the proposed 5r adaptation framework. the acronym 5r stands for right timing, right location, right device,
        right learner, and right contents, meaning that the rec- ommendation is made based on the user’s context. in the validation
        process, a functional prototype of the proposed framework was implemented, but user surveys, scalability tests, or discussions on
        software evolution were not conducted. inturn,[ 45]presentsatoolthatstoresdigitalanddigitizedsculp- tures from artists
        representing various cultures around the world. the tool uses fuzzy logic-based resources to improve recommen- dations by taking
        into account user profiles and the experience of accessing cultural heritage. the architecture created for sculpt- mate contains
        three layers: the userinterfacelayer , which allows button configuration and 3d model visualization; the application logic layer ,
        which includes the implementation of content man- agement and personalization with fuzzy logic; and finally, the data storage
        layer , which stores user information and structures. the article mentions that the focus during development was on usabil- ity,
        adaptability, and performance, allowing for future evolution of the framework due to its modular implementation. the main im-
        provements discussed in the article are the implementation of more sophisticatedmachinelearningalgorithmsandtechniquesformore
        accurate recommendations. the paper also proposes the migration from local storage to a cloud server, with integration with apis
        to access external resources and models. furthermore, the authors discuss the possibility of implementing social functionalities,
        such as sharing preferences among users, promoting a more connected community. 5.1.3 availability. another purpose of digital
        archives is to make content available to the public, facilitating access to digital cultural products, as discussed in 33% of the
        analyzed studies. some studies704 whenart meets computer science: a sr about technologies and user interaction in adaptivedigital
        museums and archives webmedia’2025, rio de janeiro,brazil present models that address the heterogeneity of digital resources,
        proposing strategies for making content available in a way that improves user experience , whether by developing user-centered and
        enjoyable interfaces [ 19], or by implementing recommendation systems to guide access [ 12,53]. these approaches aim to make
        access to heritage more inclusive, adapted to individual needs and, at the same time, increase interactivity and visitor
        engagement, providingaricherandmorepersonalizedexperience.budimanetal . [10]and strousopoulos et al . [45]state that, in addition
        to acting as preservation tools, collections play a crucial role in democratizing access to the heritage of socioethnic entities
        with limited visibility on the global stage. these tools not only ensure digital preservation but also expand access to the
        represented cultures. similarly, bollini [6]proposes the centralization of information on cultural heritage, aiming to make
        content available both to na- tives and to the non-specialized public in the milan region. that strategy is intended to preserve
        the relationships between docu- ments during the process of organizing and digitizing the works. this model aims to broaden access
        to cultural resources, promoting greater understanding among diverse audiences and encouraging engagement with local history. in
        the evaluation process, a survey was conducted with 24 participants, and the data were analyzed according to norman’s guidelines.
        based on the findings, a second design cycle was launched to implement the necessary improve- ments. the collection was evaluated
        within the field of hci, aiming toverifyusabilityanduser-centereddesign.however,noeffortwas
        madetoanalyzethecollection’spotentialforpopularization;thatis, metrics of reach or social impact were not taken into
        consideration. 5.2 techniques and technologies digital archives and museums are driven by a variety of technolo- gies aimed at
        providing immersive and personalized experiences for users. this section discusses the main technological approaches
        andtheirrelationtothearchivepurposesidentifiedintheliterature, seeking to answer the research question rq2. 5.2.1 virtual
        environments. in digital museum studies, virtual en- vironments can take on various forms and characteristics. in this article,
        virtual environments are considered as 3d interfaces, which may or may not resemble the physical spaces of real museums, allowing
        users to navigate, interact with, and explore exhibitions. this type of system often uses 3d modeling and supports specific
        equipment, such as vr headsets. svanaes [46]argues that the meaning of something is generated from the physical interactions we
        establish with the environment. thus, perception and interaction are directly linked to how we see an artifact and what it
        represents – not statically, but dynamically and generated at the moment of interaction. vr provides the envi- ronment through
        which the user can interact and, consequently, create new meanings and perceptions of the surrounding objects. therefore, it has
        become one of the most common resources in digital museums, providing immersive experiences that allow users to explore
        exhibitions intuitively. 3d virtual environments have been widely adopted in studies focusing on adaptive enhancements to
        conventional museums. for example, komianos and oikonomou [27], rajaonarivo et al . [38], bonis et al . [9], yang et al . [49],
        zhao[53],andkimetal .[25]presentsolutionsthatadapttheuserexperi- ence to the context of traditional museums through
        personalization and interaction enhancements within 3d virtual environments. these studies represent approximately 28% of the
        publications in our slr. these studies focus on different characteristics of virtual envi- ronments.forexample,in[
        49]thedevelopmentoftheenvironment reflects a concern with realism in the rendering of 3d models. the article describes the steps
        used for gamma correction, color, and tone adjustments of images to create a more realistic and therefore more immersive
        environment. zhao [53]also address this concern bydiscussingthefollowingmodelingmethods:geometricmodeling, based on mathematical
        models and computer graphics; and image- based modeling, using real image capture. while the former offers many details in the 3d
        model, it is computationally expensive for complex environments such as a digital museum. the latter offers many visual details
        but has limitations regarding the interactivity of the 3d model. therefore, the authors propose a hybrid modeling approach,
        leveraging the interactivity of the first method and the realism of the second. in addition to the visual realism of 3d models in
        the virtual envi- ronment,zhao [53]alsodiscussesmorenaturalformsofnavigation. for example, algorithms are developed, to ensure
        that movement occurs naturally, smoothly avoiding objects rather than passing through them. other works discuss the effective
        arrangement of artworks within the space, considering artistic categories [ 9], user preferences [ 38], and immersion time within
        the virtual environ- ment [27]. 5.2.2 traditional interfaces. while several adaptive works high- light a preference for 3d virtual
        environments, in which the user is directly immersed in the exhibition context, studies such as [ 2]
        proposeanalternativeapproach.inthisstudy,artworksarebrought closer to the user through simplified interfaces focused on prior-
        itizing direct interaction with displayed items, without the need for full immersion in a virtual environment. in this case, the
        user interacts directly with the model of the artwork and does not navi- gate through a virtual environment. this interaction is
        performed through traditional visual commands, by clicking buttons on the archive’s interface. studies such as [ 12] and [6] also
        favor the use of traditional web pages due to the diversity of resources available to users. this approach is common in contexts
        where resource heterogeneity de- mands a more conventional interface, focused on user-centered curation. on the other hand,
        studies aiming to enhance the user experience through interface adaptations, such as [ 35] and [19], opt for simplified and
        conventional traditional pages. this is be- cause the inclusion of external elements, such as excessive menus,
        disconnectedfunctionalities,orredundantinformation,wouldcom- promise the immersiveness of the archive. in a context where
        immersion is not a priority, several studies are dedicated to gathering and adapting artworks based on cultural and ethnic
        characteristics, without the intention of replicating a real-world exhibition in a virtual environment. examples can be found in
        studies such as [ 10,30,43,48], which adopt traditional page structures. these works focus on curating and organizing artworks
        based on cultural and ethnic categories.705 webmedia’2025, rio de janeiro,brazil oliveiraet al. 5.2.3 recommendationalgorithms.
        the literature highlights the growing adoption of recommendation algorithms in different types of digital archives, both in 3d
        virtual environments and traditional pages,aimingtoenhancethepersonalizationoftheuserexperience. in 3d environments,
        recommendation involves various tech- niques. javdani rikhtehgar et al . [23]and raptis et al . [39]use eye-tracking to assist in
        analyzing user behavior and enable sug- gestions based on their points of interest. for instance, in [ 23], users’ eye movements
        were tracked to determine which elements within paintings most attracted their attention (buildings, faces, and details). this
        information was used to make personalized rec- ommendations. the study also reveals that gaze duration can serve as an indicator
        of user preference, but this correlation comes with certain limitations. user surveys showed that the display order of artworks,
        how detailed the artwork is, or whether it has a more or less interesting description also impact gaze duration, but they do not
        necessarily define a user profile. in contrast, folksonomy-based approaches, as seen in [ 43] and [30], involve organizing content
        through collaboratively defined categories, and traditional pages provide users with a familiar inter- face to perform this task.
        in [ 30], users rated paintings (from 1 to 5) and added tags they deemed appropriate. the interface provided access to the
        painting image, title, description, and other popular tagscreatedbyusers.adatacollectionprocesswascarriedoutwith 40 individuals
        (30 general users and 10 experts) to gather tags for training a multivariable poisson model. tags were classified as (i)
        personaltags,providedbyaspecificuserforaspecificartwork;and (ii) socialtags, assigned to the artwork by various users. the results
        showed a general improvement in filtering accuracy with tags cre- ated by users. based on this, the authors proposed a hybrid
        system that incorporates folksonomy into content-based recommendation. to evaluate this framework, k-fold cross-validation and
        metrics suchasprecisionandrecallwereused,tiedtodifferentexperimental combinations (permutations between static content implementa-
        tion, personal tags, and social tags). the inclusion of socialtags produced lower results than personaltags, and combining static
        information (artwork descriptions) with personaltags achieved the highest filtering precision. the main results of this study show
        that personal preferences are more relevant than general consensus when making recommendations. moreover, models that adapt to
        user preferences are present in both immersive environments and traditional pages. examples include the use of machine learning
        for personalization, as in [ 49] and [25], as well as genetic algorithms and fuzzy logic for more accurate recommendations, as
        previously addressed in [45]. the dynamic generation of 3d virtual spaces can also be tailored to user characteristics and the
        curated selection of artworks to be displayed. in [ 8,9,38], semantic graphs grouped artworks for users, optimizing the
        recommendation process. in [ 53], recommendations are generated based on user profile, which includes demographic attributes
        collected to associate new cases with similar past ones, using the case-based reasoning technique. recommendations are generated
        in a ranked list of the best visitation routes. likewise, in [49] demographic data (age, profession, gender, education level) are
        collected to serve as input for a deep learning model that can infer user preferences.in addition to these approaches, other
        methods also deserve mention, such as calculating the proximity between clusters of artworks and users, as described in [ 25]. in
        this case, artworks are divided into thematic clusters, based on similarity in color, material, description, artist, and creation
        date. once the groups are defined, distances between them are calculated, representing how different
        theyarefromoneanother.thisinformationisthenusedtogenerate more coherent thematic exhibitions. 5.2.4 chatbots. [2,14,23] implement
        chatbots and voice inter- action to improve communication between users and the archive systems. those systems are complementary
        to the standard ways of interaction, like mouse and keyboard, and so not mandatory to the user. in [ 2], speech recognition is
        limited by the grammar that the system can recognize, which restricts interaction with the user. in this type of approach,
        questions outside the system’s predefined pattern are not understood, which could frustrate users. through this system, users can
        obtain specific information about artworks and also use specific voice commands for navigation. voice-guided navigation adds an
        accessibility layer to the software, enabling use by people with motor or visual impairments, in addition to offering a different
        form of interaction for users to acquire knowledge of the artworks. nonetheless, this feature should be regarded as a
        complementary interaction method, as reliance on voice guidance alone may pose accessibility barriers for deaf users. 5.3
        interaction features interactionfeaturesplayafundamentalroleinuserengagementand satisfaction. from this perspective, the studies
        revealed different forms of interactivity with digital archives, which will be presented in the following topics, allowing us to
        address rq3. 5.3.1 interactioninvirtualandaugmentedrealityenvironments. vr is one of the technologies that enables the creation of
        3d virtual environments, where interaction can be either immersive (through
        theuseofvrheadsetsorhapticgloves)ornon-immersive(typically via conventional screens). in [ 9], vr allows the development of a more
        immersive and realistic experience for the user, as it also enables more natural navigation. the construction of vr spaces
        involves several stages, such as the arrangement of objects in the environment, texturing, lighting, and, in some cases,
        animation. the works of [ 7,9,38,49,53] seek ways to facilitate the con- struction of vr environments and represent 25% of the
        articles we analyzed. in these studies, methods were developed to automate and simplify the creation of vr environments through
        algorithms capable of arranging the items across the available space, given a set of artworks – an otherwise time-consuming and
        repetitive manual task. in [ 27], this arrangement also aims to optimize the user’s time by ensuring that artworks are placed in
        appropriate locations with dynamically calculated spacing, minimizing unnec- essary time spent during exploration. likewise, [ 53]
        also develops an algorithm to find more natural paths that avoid obstacles in exhibitions, thereby improving the user’s navigation
        experience. in [53], interaction occurred in an intuitive and immersive man- ner, allowing users to explore the digital archive
        through different modalities. sensors captured movements, voice commands, and706 whenart meets computer science: a sr about
        technologies and user interaction in adaptivedigital museums and archives webmedia’2025, rio de janeiro,brazil gestures to enable
        fluid navigation through the virtual environ- ment, while an intelligent roaming system automatically adjusted the trajectory to
        avoid obstacles, making navigation faster. vari- ous media formats (text, image, animation, sound, and video) were also integrated
        into the systems to find more user-friendly ways to convey information. other articles, such as [ 53], [9], and [38], do not
        explicitly de- scribe how user interaction takes place – whether through mouse, keyboard, or any special equipment. in contrast, [
        49] details how interactionoccurs:thewasdkeysareusedtonavigatetheenviron- ment, the r key activates automatic navigation to a
        user-defined point, the mouse sets the viewing direction, and the right-click allows the user to rotate objects. strousopoulos et
        al . [45]describe an alternative to standard devices: headsets compatible with 3d vision, which provides greater immersion. an
        important point is that articles concerning archives using vr demonstrateaconcernwithnavigationthroughspace,emphasizing
        naturalness and user’s freedom. among the works analyzed, users were not suggested specific routes to follow; guidance occurred
        throughthemuseum’sconstructionbasedonartworkselectiondur- ing curation and automatic space creation. the only exception was [3],
        in which a route is suggested to the user and adapted not only to their preferences but also to their reactions while navigating
        the exhibition. it is worth noting that navigation is a key challenge in any vr environment, particularly immersive ones requiring
        head- sets, and not an issue exclusive to virtual archives, so that solutions and challenges in vr from other domains might apply
        to digital archives as well. surprisingly, the analyzed studies do not address motion sickness, a common concern in immersive vr
        experiences. although most works include some form of user evaluation, these are often limited to assessing curatorial aspects.
        they analyze, for example,thepositioninganddistributionofartworks,orthequality of the rendering and lighting, rather than comfort
        or discomfort during navigation. 5.3.2 voice interaction. from another perspective, in [ 2,14,23], representing 14% of the
        studies, voice resources permit a more per- sonalized and natural user interaction. with advancements in the development of llms
        (large language models), such as llama or gpt, text generation has become significantly more sophisticated and complex, allowing
        for advancements in voice system imple- mentation for digital archives, as done in [ 14]. in this project, an application was
        developed for microsoft hololens (1st generation) to present artworks to visitors, integrated with a system using the gpt-3.5
        model, which received the user’s audio recording and gen- erated the desired responses. in the application evaluation tests, a
        mixedrealityapproachwasused,displayingimagesoftheartworks to users through the headset. the results of the study indicated that
        this technology has the potential to captivate users. two metrics showed lower performance in the empirical test: immersion and
        re- sponse credibility. although the metrics and tests that indicated the model’s responses were accurate, users reported that
        they would not trust the information provided in awkward responses. further- more, they mentioned that the interaction with the
        conversational agent did not seem natural or realistic in the archive. 5.3.3 webpages. webpagesarewidelyusedtodayasasolutionfor
        digitalarchives.consideringthatoneofthegoalsofsuchcollectionsis to make archived material available, web pages offer broad com-
        patibilitywithcurrentdevices,easeofusethroughelementssuchas menusandhyperlinks,andhighscalabilityforlargeaudiences.this formof
        interaction wasemployed in [ 6,10,12,19,30,35,39,43,45], which represent 43% of the articles. some studies implemented
        traditional-format web pages with- out incorporating any unconventional interaction element. one noteworthy example is [ 19] which
        presents a study and heuristic analysis of the interfaces of three different digital museums, aiming to identify the design
        elements that are most important for creating effective interfaces of this kind. the factors deemed most impor- tant were the
        usermodel and theinterpreter . this emphasizes that the interface must have high usability and communicability, easily conveying
        its purpose and content to the user and responding sat- isfactorily to user interactions. aesthetics, although relevant, was not
        prioritized; the main aspects mentioned were typography (font size and family choice) and the alignment of page elements. in [6],
        a different form of user interaction is addressed. their framework features a map-based visualization that can be freely ex-
        ploredbytheuser.foreachpointonthemap,historicalinformation is provided by the various communities that lived there. 6 quantitative
        analysis figure 2 presents the temporal evolution of publications related to the adaptation of digital archives and museums. the
        graph shows that, despite a reduction in the number of publications in the years 2012, 2013, and 2018, the topic has been
        regaining prominence, indicating a renewed interest in the field. vr is the most widely adopted technology in the studies,
        followed by traditional web interfaces. other technologies, such as voice interaction and chat- bots, appeared in 2010 but only
        resurfaced in 2023, likely due to recent advancements in ai. the word cloud presented in figure 3 underscores the terms most
        frequently used in the analyzed studies, revealing a prominent interest in personalization, vr, and immer- sive experiences.
        complementing this discussion, figure 4, generated with the supportofthe bibliometrix andhighcharts tools,showsthenumber of
        publications by country. greece is the country with the highest number of publications, totaling 12 articles, followed by china,
        which appears in 7 publications. the results highlight the absence of publications from north or south american countries,
        revealing the need for broader discussions on interaction aspects in digital archives and museums. figure 5 emphasizes the
        relationship between the main interac- tion features employed in the papers analyzed and the purposes of the archives, categorized
        into three strands: dissemination, preser- vation, and availability. the strong interest in the use of vr stands out, as evidenced
        by its widespread adoption in 50% of the works included in the figure. one example is the study by [ 38], which proposes a model
        capable of generating a 3d virtual environment with the user’s works of interest. moreover, vr shows a similarly significant
        presence in archives aimed both at availability and dis- semination. a scarcity of works exploring other approaches, such as ar,
        is also noticeable, suggesting that technological barriers or the need for specific infrastructure may limit its application for
        navigation in digital archives. additionally, although the number707 webmedia’2025, rio de janeiro,brazil oliveiraet al. number of
        papers145 1 1 145 3 032 10 031 0 1 11 01 1 13 1 0 01 0 0 0 011 0 010 0 0 0 01traditional interfaces virtual reality chatbot voice
        interaction 2007 2009 2010 2012 2013 2018 2019 2023 20240246 figure2: trendsin the use of interaction features in works on digital
        archive adaptation. figure 3: word cloud with terms used in the studies. figure 4: publications by country. of studies
        implementing conversational agents and voice interac- tion is limited, these technologies appear to be more present instudies
        focused on archive availability, suggesting a possible rela- tionship between their adoption and the facilitation of access to
        digital cultural products. with regard to evaluation, 71% of the studies conducted experi- ments with users. notably, 100% of
        these works aimed at dissem- ination or availability, suggesting a significant focus on aspects of user interaction and access to
        archived materials. furthermore, there is a recurrence of studies seeking to empirically validate their proposals. user
        participation in this process is essential, as many of the developed solutions aim to meet individual preferences and interests,
        making the experience more engaging and personalized. in summary, by observing the focus on dissemination and avail- ability as
        purposes, the analyzed data reveal that digital archives and museums perform the role of active agents in the mediation of
        knowledge and collective memory in digital culture. the em- phasis on vr highlights the concern with user immersion in the virtual
        environment; however, the low application of ar indicates an opportunity to be explored. ultimately, empirical evaluations
        involving users are essential to validate the proposed approaches. oneoftherecurringissuesintherealmoftheartsconcernscopy- right.
        despite its relevance, only two studies explicitly address this matter in a significant way. in [ 45], the quality of 3d
        digitization of artworks is limited by the difficulty of accessing artifacts protected by copyright. in [ 12], copyright-related
        issues are discussed from a different perspective: the protection of digital artworks. one of the features proposed for the
        environment described in that study is the integration of a content management system equipped with security mechanisms capable of
        efficiently protecting various digi- tal artworks in their multiple multimedia formats (text, image, 3d model, among others). this
        type of technology is particularly im- portant in digital collections, which aim not only to provide access to content but also to
        ensure the preservation and respect of intel- lectual property rights. thus, tools designed to prevent the misuse of images,
        unauthorized copies, or non-consensual modifications contributenotonlytolegalcompliancebutalsototheconsolidation of digital
        preservation initiatives. 7 challenges and opportunities the analysis of research on digital archives reveals both persistent
        challenges and opportunities to enhance the interaction experience708 whenart meets computer science: a sr about technologies and
        user interaction in adaptivedigital museums and archives webmedia’2025, rio de janeiro,brazil 77 4444 44 2222 1133 voice
        interaction chatbots traditional interfaces virtual environments0 2 4 6 8 10 12 14 16 18dissemination availability preservation
        figure 5: interaction features by digital archive/museum purpose. within digital repositories. several studies have explored
        adapta- tionsandpersonalizationsbasedonuserprofiles,asseenin[ 43]and [23], and have proposed interactive features to improve
        navigation and content access. however, there is a noticeable lack of effec- tive applications of these approaches in natively
        digital archives. in many cases, the studies are limited to conceptual development models. for example, in [ 27], the evaluation
        is conducted using only a prototype, without implementing the results in an actual digital archive. this lack of a comprehensive
        evaluation constrains the findings to a non-realistic context. moreover, there is a clear scarcity of specific approaches in the
        construction and exploration of digital archives. for example, no implementations of 2d virtual environments were found. the main
        argument for implementing 3d virtual environments is that this interaction medium allegedly promotes greater immersion. how- ever,
        immersion is also present in 2d, albeit to a lesser degree. furthermore, hybrid adaptations that combine traditional pages with
        virtual environments tend to be more acceptable in the 2d model, as interaction is typically performed through devices that have
        become commonplace in users’ daily lives. additionally, the integration of conventional elements is also facilitated, given that
        2d interfaces are common to many other applications, making the platform more intuitive and familiar to users. it is also
        important to note that 3d virtual environment applica- tions are commonly used in the digitization of physical collections
        belonging to institutions whose buildings are, in themselves, works of art. this is the case for the louvre museum, the tate
        museum, or the museu da vida fiocruz, which are digital archives that preserve not only digitized works but also the physical
        architecture of the building that houses them. however, in the studies analyzed in this
        review,3dvirtualenvironmentsdidnotdemonstratethesamelevel of attention to architectural preservation, as they were focused on
        facilitating the generation of the virtual environments. althoughimmersiveandadaptivestrategies,asseenin[ 7,25,38], offer users
        greater immersion and more engaging visits, the use of specific devices, such as vr headsets, limits access to digital archives.
        as such, this should be an optional resource, as proposed in [45], where the use of headsets is not mandatory. also concerning the
        access to digital archives, it is evident that there is a shortage of implementations focused on the availability of works.
        javdani rikhtehgar et al . [23]and constantinides et al . [14]propose interaction methods that enhance the availability ofcontent
        to users; however, these are exceptions among the articles in our sample. the remaining studies do not address this issue,
        revealingaclearlimitationinthepotentialdisseminationandreach of digital archives. furthermore, most systems are still based on
        traditional web pages and do not implement innovative solutions. although this is not necessarily a problem, there is a clear lack
        of standardization and guidelines for developing digital archives. the studies by zhao [53], geng yang [19], and pedrero et al .
        [35]go in this direction; however, there is no clear organizational structure that provides consolidated guidelines for these
        implementations. another relevant aspect is the difficulty to integrate different areas of knowledge. works such as [ 10] clearly
        state that the cre- ation of digital archives is a multidisciplinary project, involving not only the cultural elements to be
        preserved, but also the tech- niques and guidelines for building robust software. studies in the field of computer science
        emphasize technological aspects in the development of archives, neglecting certain unique characteristics of digital works and
        interactions that arise from the digital world – elements that are, in turn, highlighted and analyzed in case studies from the
        humanities. a strong association between both fields is imperative for the development of the area and to meet the expecta- tions
        for digital archives from both technical system aspects (such as accessibility,usability,interactivity, etc.) and humanistic
        archival concerns (such as curation, storytelling, and representativeness of the collection, for example). additionally, the
        development and creation of digital archives are intrinsically linked to the preservation of the archived works, meaning that they
        must endure over time. in this regard, for the development of the software, its evolution in response to changes in technology and
        social dynamics must be considered. some al- ternatives to this problem have already been proposed and could be adapted and
        implemented, such as lehman’s laws. in [ 45], this ideaispresent;however,itwasexpectedtobemorewidelyadopted in the development of
        this type of platform. finally, it is important to highlight the development of plat- forms that support the preservation of
        collections with limited resources. preservation efforts should not be constrained by the broad availability of personnel,
        infrastructure, and financial re- sources – conditions typically found in well-established physical
        archives,orinstitutionssupportedbyexternalfunding.alternatives are explored in works such as [40], which proposes a paradigm of
        projects that incorporate minimal computing and, therefore, reduce709 webmedia’2025, rio de janeiro,brazil oliveiraet al.
        development costs. in parallel, there are also initiatives involving low-cost implementations that, for example, incorporate
        social me- diaortoolssuchastainacantoexpandaccessandthesustainability of digital preservation [36]. 8 final remarks in this study,
        a systematic review was conducted with the objec- tive of identifying the main technologies and forms of interaction employed in
        digital archives. from this analysis, it is evident that there is a lack of standardization in the field regarding guidelines and
        norms for the creation of such platforms. moreover, our results show that there is limited use of software engineering practices
        for software maintenance and preservation – essential aspects in the field of digital preservation studies. finally, most of the
        works did not demonstrate concern with evaluating software quality aspects, which reveals a significant gap as to human-computer
        interaction. as a scope limitation, this review included only projects that develop digital archives intended to host multiple
        works, excluding those focused on building technologies for individual exhibitions or
        singleartworks.relevantfutureworkcouldfocusoninitiativesthat aim to standardize the development processes of digital archives or,
        at the very least, the systematic documentation of such practices. 9 ethical considerations this work presents a systematic
        literature review, characterized as secondary research, since it does not involve direct interaction with participants nor the
        exposure of individuals to technologies or computational systems. therefore, according to cns resolution no. 510/2016 and cns
        resolution no. 674/2022, it is exempt from approval by the research ethics committee involving human sub-
        jects.thedatausedreferexclusivelytothemetadataoftheanalyzed articles, which are publicly available in the databases selected and
        described in section 4. acknowledgments thisstudywascarriedoutwiththesupportoffapematandcnpq, through the granting of research
        scholarships. the english version of this article was produced with the assistance of chatgpt and carefully revised by the
        authors. language correction tools, such as writefull, were also employed during the writing process. all stages of data
        selection, analysis, and discussion were conducted exclusively by the authors, with ai tools used solely as writing aids.
        references [1]r.ahmadandm.rafiq.2023. globalperspectiveondigitalpreservationpolicy:a systematic review. journaloflibrarianship
        andinformation science 55, 3 (2023), 859–867. https://doi.org/10.1177/09610006221111572 [2]salvatore andolina, antonella
        santangelo, and antonio gentile. 2010. adap- tive voice interaction for 3d representation of cultural heritage site. in
        2010international conference oncomplex, intelligent andsoftware intensive systems . ieee, krakow, tbd, poland, 729–733.
        https://doi.org/10.1109/cisis. 2010.139 [3]asma hanee ariffin and yu-n cheah. 2013. see what you want, feel what you see: the
        personalized re-recommendation framework using hybrid strategies for fieldtripplan.in 2013thirdworldcongress oninformation
        andcommunication technologies (wict2013). ieee, hanoi, vietnam, 262–267. https://doi.org/10. 1109/wict.2013.7113146 [4]sitaram
        asur, bernardo huberman, gábor szabó, and chunyan wang. 2011. trends in social media : persistence and decay. 5thinternational
        aaaiconference onweblogs andsocialmedia(02 2011). https://doi.org/10.2139/ ssrn.1755748 [5]caroline bertini fernandes and márcia
        gomes marques. 2019. a publicação de poesia na internet: a literatura de clarice freire. vista4 (july 2019), 175–197.
        https://doi.org/10.21814/vista.3020 [6]letizia bollini. 2019. representing a space-based digital archive on historical
        maps:auser-centereddesignapproach. in proceedings ofthe1stinternational andinterdisciplinary conference ondigitalenvironments
        foreducation, arts andheritage , alessandro luigini (ed.). vol. 919. springer international publish- ing, cham, 599–607.
        https://doi.org/10.1007/978-3-030-12240-9_62 series title: advances in intelligent systems and computing. [7]bill bonis, john
        stamos, spyros vosinakis, ioannis andreou, and themis panayiotopoulos. 2007. personalization ofcontent invirtual exhibitions .
        springer berlin heidelberg, 172–184. https://doi.org/10.1007/978-3-540-77051- 0_19 [8]bill bonis, john stamos, spyros vosinakis,
        ioannis andreou, and themis panayiotopoulos. 2007. personalization of content in virtual exhibitions. in semantic multimedia ,
        bianca falcidieno, michela spagnuolo, yannis avrithis, ioannis kompatsiaris, and paul buitelaar (eds.). vol. 4816. springer berlin
        heidel- berg, berlin, heidelberg, 172–184. https://doi.org/10.1007/978-3-540-77051-0_19 series title: lecture notes in computer
        science. [9]b. bonis, j. stamos, s. vosinakis, i. andreou, and t. panayiotopoulos. 2009. a platform for virtual museums with
        personalized content. multimedia toolsand applications 42, 2 (april 2009), 139–159. https://doi.org/10.1007/s11042-008- 0231-2
        [10]e budiman, m wati, and norhidayat. 2019. the 5r adaptation framework for cultural heritage management information system of
        the dayak tribe borneo. journal ofphysics: conference series1341, 4 (oct. 2019), 042016. https://doi.
        org/10.1088/1742-6596/1341/4/042016 [11]manuel castells. 2005. sociedade emrede. paz e terra, são paulo. [12]chengwei yang, rui
        wang, lu wang, chenglei yang, shijun liu, and xiangxu meng. 2010. the personalized service customization based on multimedia re-
        sources in digital museum grid. in 20103rdieeeinternational conference on ubi-media computing . ieee, jinhua, china, 298–304.
        https://doi.org/10.1109/ umedia.2010.5544439 [13]teixeira coelho. 2020. ecultura, autopia final:inteligência artificial e
        humanidades. editora unesp, são paulo. [14]nicolasconstantinides,argyrisconstantinides,dimitrioskoukopoulos,christos fidas, and
        marios belk. 2024. culturai: exploring mixed reality art exhibitions withlargelanguagemodelsforpersonalizedimmersiveexperiences.in
        adjunct proceedings ofthe32ndacmconference onusermodeling, adaptation and personalization . acm, cagliari italy, 102–105.
        https://doi.org/10.1145/3631700. 3664874 [15]jacqueline de araújo cunha and marcos galindo lima. 2024. preservação digital:
        tendências atuais dos conceitos e técnicas. revistaanalisando emciência da informação 11, 2 (nov. 2024), 45–60.
        https://revista.uepb.edu.br/racin/article/ view/4069 [16]qiong dang. 2018. literature review on the digital museum in a chinese
        context. communication, societyandmedia1, 2 (nov. 2018), 149. https://doi. org/10.22158/csm.v1n2p149 [17]ioannis drivas and
        eftichia vraimaki. 2025. evaluating and enhancing museum websites: unlocking insights for accessibility, usability, seo, and
        speed. metrics 2, 1 (jan. 2025), 1. https://doi.org/10.3390/metrics2010001 [18]danilo formenton and luciana de souza gracioso.
        2020. preservação digital: desafios, requisitos, estratégias e produção científica. rdbci: revista digital debiblioteconomia
        eciência dainformação 18, 00 (jun. 2020), e020012. https: //doi.org/10.20396/rdbci.v18i0.8659259 [19]geng yang. 2009. a study on
        the user-centered interface design for vir- tual museums. in 2009ieee10thinternational conference oncomputer-aided industrial
        design &conceptual design. ieee, wenzhou, china, 1647–1651. https://doi.org/10.1109/caidcd.2009.5374866 [20]pablo gobira and
        fernanda corrêa. 2019. a preservação digital da poesia: uma análise do arquivo digital da po.ex. in amemória
        dodigitaleoutrasquestões dasartesemuseologia (1ed.),pablogobira(ed.).vol.1.eduemg,belohorizonte, 165–188. [21]katherine harris.
        2014. archive. in thejohnshopkins guidetodigitalmedia, marie-laure ryan, lori emerson, and benjamin j. robertson (eds.). johns
        hop- kins university press, 16–18. [22]ahdab najib hijazi and ahmad hanif ahmad baharin. 2022. the effectiveness of digital
        technologies used for the visitor’s experience in digital museums. a systematic literature review from the last two decades.
        international journal ofinteractive mobiletechnologies (ijim)16, 16 (aug. 2022), 142–159. https:
        //doi.org/10.3991/ijim.v16i16.31811 [23]delaram javdani rikhtehgar, shenghui wang, hester huitema, julia alvares, stefan
        schlobach, carolien rieffe, and dirk heylen. 2023. personalizing cultural
        heritageaccessinavirtualrealityexhibition:auserstudyonviewingbehavior andcontentpreferences.in adjunct proceedings
        ofthe31stacmconference on usermodeling, adaptation andpersonalization .acm,limassolcyprus,379–387.710 whenart meets computer
        science: a sr about technologies and user interaction in adaptivedigital museums and archives webmedia’2025, rio de janeiro,brazil
        https://doi.org/10.1145/3563359.3596666 [24]otim kayaga and kiu publication extension. 2024. digital archiving and preser- vation
        of art: challenges and innovation. 3 (08 2024), 21–25. [25]hayun kim, maryam shakeri, jae-eun shin, and woontack woo. 2024. space-
        adaptiveartworkplacementbasedoncontentsimilaritiesforcuratingthematic spaces in a virtual museum. journaloncomputing andcultural
        heritage 17, 1 (feb. 2024), 1–21. https://doi.org/10.1145/3631134 [26]barbarakitchenham.2004.
        proceduresforperformingsystematicreviews. keele, uk,keeleuniv. 33 (08 2004). [27]vasileios komianos and konstantinos oikonomou.
        2018. adaptive exhibition topologies for personalized virtual museums. iopconference series:materials science andengineering 364
        (june 2018), 012011. https://doi.org/10.1088/1757- 899x/364/1/012011 [28]jin woo lee, yikyung kim, and soo hee lee. 2019. digital
        museum and user experience: the case of google art & culture. in international symposium on electronic art. international
        symposium on electronic art. [29]jingjing li, xiaoyang zheng, ikumu watanabe, and yoichi ochiai. 2024. a systematic review of
        digital transformation technologies in museum exhibition. computers inhuman behavior 161 (dec. 2024), 108407.
        https://doi.org/10.1016/ j.chb.2024.108407 [30]pasquale lops, marco de gemmis, giovanni semeraro, cataldo musto, fedelucio
        narducci,andmassimobux.2009. asemanticcontent-based recommendersys- tem integrating folksonomies for personalized access. in
        webpersonalization inintelligent environments , janusz kacprzyk, giovanna castellano, lakhmi c. jain, and anna maria fanelli
        (eds.). vol. 229. springer berlin heidelberg, berlin, heidelberg, 27–47. https://doi.org/10.1007/978-3-642-02794-9_2 series title:
        studies in computational intelligence. [31]lev manovich. 2001. thelanguage ofnewmedia. mit press, cambridge, ma. [32]dalton lopes
        martins, josé eduardo santarém segundo, marcel ferrante silva, and joyce siqueira. 2017. repositório digital com o software livre
        tainacan: revisão da ferramenta e exemplo de implantação na área cultural com a re- vista filme cultura. in anaisdoencontro
        nacional depesquisa emciência da informação (enancib). ancib. [33]trevor owens and thomas padilla. 2020. digital sources and
        digital archives: historicalevidenceinthedigitalage. international journalofdigitalhumanities 1 (2020), 325–341.
        https://doi.org/10.1007/s42803-020-00028-7 [34]dragana pavlović. 2022. digital tools in museum learning – a liter- ature review
        from 2000 to 2020. factauniversitatis, series:teaching, learning andteacher education (jan. 2022), 167. https://doi.org/10.22190/
        futlte211104013p [35]a. pedrero, v. alonso, m.a. villarroel, p. de la fuente, and a.s. cabaco. 2009. presentation adaptation:
        results from a case study. in engineering theuser interface ,miguelredondo,crescenciobravo,andmanuelortega(eds.).springer london,
        london, 1–13. https://doi.org/10.1007/978-1-84800-136-7_15 [36]vinícius carvalho pereira. 2024. poesia em flash na antología de
        liter- atura electrónica latinoamericana y caribeña: questões de arquivo. acta scientiarum. language andculture 46, 1 (may 2024),
        e65240. https://doi.org/10. 4025/actascilangcult.v46i1.65240 [37]isabella peters and wolfgang g. stock. 2007. folksonomy and
        information retrieval. proceedings oftheamerican society forinformation science and technology 44, 1 (jan. 2007), 1–28.
        https://doi.org/10.1002/meet.1450440226 [38]landy rajaonarivo, eric maisel, and pierre de loor. 2019. an evolving museum metaphor
        applied to cultural heritage for personalized content delivery. user modeling anduser-adapted interaction 29, 1 (march 2019),
        161–200. https: //doi.org/10.1007/s11257-019-09222-x [39]george e. raptis, christos fidas, christina katsini, and nikolaos
        avouris. 2019. a cognition-centered personalization framework for cultural-heritage content. usermodeling anduser-adapted
        interaction 29, 1 (march 2019), 9–65. https: //doi.org/10.1007/s11257-019-09226-7 [40]roopika risam and alex gil. 2022.
        introduction: the questions of minimal com- puting.digitalhumanities quarterly 16,2(2022). http://www.digitalhumanities.
        org/dhq/vol/16/2/000620/000620.html [41]rejane c. rocha. 2021. fora da estante: questões de arquivo e de preservação da literatura
        digital. nuevarevistadelpacífico 74 (june 2021), 290–309. https: //doi.org/10.4067/s0719-51762021000100290 [42]rejane c. rocha.
        2023. a memória literária: arquivo em tempos de bases de dados.universum (talca)38,1(jul2023),121–133.
        https://doi.org/10.4067/s0718- 23762023000100121 [43]giovanni semeraro, pasquale lops, marco de gemmis, cataldo musto, and
        fedelucio narducci. 2012. a folksonomy-based recommender system for person- alized access to digital artworks. journaloncomputing
        andcultural heritage 5, 3 (oct. 2012), 1–22. https://doi.org/10.1145/2362402.2362405 [44]m. n. sitokdana and a. r. tanaamah. 2016.
        strategi pembangunan e-culture di indonesia. jutisi 2, 2 (august 2016). [45]panagiotis strousopoulos, christos papakostas,
        christos troussas, akrivi krouska, phivos mylonas, and cleo sgouropoulou. 2023. sculptmate: personal- izing cultural heritage
        experience using fuzzy weights. in adjunct proceedingsofthe31stacmconference onusermodeling, adaptation andpersonalization . acm,
        limassol cyprus, 397–407. https://doi.org/10.1145/3563359.3596667 [46]d. svanaes. 2013. interaction design for and with the lived
        body: some implica- tions of merleau-ponty’s phenomenology. proceedings ofacmtransactions on computer-human interaction (tochi) 20
        (2013). special issue on the theory and practice of embodied interaction in hci and interaction design.
        [47]yantingtong,binyuecui,andyulinchen.2018. researchonuivisualdesignof intangible cultural heritage digital museum based on user
        experience. in 2018 13thinternational conference oncomputer science amp;education (iccse). ieee, 1–4.
        https://doi.org/10.1109/iccse.2018.8468809 [48]qinwang.2022. theapplicationofpersonalizedrecommendationsysteminthe cross-regional
        promotion of provincial intangible cultural heritage. advances inmultimedia 2022 (oct. 2022), 1–10.
        https://doi.org/10.1155/2022/5811341 [49]meng yang, jia-xiu zhang, yi shi, bo liu, le-xin guo, zhi-peng yu, bin sheng, and
        li-zhuang ma. 2023. framework of personalized layout for a museum exhi- bition hall. multimedia toolsandapplications 83, 8 (aug.
        2023), 24563–24587. https://doi.org/10.1007/s11042-023-16307-8 [50]jihyunyiandhaesunkim.2021.
        userexperienceresearch,experiencedesign, and evaluation methods for museum mixed reality experience. j.comput. cult. herit. 14, 4,
        article 48 (sept. 2021), 28 pages. https://doi.org/10.1145/3462645 [51]li yifei and mohd kamal othman. 2024. investigating the
        behavioural intentions of museum visitors towards vr: a systematic literature review. computers in human behavior 155 (june 2024),
        108167. https://doi.org/10.1016/j.chb.2024. 108167 [52]namira rahmi zahara and tamara adriani salim. 2022. preservation of digital
        archives: systematic literature review. recordandlibrary journal8, 2 (dec. 2022), 285–297.
        https://doi.org/10.20473/rlj.v8-i2.2022.285-297 [53]lingzhao.2023. personalizedhealthcaremuseumexhibitionsystemdesignbased on vr
        and deep learning driven multimedia and multimodal sensing. personal andubiquitous computing 27, 3 (june 2023), 973–988.
        https://doi.org/10.1007/ s00779-022-01672-2711
  > CONTRIBUIÇÃO:
    Score: 2.000
        when art meets computer science: a systematic review about technologies and user interaction in adaptive digital museums and
        archives enzo rigazzo oliveira media lab universidade federal de mato grosso cuiabá, mato grosso, brasil
        enzo.oliveira@sou.ufmt.brgabriel josé do amaral schuina media lab universidade federal de mato grosso cuiabá, mato grosso, brasil
        gabriel.schuina@sou.ufmt.br vinícius carvalho pereira instituto de linguagens universidade federal de mato grosso cuiabá, mato
        grosso vinicius.pereira@ufmt.brrenan vinicius aranha media lab universidade federal de mato grosso cuiabá, mato grosso, brasil
        renan.aranha@ufmt.br abstract thedigitizationofartisticproductions,ortheircreationinanatively digital format, has expanded their
        scope beyond original intentions, bringing them into close interaction with software-related aspects. in this context, the
        dissemination, preservation, and access to such works, especially within digital museums and digital archives, are inevitably
        influenced by the quality of the underlying software. considering the inherent challenges at the intersection of digital
        humanitiesandcomputing,particularlytheneedforuser-centered andcustomizableexperiencestoeffectivelymanagelarge,heteroge-
        neouscollections,thisarticlepresentsasystematicliteraturereview focused on adaptive, personalized, and customizable digital muse-
        ums and archives. the review aims to identify the main purposes of these systems, the technologies employed in their construction
        and maintenance, and the interaction approaches proposed for users. using a systematic protocol, searches were conducted across
        acm digital library, ieee xplore, science direct, and scopus, result- ing in the analysis of 21 studies. based on the analysis of
        studies, we discuss trends, challenges, and opportunities for the design and development of adaptive digital museums and archives,
        such as the limited incorporation of human-computer interaction and software engineering principles and the need for greater
        standard- ization in the development of adaptive digital archives. keywords adaptive systems, digital museums, digital archives 1
        introduction digital transformation has brought diverse impacts across different sectors of society. in the field of the
        humanities, artistic production standsoutasoneofthedomainsaffectedbydigitaltechnologies.as evidence, it can be observed that,
        while efforts to preserve physical materials have intensified, ranging from manuscripts and paintings in: proceedings of the
        brazilian symposium on multimedia and the web (webme- dia’2025). rio de janeiro, brazil. porto alegre: brazilian computer society,
        2025. © 2025 sbc – brazilian computing society. issn 2966-2753to audiovisual records stored on videotapes, there has also been an
        increase in the production of digital-born content on platforms such as social media [5]. although these digital platforms
        facilitate the dissemination of arts, the ephemeral nature of online materials poses a potential risk to the preservation of
        cultural and artistic products. works published as posts on social networks such as instagram and x, for example, tend to be
        dispersed amid the large volume of new content continually posted [ 4]. furthermore, the discontinuation of certain platforms, as
        the social network orkut, can lead to the permanent loss of digital materials. preservation is also threatened when artistic works
        rely on specific technologies that become ob- solete, as occurred with creations developed in flash, which ceased to be supported
        by major web browsers at the end of 2020 [36]. without proper care for the preservation and cataloging of these digital works,
        they are subject to disappearance, technological ob- solescence, or even simple dispersal across the web [ 24]. the de-
        terioration process, although generally not caused by humidity, temperature, or light – as is the case with physical works – also
        appliesto digital creations,since theyaresubjectto data corruption and loss, as well as technological lag or discontinuation of
        propri- etary technologies. therefore, far from being a topic of exclusive interest to the digital humanities, the preservation of
        digital art is also an inherent subject of computer science. in this challenging context, the creation of digital archives rep-
        resents an effective conservation strategy for these works and has becomeanincreasinglyfrequentendeavorinthefieldofdigitalhu-
        manities [ 15]. these platforms, which combine archival, museologi- cal, and sometimes even educational purposes, may help
        overcome both geographical distances and certain socioeconomic barriers to accessing archived cultural products. although they
        share some goals and purposes with traditional museums, these platforms do not necessarily replicate the experience of visiting a
        physical space, and may instead employ different interaction resources. in the preservation of digital-born or digitized works,
        several projects have sought to provide solutions for the field. one such example is tainacan, a free software platform aimed at
        building collaborative digital archives [ 32], developed by the university of699 webmedia’2025, rio de janeiro,brazil oliveiraet
        al. brasília, with support from the federal university of goiás, the brazilian institute of information in science and technology,
        and the brazilian institute of museums. digital archives developed us-
        ingtainacangenerallypresentworkstovisitorsthroughtraditional web pages, as in the museu da casa de benjamin constant1. how-
        ever,thisisnottheonlyapproachadoptedbysuchplatforms.other initiatives, such as the museu do ipiranga virtual2and the museum of
        life3maintained by fiocruz, use virtual reality (vr) to cre- ate immersive experiences with digitally preserved works or even
        environments. giventheinterdisciplinarynatureofthetopicanditsfoundation in digital technologies, it is essential to examine key
        aspects from fields such as human-computer interaction (hci), multimedia and software engineering (se) in digital archives or
        museums. in the field of hci, there is room not only for improving the resources employed, but also for customizing and evaluating
        these tools from the users’ perspective, in order to offer a better user experience while interacting with the digital archive or
        museum. this includes analyzing how the modes of interaction with these platforms, such as through web pages or vr environments,
        can influence user inter- est, exploration of the archive, and overall experience quality. with regard to se, it is necessary to
        observe the development of tech- niques that ensure the efficient implementation of digital archives, with particular attention to
        the evolution of both the archives and the digital-born works over time. given the interdisciplinary nature of digital archives
        and the fragmented treatment they often receive across the digital hu- manities and computer science, this systematic literature
        review examines 21 studies to identify the primary purposes of such plat- forms, the technological strategies employed in their
        development, and the interaction modalities made available to users. by articulat- ing perspectives from both fields, the study
        contributes to a deeper understandingofcurrentpracticeswhilealsorevealingcriticalgaps, such as the limited incorporation of
        human-computer interaction and software engineering principles, the lack of standardization in development methodologies, and the
        insufficient attention to accessibility and long-term software evolution. 2 fundamental concepts given the interdisciplinary
        nature of this work, involving both the humanities and computer science, we present in this section some fundamental definitions
        for the discussions addressed in this study. 2.1 digital archives in this work, we use the term “archives” to refer to
        institutions that collect, systematize, preserve, and present cultural products to the
        public.withinthisscope,differenttypesofinstitutionsareincluded, suchas museums, archives,and libraries. theirfunctions may differ
        for specialists, but for the general public (and for the purposes of this study) they can all be understood as memory
        institutions. digital archives can be broadly defined as organized collections
        ofculturalproductsthatareeitheroriginallydigital(suchasebooks
        1https://museucasabenjaminconstant.acervos.museus.gov.br/pagina-acervo- museologico/ 2https://museudoipirangavirtual.com.br/
        3https://eravirtual.org/parque-da-ciencia/or images produced by generative algorithms) or digitized (such as images of books and
        photographs of oil paintings, among others). according to owens and padilla [33], a digitized collection may be a copy of a
        partial or complete collection of a physical archive, as in the case of the bnbdigital4, or thecentrodigitaldedocumen-
        taçãoepesquisamemóriasdosuldabahia5. both in digitized and digital archives, each collected item is described by metadata and, in
        general, the collections are accessed by the public through an online interface. the importance of digital archives for the
        construction of a memory of our present time is directly proportional to the chal- lenges they face. in addition to issues of
        funding, infrastructure, and archival methodology, which also affect physical collections, digital archives face issues such as
        technological obsolescence [ 42], archival instability, and the potential for infinite data accumulation [21]. 2.2 digital culture
        digital culture can be defined as the set of cultural practices that emerge from contexts in which interactions between two or
        more humans, between humans and the world, and between humans and their ideas are mediated by computational technologies. in his
        anal- ysis of the language of new media, [ 31] defines five characteristics of this language, which can also define the structural
        elements of digital culture: numerical representation, modularity, automation, variability, and cultural transcoding. other
        proposals for the semiotic characterization of digital cul- ture, such as that of [ 13], highlight features such as digitality,
        mo- bility, impermanence, disruption, connectivity, editability, combi- natorics, duplicability, exponentiality, and virtuality,
        among others. describing how we relate to information and communication tech- nologies (ict), these features are hallmarks of a
        culture in which data is transformed into information and gains prominence in eco- nomic, political, and social processes, in a
        dynamic that castells [11]called informationalism. generating data that multiply and circulate in accelerated global flows, the
        complexification of digital culture requires a complexification and evolution of digital archives as memory devices for the
        growing mass of data. 2.3 folksonomy folksonomy is a term that blends the words “folk” and “taxonomy” to describe the process of
        collaboratively tagging content. in this process, users evaluate the content and define tags that represent it, creating a form of
        categorization that evolves organically [ 43]. this can be done in two ways: if the tags are stored only once, we have a narrow
        folksonomy; however, if each new instance of the tag is recorded,itisconsideredabroadfolksonomy.inthelatterapproach, it is
        possible to conduct an in-depth analysis of the number of tags and the exposed content, ensuring greater fidelity to the tag [
        37]. by reflecting the way users organize and categorize information on the internet, folksonomy is deeply related to digital
        culture and digital archives. 4http://bnbdigital.cultura.df.gov.br/ 5https://memoriasulbahia.com.br/700 whenart meets computer
        science: a sr about technologies and user interaction in adaptivedigital museums and archives webmedia’2025, rio de janeiro,brazil
        3 state of the art due to its interdisciplinary nature, research involving the creation of digital works, museums, or archives may
        present different per- spectives on the artifacts produced and their use. thus, this section
        discussesworksthatrepresentthestateoftheartindigitalarchives from the perspective of each area. 3.1 digital humanities from the
        perspective of digital humanities, publications usually discuss aspects related to the definition of digital archives and their
        main characteristics. “anarchive”, for example, is a term used by rocha[41]torecognizetheinstability,ephemerality,andvariability
        of digital media, which define the characteristics of digital works. with the advancement of digital technologies, it is
        increasingly common for works to exist exclusively in digital archives. a central issue, therefore, is to find an effective means
        of preserving these works while respecting their unique characteristics. other studies discuss the effective preservation of
        digital works, whichrequiresnotonlyprotectingthemfromobsolescencebutalso maintaining their unique characteristics, including their
        ephemer- ality and technological dependence. rocha [41]argues that the intrinsic obsolescence of digital works also needs to be
        preserved. this ephemeral existence demands the preservation not only of the works themselves but also of their interaction with
        the reader. gobira and corrêa [20]describe the creation and development of the po.ex digital archive, focusing on the preservation
        of digi- tal poems. their preservation efforts ensured that the interactive features of the works were maintained. since these
        works were created through programming, they required servers for distribu- tion. to address this issue, the works were
        reimplemented on the platform’s own servers. alternatively, the implementation could be made available on multiple platforms,
        reinforcing the idea that dissemination itself is a form of preservation. while the po.ex digital archive focuses on preserving
        the in- teractivity of the works, pereira [36]discuss the decentralization of
        digitalpreservationandthevalorizationofworksfrommatogrosso, whilecataloginganddisseminatingregionalliteraryproductions.in the
        digital literature collection of mato grosso, works published on websites or social media platforms (instagram, wattpad, twit-
        ter, facebook, etc.) by artists born or residing in the state of mato grosso, brazil, are showcased. this collection serves as a
        refuge space for lesser-known works and proposes a means for the dissem- ination and conservation of regional works in a tool
        conceived in brazil: the open-source wordpress plugin tainacan. thus, accord- ing to pereira [36], the project fosters the
        independence of research and literary production delinked from eurocentric technological and aesthetic standards. 3.2 computer
        science from the perspective of computer science, many studies focus on the development of methodologies and technical guidelines
        aimed at digital preservation. in this line, formenton and gracioso [18] propose guidelines for the preservation of digital works,
        consider- ing the ephemerality of dissemination and storage media, for both digital-born and digitized works. their work outlines
        challenges of managerial, technical, legal, political, economic, and social nature.ahmad and rafiq [1]highlight that many
        organizations already have or are trying to develop digital preservation policies. how- ever, they argue that the development of
        such policies is generally considered an intrinsic responsibility of organizations, rather than an outsourced or globalized task.
        aspects related to hci, in turn, have been less explored in the context of digital museums and archives. tong et al . [47]propose
        visual interface design strategies for digital museums of intangible heritage based on user experience principles, focusing on
        color, typography, and layout, but without conducting user evaluations. similarly, lee et al . [28]analyze the google art &
        culture plat- form through the lens of remediation theory, identifying interface elements that foster both information delivery
        and user engage- ment.theirstudyprovidesconceptualinsights,butdoesnotinclude empirical testing with users. on the other hand, a
        broader and com- plementary perspective is provided by drivas and vraimaki [17], who evaluate 234 museum websites based on
        accessibility, usability, seo, and speed. the authors emphasized the relevance of user- centered metrics and highlighted
        disparities in user experience between mobile and desktop platforms. the proposed framework promotes inclusive design and supports
        non-technical staff in im- proving digital interfaces, reinforcing key hci principles such as usability, accessibility, and
        equity. 3.3 contributions of this paper thescientificliteraturepresentsreviewsdiscussingtheuseofdigital technologies, such as
        artificial intelligence (ai) and vr, within the scope of exhibitions, archives, and museums. for instance, [ 51] and [22] focus on
        visitor behavior and user experience with immersive technologies such as vr and augmented reality (ar) in museum contexts. their
        analyses, however, are predominantly limited to physical or hybrid exhibitions. li et al . [29]offers a comprehensive
        overviewofdigitaltransformationtechnologies(dtts),including ai, internet of things (iot), robotics, and 3d printing, but does not
        examine how these technologies relate to the communicative or functional objectives of digital collections. complementarily,
        studies such as [ 52] and [16] are more aligned with institutional and preservation-oriented concerns and do not explore user
        interaction in depth. pavlović [34]in contrast, dis- cusses digital tools for learning in museums but remains grounded in
        pedagogical theory without analyzing digital archives as plat- forms for broader cultural participation. however, these reviews
        consider the role of such technologies as part of an experience that is predominantly analog and often guided by professionals or
        instructions within the physical environment. with this literature review, we aim to investigate the technological decisions and
        in- teraction approaches that have been adopted in exclusively digital collections and museums with adaptation, personalization or
        cus- tomization. this investigation is important because, in such cases, the user’s entire interaction with artistic productions
        is mediated by interfaces, which may influence their experience, interest and appreciation of these works. 4 methodology in order
        to identify the characteristics, user interaction methods, and digital technologies used in digital museums and archives with701
        webmedia’2025, rio de janeiro,brazil oliveiraet al. adaptation, we conducted a systematic literature review (slr). this review was
        organized into three main stages, as presented in [26]:planning ,conducting , andreporting . the first stage ( planning ) involves
        defining the scope and the review protocol. the protocol adopted was picoc, which is detailed in table 1. through this protocol,
        the area and object of study were defined ( population , intervention ,comparison ), along with the expected objectives ( out-
        come)andthegroupsaffectedbythisreview( context).ourresearch questions (rqs) are the following: •rq1:for what purpose are digital
        archives developed? •rq2:what computational technologies can be observed in digital archives? how do these characteristics relate
        to the purpose of the archives? •rq3:how do users of digital archives interact with the platform and the works available there?
        our first research question (rq1) aims to explore the purpose of digital archives. while many of them were developed to digitalize
        physical museums, other digital archives were created aiming to enhance the availability of artworks. considering that the purpose
        of a digital archive can influence the interaction aspects and the technologies adopted, we addressed this topic in this review.
        then, in the second research question (rq2), we observed the technolo- gies adopted in each digital archived related in the
        papers, aiming to identify if there is any association between technologies and archives’ purposes. aspects related to users’
        interaction were dis- cussed in our third research question (rq3), aiming to identify challenges, limitations and opportunities
        for this context. in the second stage ( conducting ), some control articles were selected through a non-systematic search in the
        scielo and capes journal portal databases, aiming to identify relevant articles that could serve as a basis for the selection of
        keywords. the resulting search string, derived from these keywords, was: titlemustcontain: (personaliz* or adapt* or customiz* or
        user-center*); metadata must contain: (“digital archive” or “digital collection” or “digital
        museum”or“virtualmuseum”or“culturalheritage”or“digitalart gallery”) . the string was applied to four academic databases: acm
        digital library, ieee xplore, science direct, and scopus. to ensure robust and comprehensive coverage of the study’s
        interdisciplinary focus, the selection targeted databases prominent in computer science (e.g., hci and software engineering) and
        broader research fields(e.g.,digitalhumanitiesandculturalheritage).table2shows all versions of the strings. the search string was
        meticulously crafted to maximize the re- trieval of interdisciplinary works, combining terms for adaptation (e.g., adapt*,
        personaliz*) with context keywords (e.g., ”digital mu- seum”, ”cultural heritage”) to ensure all selected studies remained highly
        relevant to the review’s core focus. after the initial data col- lection using the search strings, the database filters were
        deemed insufficiently precise. to ensure the proper selection of articles, a python script was developed to automatically verify
        the presence of the correct keywords in the metadata and titles, as specified in the search strings. in order for articles to be
        selected within the scope defined by the review protocol, the inclusion and exclusion criteria were established and listed below:
        i1:the study addresses the development, maintenance, or use of a digital collection or digital museum.i2:the study describes
        technical aspects (interaction methods, technologies used) that support the understanding of com- putational elements.
        i3:thestudypresentsasolutionfocusedonabroadercollection, rather than on a single (art)work. e1:the study does not discuss the
        development, maintenance, or use of a digital collection/museum. e2:the study does not describe technical aspects (interaction
        methods, technology used) that enable understanding of computational aspects. e3:the study presents a solution related to a
        specific (art)work, without addressing a broader collection. astudyisconsideredeligiblewhennoneoftheexclusioncriteria apply.
        additionally, no restriction was placed on the publication date of the articles. subsequently, data extraction was divided into
        two stages: partial and full; and performed by two people. initially, titles and abstracts of all papers retrieved from the
        databases were read. only the articles that met the inclusion criteria were read in full, for detailed information extraction and
        the extraction was performed by using a structured form briefly described in table 3.
        also,whetherornotthestudyincludedauserevaluationwastaken into account during the extraction. this aspect was considered rel- evant
        for identifying works that go beyond technical or theoretical descriptionsandprovideevidenceofpracticalapplicationsanduser
        experience. at the end of the selection process, 21 articles were accepted. the selection process is shown in figure 1, while
        table 4 presents the data collected from the articles selected during this phase. 5 results and discussion in this section, we
        present the results obtained in our investigation, based on the data synthesized in table 4. next, we answer the previously
        formulated research questions and perform a critical analysis of the evidence found, highlighting the contributions and
        limitations. 5.1 purpose of digital archives the analysis of the selected articles reveals that the digital archives addressed in
        these studies are applied in different contexts, also involving different purposes in their conception. in this sense, to support
        the discussion of rq1, we chose to divide the purposes of the archives into three strands: i) dissemination , related to im-
        proving visitation; ii) preservation , aimed at the maintenance and care of digital works over time; iii) availability , related
        to the facil- itation of access to digital works. these categories are not mutually
        exclusive;therefore,anarchivedescribedinacertainstudymayfall into more than one category, highlighting the multifunctionality of
        digital archives. 5.1.1 dissemination. dissemination, which involves the concern with providing a more meaningful experience of
        exploring the worksinthearchives,isthemostrecurringpurpose,beingobserved in 57.14% of the studies. a significant point raised in
        the works with this purpose is the need to condense the content presented to the user [ 3,30,38,43], which include, among others,
        examples that employ recommender systems for this purpose. this stems from702 whenart meets computer science: a sr about
        technologies and user interaction in adaptivedigital museums and archives webmedia’2025, rio de janeiro,brazil table 1:
        descriptive table of picoc protocol elements. picoc protocol population studies that describe the development, evaluation, or
        analysis of digital archives and their impacts. intervention “innovative” approaches to exploring digital archives. comparison
        digital archives with traditional interaction approaches, such as static web pages. outcome experience with the works, user
        experience, interest in exploring the digital archive. context academic papers published in conferences or journals, as well as
        applications made publicly available. records identified through database searching (n = 431)additional records identified through
        other sources (n = 0) records after duplicates removed (n = 360) records screened (n = 360) records excluded (n = 317) full-text
        articles assessed for eligibility (n = 43)full-text articles excluded, with reasons (n = 11) - not relevant (n = 2) - not
        open/available paper (n = 9) studies included in qual- itative synthesis (n = 21) studies included in quantita- tive synthesis
        (meta-analysis)identification screening eligibility included figure 1: prisma flow diagram illustrating the identification,
        screening, eligibility,and inclusion of studies accordingto the defined criteria. the fact that many archives have large databases
        of works and a heterogeneous audience. thus, the task of presenting appropriate content for a certain user becomes much more
        complex in this situation. bonis et al . [9]mention that, due to the large volume of
        dataintheseplatforms,thereisaneedforcontentrecommendation to enable user interaction with these extensive data sets. according to
        this study, a common strategy is to subdivide large data sets, therebygeneratingsubsets.fromthesesubsets,contentsuggestions
        aregeneratedforusers.tothisend,theauthorsimplementsemantic graphs to better organize the works. since archives also play an active
        role in mediating knowledge, those designed with this purpose often adopt various strategies to encourage user interaction and the
        discovery of new cultural products, making the experience more immersive and engaging. our review found works involving catalog
        personalization accord- ing to user characteristics ([ 3,38]), encouragement of users’ active participation in exploring the
        collections ([ 39]), and the creation of more intuitive environments ([19]). geng yang [19]evaluated what design characteristics
        are most important to users of these tools. a form was used to collect data on which factors influence user comprehension while
        navigating the page of a digital archive. in the case of [ 53], implementation efficiency was evaluated through experimental
        testing. the authorsdeveloped an automatic path search algorithm and applied it to a digital collection. then, they incorporated
        the obstacle avoidance technique and compared the performance before and after the im- plementation. the result revealed
        improvements not only in more natural movement but also in processing performance and use of memory space. another approach
        adopted by researchers involved improving how additional information about the works is communicated to users. studies such as [
        2,14] investigate more natural means of communication between the user and the collection, promoting greater familiarity and,
        consequently, better learning. to evaluate communication, [ 14] led an experiment in which, after interacting with the tool, the
        users responded to a survey assessing mixed reality experiences, as proposed in [ 50]. the results of this study will be discussed
        in more detail in section 5.3.2. also from a social perspective, [ 9] developed a method to create communities with similar
        interests, thus increasing engagement and encouraging col- laborative exploration of digital archives. once the user modeling is
        established, it was possible to compare different users, and thus create groups with similar interests. personalized rooms were
        cre- ated and assigned to users with similar preferences, so that users could meet and communicate.703 webmedia’2025, rio de
        janeiro,brazil oliveiraet al. table 2: database search strings. database search string acm digital library [[title: personaliz*]
        or [title: adapt*] or [title: cus- tomiz*] or [title: user-center*]] and [[all: ”digital archive”] or [all: ”digital collection”]
        or [all: ”digital museum”] or [all: ”virtual museum”] or [all: ”cultural heritage”] or [all: ”digital art gallery”]] sciencedirect
        title, abstract, keywords: ”digital archive” or ”digital collection” or ”digital museum” or ”virtual museum” or ”cultural
        heritage” or ”digital art gallery” title: per- sonalizationorpersonalizedoradaptationoradaptive or customization or customized or
        user-centered scopus title ( personaliz* or adapt* or customiz* or user- center* ) and title ( ”digital archive” or ”digital col-
        lection” or ”digital museum” or ”virtual museum” or ”cultural heritage” or ”digital art gallery” ) ieee xplore (”document
        title”:personaliz* or ”document ti- tle”:adapt* or ”document title”:customiz* or ”doc- ument title”:user-center*) and (”all
        metadata”:”digital archive” or ”all metadata”:”digital collection” or ”all metadata”:”digital museum” or ”all metadata”:”virtual
        museum” or ”all metadata”:”cultural heritage” or ”all metadata”:”digital art gallery”) note:each string was adapted to each
        platform’s search syntax. table 3: summary of key categories extracted from the ana- lyzed articles. question main answers purpose
        of the archive availability, dissemination, preservation interaction techniques and their improvementrecommendation systems,
        personalized 3d environment generation, software quality (a, folksonomy, chatbot, realistic environments, data organization
        interaction resources virtual reality, traditional page, voice, mixed reality, social network creation tools unity, python,
        javascript, xml, wordpress media formats of the artwork images, text, 3d models, audio, video user evaluation? yes, no, not
        informed reported challenges lack of funding, technical problems, user education, hardware limitations, interdisciplinary
        integration 5.1.2 preservation. the preservation of works, whether digitized or digital-born, is a central motivation for the
        development of sev- eral digital archives. however, within the scope of this review, few articles have focused on preservation;
        instead, this concern arose secondarily. for this reason, only 9.52% of the articles fall into this category. in [ 10], the goal
        of conserving digital cultural products [44] in digital archives is explicit. the researchers aimed at creating a digital
        collection of indonesian customs, arts, and traditions to ensure these are not lost over time. the “e-dayaknese” framework
        developed by the authors allows for the creation of entirely new cultural products or the association of new items with existing
        ones. it leverages a semantic structure based on the relationships between items, which facilitates the discovery of related
        content. in the proposed architecture, the digital organization of cultural data improves the consultation time and registration
        of new items. in addition to that, one of its modules is responsible for collecting usertable 4: articles included in this
        systematic review. # citation year rq1 rq2 rq3 1 [7] 2007 dis rs, peg vr 2 [9] 2009 dis rs, peg vr 3 [35] 2009 dis sq tp 4 [19]
        2009 ava sq tp 5 [30] 2009 dis rs, folk tp 6 [12] 2010 ava do tp, vr 7 [2] 2010 dis chat tp 8 [43] 2012 dis rs, folk tp 9 [3] 2013
        dis peg vr 10 [27] 2018 dis peg vr 11 [38] 2019 dis rs, peg vr 12 [39] 2019 dis rs, eye tp 13 [10] 2019 pre rs tp 14 [6] 2019 dis
        sq tp 15 [48] 2022 pre rs tp, vr 16 [49] 2023 dis rs, peg vr 17 [53] 2023 dis re vr 18 [23] 2023 dis re, eye, chat vr, voi 19 [45]
        2023 dis rs, sq tp 20 [25] 2024 ava peg vr 21 [14] 2024 dis chat mr, voi caption: ava: availability, dis: dissemination, pre:
        preservation, rs: recommendation systems, peg: personalized 3d environment generation, folk: folksonomy, chat: chatbot, eye:
        eye-tracking, re: realistic environments, sq: software quality analysis, do: data organization, vr: virtual reality, tp:
        traditional page, mr: mixed reality, voi: voice interaction. information, enabling personalized recommendations. the informa- tion
        is collected following the proposed 5r adaptation framework. the acronym 5r stands for right timing, right location, right device,
        right learner, and right contents, meaning that the rec- ommendation is made based on the user’s context. in the validation
        process, a functional prototype of the proposed framework was implemented, but user surveys, scalability tests, or discussions on
        software evolution were not conducted. inturn,[ 45]presentsatoolthatstoresdigitalanddigitizedsculp- tures from artists
        representing various cultures around the world. the tool uses fuzzy logic-based resources to improve recommen- dations by taking
        into account user profiles and the experience of accessing cultural heritage. the architecture created for sculpt- mate contains
        three layers: the userinterfacelayer , which allows button configuration and 3d model visualization; the application logic layer ,
        which includes the implementation of content man- agement and personalization with fuzzy logic; and finally, the data storage
        layer , which stores user information and structures. the article mentions that the focus during development was on usabil- ity,
        adaptability, and performance, allowing for future evolution of the framework due to its modular implementation. the main im-
        provements discussed in the article are the implementation of more sophisticatedmachinelearningalgorithmsandtechniquesformore
        accurate recommendations. the paper also proposes the migration from local storage to a cloud server, with integration with apis
        to access external resources and models. furthermore, the authors discuss the possibility of implementing social functionalities,
        such as sharing preferences among users, promoting a more connected community. 5.1.3 availability. another purpose of digital
        archives is to make content available to the public, facilitating access to digital cultural products, as discussed in 33% of the
        analyzed studies. some studies704 whenart meets computer science: a sr about technologies and user interaction in adaptivedigital
        museums and archives webmedia’2025, rio de janeiro,brazil present models that address the heterogeneity of digital resources,
        proposing strategies for making content available in a way that improves user experience , whether by developing user-centered and
        enjoyable interfaces [ 19], or by implementing recommendation systems to guide access [ 12,53]. these approaches aim to make
        access to heritage more inclusive, adapted to individual needs and, at the same time, increase interactivity and visitor
        engagement, providingaricherandmorepersonalizedexperience.budimanetal . [10]and strousopoulos et al . [45]state that, in addition
        to acting as preservation tools, collections play a crucial role in democratizing access to the heritage of socioethnic entities
        with limited visibility on the global stage. these tools not only ensure digital preservation but also expand access to the
        represented cultures. similarly, bollini [6]proposes the centralization of information on cultural heritage, aiming to make
        content available both to na- tives and to the non-specialized public in the milan region. that strategy is intended to preserve
        the relationships between docu- ments during the process of organizing and digitizing the works. this model aims to broaden access
        to cultural resources, promoting greater understanding among diverse audiences and encouraging engagement with local history. in
        the evaluation process, a survey was conducted with 24 participants, and the data were analyzed according to norman’s guidelines.
        based on the findings, a second design cycle was launched to implement the necessary improve- ments. the collection was evaluated
        within the field of hci, aiming toverifyusabilityanduser-centereddesign.however,noeffortwas
        madetoanalyzethecollection’spotentialforpopularization;thatis, metrics of reach or social impact were not taken into
        consideration. 5.2 techniques and technologies digital archives and museums are driven by a variety of technolo- gies aimed at
        providing immersive and personalized experiences for users. this section discusses the main technological approaches
        andtheirrelationtothearchivepurposesidentifiedintheliterature, seeking to answer the research question rq2. 5.2.1 virtual
        environments. in digital museum studies, virtual en- vironments can take on various forms and characteristics. in this article,
        virtual environments are considered as 3d interfaces, which may or may not resemble the physical spaces of real museums, allowing
        users to navigate, interact with, and explore exhibitions. this type of system often uses 3d modeling and supports specific
        equipment, such as vr headsets. svanaes [46]argues that the meaning of something is generated from the physical interactions we
        establish with the environment. thus, perception and interaction are directly linked to how we see an artifact and what it
        represents – not statically, but dynamically and generated at the moment of interaction. vr provides the envi- ronment through
        which the user can interact and, consequently, create new meanings and perceptions of the surrounding objects. therefore, it has
        become one of the most common resources in digital museums, providing immersive experiences that allow users to explore
        exhibitions intuitively. 3d virtual environments have been widely adopted in studies focusing on adaptive enhancements to
        conventional museums. for example, komianos and oikonomou [27], rajaonarivo et al . [38], bonis et al . [9], yang et al . [49],
        zhao[53],andkimetal .[25]presentsolutionsthatadapttheuserexperi- ence to the context of traditional museums through
        personalization and interaction enhancements within 3d virtual environments. these studies represent approximately 28% of the
        publications in our slr. these studies focus on different characteristics of virtual envi- ronments.forexample,in[
        49]thedevelopmentoftheenvironment reflects a concern with realism in the rendering of 3d models. the article describes the steps
        used for gamma correction, color, and tone adjustments of images to create a more realistic and therefore more immersive
        environment. zhao [53]also address this concern bydiscussingthefollowingmodelingmethods:geometricmodeling, based on mathematical
        models and computer graphics; and image- based modeling, using real image capture. while the former offers many details in the 3d
        model, it is computationally expensive for complex environments such as a digital museum. the latter offers many visual details
        but has limitations regarding the interactivity of the 3d model. therefore, the authors propose a hybrid modeling approach,
        leveraging the interactivity of the first method and the realism of the second. in addition to the visual realism of 3d models in
        the virtual envi- ronment,zhao [53]alsodiscussesmorenaturalformsofnavigation. for example, algorithms are developed, to ensure
        that movement occurs naturally, smoothly avoiding objects rather than passing through them. other works discuss the effective
        arrangement of artworks within the space, considering artistic categories [ 9], user preferences [ 38], and immersion time within
        the virtual environ- ment [27]. 5.2.2 traditional interfaces. while several adaptive works high- light a preference for 3d virtual
        environments, in which the user is directly immersed in the exhibition context, studies such as [ 2]
        proposeanalternativeapproach.inthisstudy,artworksarebrought closer to the user through simplified interfaces focused on prior-
        itizing direct interaction with displayed items, without the need for full immersion in a virtual environment. in this case, the
        user interacts directly with the model of the artwork and does not navi- gate through a virtual environment. this interaction is
        performed through traditional visual commands, by clicking buttons on the archive’s interface. studies such as [ 12] and [6] also
        favor the use of traditional web pages due to the diversity of resources available to users. this approach is common in contexts
        where resource heterogeneity de- mands a more conventional interface, focused on user-centered curation. on the other hand,
        studies aiming to enhance the user experience through interface adaptations, such as [ 35] and [19], opt for simplified and
        conventional traditional pages. this is be- cause the inclusion of external elements, such as excessive menus,
        disconnectedfunctionalities,orredundantinformation,wouldcom- promise the immersiveness of the archive. in a context where
        immersion is not a priority, several studies are dedicated to gathering and adapting artworks based on cultural and ethnic
        characteristics, without the intention of replicating a real-world exhibition in a virtual environment. examples can be found in
        studies such as [ 10,30,43,48], which adopt traditional page structures. these works focus on curating and organizing artworks
        based on cultural and ethnic categories.705 webmedia’2025, rio de janeiro,brazil oliveiraet al. 5.2.3 recommendationalgorithms.
        the literature highlights the growing adoption of recommendation algorithms in different types of digital archives, both in 3d
        virtual environments and traditional pages,aimingtoenhancethepersonalizationoftheuserexperience. in 3d environments,
        recommendation involves various tech- niques. javdani rikhtehgar et al . [23]and raptis et al . [39]use eye-tracking to assist in
        analyzing user behavior and enable sug- gestions based on their points of interest. for instance, in [ 23], users’ eye movements
        were tracked to determine which elements within paintings most attracted their attention (buildings, faces, and details). this
        information was used to make personalized rec- ommendations. the study also reveals that gaze duration can serve as an indicator
        of user preference, but this correlation comes with certain limitations. user surveys showed that the display order of artworks,
        how detailed the artwork is, or whether it has a more or less interesting description also impact gaze duration, but they do not
        necessarily define a user profile. in contrast, folksonomy-based approaches, as seen in [ 43] and [30], involve organizing content
        through collaboratively defined categories, and traditional pages provide users with a familiar inter- face to perform this task.
        in [ 30], users rated paintings (from 1 to 5) and added tags they deemed appropriate. the interface provided access to the
        painting image, title, description, and other popular tagscreatedbyusers.adatacollectionprocesswascarriedoutwith 40 individuals
        (30 general users and 10 experts) to gather tags for training a multivariable poisson model. tags were classified as (i)
        personaltags,providedbyaspecificuserforaspecificartwork;and (ii) socialtags, assigned to the artwork by various users. the results
        showed a general improvement in filtering accuracy with tags cre- ated by users. based on this, the authors proposed a hybrid
        system that incorporates folksonomy into content-based recommendation. to evaluate this framework, k-fold cross-validation and
        metrics suchasprecisionandrecallwereused,tiedtodifferentexperimental combinations (permutations between static content implementa-
        tion, personal tags, and social tags). the inclusion of socialtags produced lower results than personaltags, and combining static
        information (artwork descriptions) with personaltags achieved the highest filtering precision. the main results of this study show
        that personal preferences are more relevant than general consensus when making recommendations. moreover, models that adapt to
        user preferences are present in both immersive environments and traditional pages. examples include the use of machine learning
        for personalization, as in [ 49] and [25], as well as genetic algorithms and fuzzy logic for more accurate recommendations, as
        previously addressed in [45]. the dynamic generation of 3d virtual spaces can also be tailored to user characteristics and the
        curated selection of artworks to be displayed. in [ 8,9,38], semantic graphs grouped artworks for users, optimizing the
        recommendation process. in [ 53], recommendations are generated based on user profile, which includes demographic attributes
        collected to associate new cases with similar past ones, using the case-based reasoning technique. recommendations are generated
        in a ranked list of the best visitation routes. likewise, in [49] demographic data (age, profession, gender, education level) are
        collected to serve as input for a deep learning model that can infer user preferences.in addition to these approaches, other
        methods also deserve mention, such as calculating the proximity between clusters of artworks and users, as described in [ 25]. in
        this case, artworks are divided into thematic clusters, based on similarity in color, material, description, artist, and creation
        date. once the groups are defined, distances between them are calculated, representing how different
        theyarefromoneanother.thisinformationisthenusedtogenerate more coherent thematic exhibitions. 5.2.4 chatbots. [2,14,23] implement
        chatbots and voice inter- action to improve communication between users and the archive systems. those systems are complementary
        to the standard ways of interaction, like mouse and keyboard, and so not mandatory to the user. in [ 2], speech recognition is
        limited by the grammar that the system can recognize, which restricts interaction with the user. in this type of approach,
        questions outside the system’s predefined pattern are not understood, which could frustrate users. through this system, users can
        obtain specific information about artworks and also use specific voice commands for navigation. voice-guided navigation adds an
        accessibility layer to the software, enabling use by people with motor or visual impairments, in addition to offering a different
        form of interaction for users to acquire knowledge of the artworks. nonetheless, this feature should be regarded as a
        complementary interaction method, as reliance on voice guidance alone may pose accessibility barriers for deaf users. 5.3
        interaction features interactionfeaturesplayafundamentalroleinuserengagementand satisfaction. from this perspective, the studies
        revealed different forms of interactivity with digital archives, which will be presented in the following topics, allowing us to
        address rq3. 5.3.1 interactioninvirtualandaugmentedrealityenvironments. vr is one of the technologies that enables the creation of
        3d virtual environments, where interaction can be either immersive (through
        theuseofvrheadsetsorhapticgloves)ornon-immersive(typically via conventional screens). in [ 9], vr allows the development of a more
        immersive and realistic experience for the user, as it also enables more natural navigation. the construction of vr spaces
        involves several stages, such as the arrangement of objects in the environment, texturing, lighting, and, in some cases,
        animation. the works of [ 7,9,38,49,53] seek ways to facilitate the con- struction of vr environments and represent 25% of the
        articles we analyzed. in these studies, methods were developed to automate and simplify the creation of vr environments through
        algorithms capable of arranging the items across the available space, given a set of artworks – an otherwise time-consuming and
        repetitive manual task. in [ 27], this arrangement also aims to optimize the user’s time by ensuring that artworks are placed in
        appropriate locations with dynamically calculated spacing, minimizing unnec- essary time spent during exploration. likewise, [ 53]
        also develops an algorithm to find more natural paths that avoid obstacles in exhibitions, thereby improving the user’s navigation
        experience. in [53], interaction occurred in an intuitive and immersive man- ner, allowing users to explore the digital archive
        through different modalities. sensors captured movements, voice commands, and706 whenart meets computer science: a sr about
        technologies and user interaction in adaptivedigital museums and archives webmedia’2025, rio de janeiro,brazil gestures to enable
        fluid navigation through the virtual environ- ment, while an intelligent roaming system automatically adjusted the trajectory to
        avoid obstacles, making navigation faster. vari- ous media formats (text, image, animation, sound, and video) were also integrated
        into the systems to find more user-friendly ways to convey information. other articles, such as [ 53], [9], and [38], do not
        explicitly de- scribe how user interaction takes place – whether through mouse, keyboard, or any special equipment. in contrast, [
        49] details how interactionoccurs:thewasdkeysareusedtonavigatetheenviron- ment, the r key activates automatic navigation to a
        user-defined point, the mouse sets the viewing direction, and the right-click allows the user to rotate objects. strousopoulos et
        al . [45]describe an alternative to standard devices: headsets compatible with 3d vision, which provides greater immersion. an
        important point is that articles concerning archives using vr demonstrateaconcernwithnavigationthroughspace,emphasizing
        naturalness and user’s freedom. among the works analyzed, users were not suggested specific routes to follow; guidance occurred
        throughthemuseum’sconstructionbasedonartworkselectiondur- ing curation and automatic space creation. the only exception was [3],
        in which a route is suggested to the user and adapted not only to their preferences but also to their reactions while navigating
        the exhibition. it is worth noting that navigation is a key challenge in any vr environment, particularly immersive ones requiring
        head- sets, and not an issue exclusive to virtual archives, so that solutions and challenges in vr from other domains might apply
        to digital archives as well. surprisingly, the analyzed studies do not address motion sickness, a common concern in immersive vr
        experiences. although most works include some form of user evaluation, these are often limited to assessing curatorial aspects.
        they analyze, for example,thepositioninganddistributionofartworks,orthequality of the rendering and lighting, rather than comfort
        or discomfort during navigation. 5.3.2 voice interaction. from another perspective, in [ 2,14,23], representing 14% of the
        studies, voice resources permit a more per- sonalized and natural user interaction. with advancements in the development of llms
        (large language models), such as llama or gpt, text generation has become significantly more sophisticated and complex, allowing
        for advancements in voice system imple- mentation for digital archives, as done in [ 14]. in this project, an application was
        developed for microsoft hololens (1st generation) to present artworks to visitors, integrated with a system using the gpt-3.5
        model, which received the user’s audio recording and gen- erated the desired responses. in the application evaluation tests, a
        mixedrealityapproachwasused,displayingimagesoftheartworks to users through the headset. the results of the study indicated that
        this technology has the potential to captivate users. two metrics showed lower performance in the empirical test: immersion and
        re- sponse credibility. although the metrics and tests that indicated the model’s responses were accurate, users reported that
        they would not trust the information provided in awkward responses. further- more, they mentioned that the interaction with the
        conversational agent did not seem natural or realistic in the archive. 5.3.3 webpages. webpagesarewidelyusedtodayasasolutionfor
        digitalarchives.consideringthatoneofthegoalsofsuchcollectionsis to make archived material available, web pages offer broad com-
        patibilitywithcurrentdevices,easeofusethroughelementssuchas menusandhyperlinks,andhighscalabilityforlargeaudiences.this formof
        interaction wasemployed in [ 6,10,12,19,30,35,39,43,45], which represent 43% of the articles. some studies implemented
        traditional-format web pages with- out incorporating any unconventional interaction element. one noteworthy example is [ 19] which
        presents a study and heuristic analysis of the interfaces of three different digital museums, aiming to identify the design
        elements that are most important for creating effective interfaces of this kind. the factors deemed most impor- tant were the
        usermodel and theinterpreter . this emphasizes that the interface must have high usability and communicability, easily conveying
        its purpose and content to the user and responding sat- isfactorily to user interactions. aesthetics, although relevant, was not
        prioritized; the main aspects mentioned were typography (font size and family choice) and the alignment of page elements. in [6],
        a different form of user interaction is addressed. their framework features a map-based visualization that can be freely ex-
        ploredbytheuser.foreachpointonthemap,historicalinformation is provided by the various communities that lived there. 6 quantitative
        analysis figure 2 presents the temporal evolution of publications related to the adaptation of digital archives and museums. the
        graph shows that, despite a reduction in the number of publications in the years 2012, 2013, and 2018, the topic has been
        regaining prominence, indicating a renewed interest in the field. vr is the most widely adopted technology in the studies,
        followed by traditional web interfaces. other technologies, such as voice interaction and chat- bots, appeared in 2010 but only
        resurfaced in 2023, likely due to recent advancements in ai. the word cloud presented in figure 3 underscores the terms most
        frequently used in the analyzed studies, revealing a prominent interest in personalization, vr, and immer- sive experiences.
        complementing this discussion, figure 4, generated with the supportofthe bibliometrix andhighcharts tools,showsthenumber of
        publications by country. greece is the country with the highest number of publications, totaling 12 articles, followed by china,
        which appears in 7 publications. the results highlight the absence of publications from north or south american countries,
        revealing the need for broader discussions on interaction aspects in digital archives and museums. figure 5 emphasizes the
        relationship between the main interac- tion features employed in the papers analyzed and the purposes of the archives, categorized
        into three strands: dissemination, preser- vation, and availability. the strong interest in the use of vr stands out, as evidenced
        by its widespread adoption in 50% of the works included in the figure. one example is the study by [ 38], which proposes a model
        capable of generating a 3d virtual environment with the user’s works of interest. moreover, vr shows a similarly significant
        presence in archives aimed both at availability and dis- semination. a scarcity of works exploring other approaches, such as ar,
        is also noticeable, suggesting that technological barriers or the need for specific infrastructure may limit its application for
        navigation in digital archives. additionally, although the number707 webmedia’2025, rio de janeiro,brazil oliveiraet al. number of
        papers145 1 1 145 3 032 10 031 0 1 11 01 1 13 1 0 01 0 0 0 011 0 010 0 0 0 01traditional interfaces virtual reality chatbot voice
        interaction 2007 2009 2010 2012 2013 2018 2019 2023 20240246 figure2: trendsin the use of interaction features in works on digital
        archive adaptation. figure 3: word cloud with terms used in the studies. figure 4: publications by country. of studies
        implementing conversational agents and voice interac- tion is limited, these technologies appear to be more present instudies
        focused on archive availability, suggesting a possible rela- tionship between their adoption and the facilitation of access to
        digital cultural products. with regard to evaluation, 71% of the studies conducted experi- ments with users. notably, 100% of
        these works aimed at dissem- ination or availability, suggesting a significant focus on aspects of user interaction and access to
        archived materials. furthermore, there is a recurrence of studies seeking to empirically validate their proposals. user
        participation in this process is essential, as many of the developed solutions aim to meet individual preferences and interests,
        making the experience more engaging and personalized. in summary, by observing the focus on dissemination and avail- ability as
        purposes, the analyzed data reveal that digital archives and museums perform the role of active agents in the mediation of
        knowledge and collective memory in digital culture. the em- phasis on vr highlights the concern with user immersion in the virtual
        environment; however, the low application of ar indicates an opportunity to be explored. ultimately, empirical evaluations
        involving users are essential to validate the proposed approaches. oneoftherecurringissuesintherealmoftheartsconcernscopy- right.
        despite its relevance, only two studies explicitly address this matter in a significant way. in [ 45], the quality of 3d
        digitization of artworks is limited by the difficulty of accessing artifacts protected by copyright. in [ 12], copyright-related
        issues are discussed from a different perspective: the protection of digital artworks. one of the features proposed for the
        environment described in that study is the integration of a content management system equipped with security mechanisms capable of
        efficiently protecting various digi- tal artworks in their multiple multimedia formats (text, image, 3d model, among others). this
        type of technology is particularly im- portant in digital collections, which aim not only to provide access to content but also to
        ensure the preservation and respect of intel- lectual property rights. thus, tools designed to prevent the misuse of images,
        unauthorized copies, or non-consensual modifications contributenotonlytolegalcompliancebutalsototheconsolidation of digital
        preservation initiatives. 7 challenges and opportunities the analysis of research on digital archives reveals both persistent
        challenges and opportunities to enhance the interaction experience708 whenart meets computer science: a sr about technologies and
        user interaction in adaptivedigital museums and archives webmedia’2025, rio de janeiro,brazil 77 4444 44 2222 1133 voice
        interaction chatbots traditional interfaces virtual environments0 2 4 6 8 10 12 14 16 18dissemination availability preservation
        figure 5: interaction features by digital archive/museum purpose. within digital repositories. several studies have explored
        adapta- tionsandpersonalizationsbasedonuserprofiles,asseenin[ 43]and [23], and have proposed interactive features to improve
        navigation and content access. however, there is a noticeable lack of effec- tive applications of these approaches in natively
        digital archives. in many cases, the studies are limited to conceptual development models. for example, in [ 27], the evaluation
        is conducted using only a prototype, without implementing the results in an actual digital archive. this lack of a comprehensive
        evaluation constrains the findings to a non-realistic context. moreover, there is a clear scarcity of specific approaches in the
        construction and exploration of digital archives. for example, no implementations of 2d virtual environments were found. the main
        argument for implementing 3d virtual environments is that this interaction medium allegedly promotes greater immersion. how- ever,
        immersion is also present in 2d, albeit to a lesser degree. furthermore, hybrid adaptations that combine traditional pages with
        virtual environments tend to be more acceptable in the 2d model, as interaction is typically performed through devices that have
        become commonplace in users’ daily lives. additionally, the integration of conventional elements is also facilitated, given that
        2d interfaces are common to many other applications, making the platform more intuitive and familiar to users. it is also
        important to note that 3d virtual environment applica- tions are commonly used in the digitization of physical collections
        belonging to institutions whose buildings are, in themselves, works of art. this is the case for the louvre museum, the tate
        museum, or the museu da vida fiocruz, which are digital archives that preserve not only digitized works but also the physical
        architecture of the building that houses them. however, in the studies analyzed in this
        review,3dvirtualenvironmentsdidnotdemonstratethesamelevel of attention to architectural preservation, as they were focused on
        facilitating the generation of the virtual environments. althoughimmersiveandadaptivestrategies,asseenin[ 7,25,38], offer users
        greater immersion and more engaging visits, the use of specific devices, such as vr headsets, limits access to digital archives.
        as such, this should be an optional resource, as proposed in [45], where the use of headsets is not mandatory. also concerning the
        access to digital archives, it is evident that there is a shortage of implementations focused on the availability of works.
        javdani rikhtehgar et al . [23]and constantinides et al . [14]propose interaction methods that enhance the availability ofcontent
        to users; however, these are exceptions among the articles in our sample. the remaining studies do not address this issue,
        revealingaclearlimitationinthepotentialdisseminationandreach of digital archives. furthermore, most systems are still based on
        traditional web pages and do not implement innovative solutions. although this is not necessarily a problem, there is a clear lack
        of standardization and guidelines for developing digital archives. the studies by zhao [53], geng yang [19], and pedrero et al .
        [35]go in this direction; however, there is no clear organizational structure that provides consolidated guidelines for these
        implementations. another relevant aspect is the difficulty to integrate different areas of knowledge. works such as [ 10] clearly
        state that the cre- ation of digital archives is a multidisciplinary project, involving not only the cultural elements to be
        preserved, but also the tech- niques and guidelines for building robust software. studies in the field of computer science
        emphasize technological aspects in the development of archives, neglecting certain unique characteristics of digital works and
        interactions that arise from the digital world – elements that are, in turn, highlighted and analyzed in case studies from the
        humanities. a strong association between both fields is imperative for the development of the area and to meet the expecta- tions
        for digital archives from both technical system aspects (such as accessibility,usability,interactivity, etc.) and humanistic
        archival concerns (such as curation, storytelling, and representativeness of the collection, for example). additionally, the
        development and creation of digital archives are intrinsically linked to the preservation of the archived works, meaning that they
        must endure over time. in this regard, for the development of the software, its evolution in response to changes in technology and
        social dynamics must be considered. some al- ternatives to this problem have already been proposed and could be adapted and
        implemented, such as lehman’s laws. in [ 45], this ideaispresent;however,itwasexpectedtobemorewidelyadopted in the development of
        this type of platform. finally, it is important to highlight the development of plat- forms that support the preservation of
        collections with limited resources. preservation efforts should not be constrained by the broad availability of personnel,
        infrastructure, and financial re- sources – conditions typically found in well-established physical
        archives,orinstitutionssupportedbyexternalfunding.alternatives are explored in works such as [40], which proposes a paradigm of
        projects that incorporate minimal computing and, therefore, reduce709 webmedia’2025, rio de janeiro,brazil oliveiraet al.
        development costs. in parallel, there are also initiatives involving low-cost implementations that, for example, incorporate
        social me- diaortoolssuchastainacantoexpandaccessandthesustainability of digital preservation [36]. 8 final remarks in this study,
        a systematic review was conducted with the objec- tive of identifying the main technologies and forms of interaction employed in
        digital archives. from this analysis, it is evident that there is a lack of standardization in the field regarding guidelines and
        norms for the creation of such platforms. moreover, our results show that there is limited use of software engineering practices
        for software maintenance and preservation – essential aspects in the field of digital preservation studies. finally, most of the
        works did not demonstrate concern with evaluating software quality aspects, which reveals a significant gap as to human-computer
        interaction. as a scope limitation, this review included only projects that develop digital archives intended to host multiple
        works, excluding those focused on building technologies for individual exhibitions or
        singleartworks.relevantfutureworkcouldfocusoninitiativesthat aim to standardize the development processes of digital archives or,
        at the very least, the systematic documentation of such practices. 9 ethical considerations this work presents a systematic
        literature review, characterized as secondary research, since it does not involve direct interaction with participants nor the
        exposure of individuals to technologies or computational systems. therefore, according to cns resolution no. 510/2016 and cns
        resolution no. 674/2022, it is exempt from approval by the research ethics committee involving human sub-
        jects.thedatausedreferexclusivelytothemetadataoftheanalyzed articles, which are publicly available in the databases selected and
        described in section 4. acknowledgments thisstudywascarriedoutwiththesupportoffapematandcnpq, through the granting of research
        scholarships. the english version of this article was produced with the assistance of chatgpt and carefully revised by the
        authors. language correction tools, such as writefull, were also employed during the writing process. all stages of data
        selection, analysis, and discussion were conducted exclusively by the authors, with ai tools used solely as writing aids.
        references [1]r.ahmadandm.rafiq.2023. globalperspectiveondigitalpreservationpolicy:a systematic review. journaloflibrarianship
        andinformation science 55, 3 (2023), 859–867. https://doi.org/10.1177/09610006221111572 [2]salvatore andolina, antonella
        santangelo, and antonio gentile. 2010. adap- tive voice interaction for 3d representation of cultural heritage site. in
        2010international conference oncomplex, intelligent andsoftware intensive systems . ieee, krakow, tbd, poland, 729–733.
        https://doi.org/10.1109/cisis. 2010.139 [3]asma hanee ariffin and yu-n cheah. 2013. see what you want, feel what you see: the
        personalized re-recommendation framework using hybrid strategies for fieldtripplan.in 2013thirdworldcongress oninformation
        andcommunication technologies (wict2013). ieee, hanoi, vietnam, 262–267. https://doi.org/10. 1109/wict.2013.7113146 [4]sitaram
        asur, bernardo huberman, gábor szabó, and chunyan wang. 2011. trends in social media : persistence and decay. 5thinternational
        aaaiconference onweblogs andsocialmedia(02 2011). https://doi.org/10.2139/ ssrn.1755748 [5]caroline bertini fernandes and márcia
        gomes marques. 2019. a publicação de poesia na internet: a literatura de clarice freire. vista4 (july 2019), 175–197.
        https://doi.org/10.21814/vista.3020 [6]letizia bollini. 2019. representing a space-based digital archive on historical
        maps:auser-centereddesignapproach. in proceedings ofthe1stinternational andinterdisciplinary conference ondigitalenvironments
        foreducation, arts andheritage , alessandro luigini (ed.). vol. 919. springer international publish- ing, cham, 599–607.
        https://doi.org/10.1007/978-3-030-12240-9_62 series title: advances in intelligent systems and computing. [7]bill bonis, john
        stamos, spyros vosinakis, ioannis andreou, and themis panayiotopoulos. 2007. personalization ofcontent invirtual exhibitions .
        springer berlin heidelberg, 172–184. https://doi.org/10.1007/978-3-540-77051- 0_19 [8]bill bonis, john stamos, spyros vosinakis,
        ioannis andreou, and themis panayiotopoulos. 2007. personalization of content in virtual exhibitions. in semantic multimedia ,
        bianca falcidieno, michela spagnuolo, yannis avrithis, ioannis kompatsiaris, and paul buitelaar (eds.). vol. 4816. springer berlin
        heidel- berg, berlin, heidelberg, 172–184. https://doi.org/10.1007/978-3-540-77051-0_19 series title: lecture notes in computer
        science. [9]b. bonis, j. stamos, s. vosinakis, i. andreou, and t. panayiotopoulos. 2009. a platform for virtual museums with
        personalized content. multimedia toolsand applications 42, 2 (april 2009), 139–159. https://doi.org/10.1007/s11042-008- 0231-2
        [10]e budiman, m wati, and norhidayat. 2019. the 5r adaptation framework for cultural heritage management information system of
        the dayak tribe borneo. journal ofphysics: conference series1341, 4 (oct. 2019), 042016. https://doi.
        org/10.1088/1742-6596/1341/4/042016 [11]manuel castells. 2005. sociedade emrede. paz e terra, são paulo. [12]chengwei yang, rui
        wang, lu wang, chenglei yang, shijun liu, and xiangxu meng. 2010. the personalized service customization based on multimedia re-
        sources in digital museum grid. in 20103rdieeeinternational conference on ubi-media computing . ieee, jinhua, china, 298–304.
        https://doi.org/10.1109/ umedia.2010.5544439 [13]teixeira coelho. 2020. ecultura, autopia final:inteligência artificial e
        humanidades. editora unesp, são paulo. [14]nicolasconstantinides,argyrisconstantinides,dimitrioskoukopoulos,christos fidas, and
        marios belk. 2024. culturai: exploring mixed reality art exhibitions withlargelanguagemodelsforpersonalizedimmersiveexperiences.in
        adjunct proceedings ofthe32ndacmconference onusermodeling, adaptation and personalization . acm, cagliari italy, 102–105.
        https://doi.org/10.1145/3631700. 3664874 [15]jacqueline de araújo cunha and marcos galindo lima. 2024. preservação digital:
        tendências atuais dos conceitos e técnicas. revistaanalisando emciência da informação 11, 2 (nov. 2024), 45–60.
        https://revista.uepb.edu.br/racin/article/ view/4069 [16]qiong dang. 2018. literature review on the digital museum in a chinese
        context. communication, societyandmedia1, 2 (nov. 2018), 149. https://doi. org/10.22158/csm.v1n2p149 [17]ioannis drivas and
        eftichia vraimaki. 2025. evaluating and enhancing museum websites: unlocking insights for accessibility, usability, seo, and
        speed. metrics 2, 1 (jan. 2025), 1. https://doi.org/10.3390/metrics2010001 [18]danilo formenton and luciana de souza gracioso.
        2020. preservação digital: desafios, requisitos, estratégias e produção científica. rdbci: revista digital debiblioteconomia
        eciência dainformação 18, 00 (jun. 2020), e020012. https: //doi.org/10.20396/rdbci.v18i0.8659259 [19]geng yang. 2009. a study on
        the user-centered interface design for vir- tual museums. in 2009ieee10thinternational conference oncomputer-aided industrial
        design &conceptual design. ieee, wenzhou, china, 1647–1651. https://doi.org/10.1109/caidcd.2009.5374866 [20]pablo gobira and
        fernanda corrêa. 2019. a preservação digital da poesia: uma análise do arquivo digital da po.ex. in amemória
        dodigitaleoutrasquestões dasartesemuseologia (1ed.),pablogobira(ed.).vol.1.eduemg,belohorizonte, 165–188. [21]katherine harris.
        2014. archive. in thejohnshopkins guidetodigitalmedia, marie-laure ryan, lori emerson, and benjamin j. robertson (eds.). johns
        hop- kins university press, 16–18. [22]ahdab najib hijazi and ahmad hanif ahmad baharin. 2022. the effectiveness of digital
        technologies used for the visitor’s experience in digital museums. a systematic literature review from the last two decades.
        international journal ofinteractive mobiletechnologies (ijim)16, 16 (aug. 2022), 142–159. https:
        //doi.org/10.3991/ijim.v16i16.31811 [23]delaram javdani rikhtehgar, shenghui wang, hester huitema, julia alvares, stefan
        schlobach, carolien rieffe, and dirk heylen. 2023. personalizing cultural
        heritageaccessinavirtualrealityexhibition:auserstudyonviewingbehavior andcontentpreferences.in adjunct proceedings
        ofthe31stacmconference on usermodeling, adaptation andpersonalization .acm,limassolcyprus,379–387.710 whenart meets computer
        science: a sr about technologies and user interaction in adaptivedigital museums and archives webmedia’2025, rio de janeiro,brazil
        https://doi.org/10.1145/3563359.3596666 [24]otim kayaga and kiu publication extension. 2024. digital archiving and preser- vation
        of art: challenges and innovation. 3 (08 2024), 21–25. [25]hayun kim, maryam shakeri, jae-eun shin, and woontack woo. 2024. space-
        adaptiveartworkplacementbasedoncontentsimilaritiesforcuratingthematic spaces in a virtual museum. journaloncomputing andcultural
        heritage 17, 1 (feb. 2024), 1–21. https://doi.org/10.1145/3631134 [26]barbarakitchenham.2004.
        proceduresforperformingsystematicreviews. keele, uk,keeleuniv. 33 (08 2004). [27]vasileios komianos and konstantinos oikonomou.
        2018. adaptive exhibition topologies for personalized virtual museums. iopconference series:materials science andengineering 364
        (june 2018), 012011. https://doi.org/10.1088/1757- 899x/364/1/012011 [28]jin woo lee, yikyung kim, and soo hee lee. 2019. digital
        museum and user experience: the case of google art & culture. in international symposium on electronic art. international
        symposium on electronic art. [29]jingjing li, xiaoyang zheng, ikumu watanabe, and yoichi ochiai. 2024. a systematic review of
        digital transformation technologies in museum exhibition. computers inhuman behavior 161 (dec. 2024), 108407.
        https://doi.org/10.1016/ j.chb.2024.108407 [30]pasquale lops, marco de gemmis, giovanni semeraro, cataldo musto, fedelucio
        narducci,andmassimobux.2009. asemanticcontent-based recommendersys- tem integrating folksonomies for personalized access. in
        webpersonalization inintelligent environments , janusz kacprzyk, giovanna castellano, lakhmi c. jain, and anna maria fanelli
        (eds.). vol. 229. springer berlin heidelberg, berlin, heidelberg, 27–47. https://doi.org/10.1007/978-3-642-02794-9_2 series title:
        studies in computational intelligence. [31]lev manovich. 2001. thelanguage ofnewmedia. mit press, cambridge, ma. [32]dalton lopes
        martins, josé eduardo santarém segundo, marcel ferrante silva, and joyce siqueira. 2017. repositório digital com o software livre
        tainacan: revisão da ferramenta e exemplo de implantação na área cultural com a re- vista filme cultura. in anaisdoencontro
        nacional depesquisa emciência da informação (enancib). ancib. [33]trevor owens and thomas padilla. 2020. digital sources and
        digital archives: historicalevidenceinthedigitalage. international journalofdigitalhumanities 1 (2020), 325–341.
        https://doi.org/10.1007/s42803-020-00028-7 [34]dragana pavlović. 2022. digital tools in museum learning – a liter- ature review
        from 2000 to 2020. factauniversitatis, series:teaching, learning andteacher education (jan. 2022), 167. https://doi.org/10.22190/
        futlte211104013p [35]a. pedrero, v. alonso, m.a. villarroel, p. de la fuente, and a.s. cabaco. 2009. presentation adaptation:
        results from a case study. in engineering theuser interface ,miguelredondo,crescenciobravo,andmanuelortega(eds.).springer london,
        london, 1–13. https://doi.org/10.1007/978-1-84800-136-7_15 [36]vinícius carvalho pereira. 2024. poesia em flash na antología de
        liter- atura electrónica latinoamericana y caribeña: questões de arquivo. acta scientiarum. language andculture 46, 1 (may 2024),
        e65240. https://doi.org/10. 4025/actascilangcult.v46i1.65240 [37]isabella peters and wolfgang g. stock. 2007. folksonomy and
        information retrieval. proceedings oftheamerican society forinformation science and technology 44, 1 (jan. 2007), 1–28.
        https://doi.org/10.1002/meet.1450440226 [38]landy rajaonarivo, eric maisel, and pierre de loor. 2019. an evolving museum metaphor
        applied to cultural heritage for personalized content delivery. user modeling anduser-adapted interaction 29, 1 (march 2019),
        161–200. https: //doi.org/10.1007/s11257-019-09222-x [39]george e. raptis, christos fidas, christina katsini, and nikolaos
        avouris. 2019. a cognition-centered personalization framework for cultural-heritage content. usermodeling anduser-adapted
        interaction 29, 1 (march 2019), 9–65. https: //doi.org/10.1007/s11257-019-09226-7 [40]roopika risam and alex gil. 2022.
        introduction: the questions of minimal com- puting.digitalhumanities quarterly 16,2(2022). http://www.digitalhumanities.
        org/dhq/vol/16/2/000620/000620.html [41]rejane c. rocha. 2021. fora da estante: questões de arquivo e de preservação da literatura
        digital. nuevarevistadelpacífico 74 (june 2021), 290–309. https: //doi.org/10.4067/s0719-51762021000100290 [42]rejane c. rocha.
        2023. a memória literária: arquivo em tempos de bases de dados.universum (talca)38,1(jul2023),121–133.
        https://doi.org/10.4067/s0718- 23762023000100121 [43]giovanni semeraro, pasquale lops, marco de gemmis, cataldo musto, and
        fedelucio narducci. 2012. a folksonomy-based recommender system for person- alized access to digital artworks. journaloncomputing
        andcultural heritage 5, 3 (oct. 2012), 1–22. https://doi.org/10.1145/2362402.2362405 [44]m. n. sitokdana and a. r. tanaamah. 2016.
        strategi pembangunan e-culture di indonesia. jutisi 2, 2 (august 2016). [45]panagiotis strousopoulos, christos papakostas,
        christos troussas, akrivi krouska, phivos mylonas, and cleo sgouropoulou. 2023. sculptmate: personal- izing cultural heritage
        experience using fuzzy weights. in adjunct proceedingsofthe31stacmconference onusermodeling, adaptation andpersonalization . acm,
        limassol cyprus, 397–407. https://doi.org/10.1145/3563359.3596667 [46]d. svanaes. 2013. interaction design for and with the lived
        body: some implica- tions of merleau-ponty’s phenomenology. proceedings ofacmtransactions on computer-human interaction (tochi) 20
        (2013). special issue on the theory and practice of embodied interaction in hci and interaction design.
        [47]yantingtong,binyuecui,andyulinchen.2018. researchonuivisualdesignof intangible cultural heritage digital museum based on user
        experience. in 2018 13thinternational conference oncomputer science amp;education (iccse). ieee, 1–4.
        https://doi.org/10.1109/iccse.2018.8468809 [48]qinwang.2022. theapplicationofpersonalizedrecommendationsysteminthe cross-regional
        promotion of provincial intangible cultural heritage. advances inmultimedia 2022 (oct. 2022), 1–10.
        https://doi.org/10.1155/2022/5811341 [49]meng yang, jia-xiu zhang, yi shi, bo liu, le-xin guo, zhi-peng yu, bin sheng, and
        li-zhuang ma. 2023. framework of personalized layout for a museum exhi- bition hall. multimedia toolsandapplications 83, 8 (aug.
        2023), 24563–24587. https://doi.org/10.1007/s11042-023-16307-8 [50]jihyunyiandhaesunkim.2021.
        userexperienceresearch,experiencedesign, and evaluation methods for museum mixed reality experience. j.comput. cult. herit. 14, 4,
        article 48 (sept. 2021), 28 pages. https://doi.org/10.1145/3462645 [51]li yifei and mohd kamal othman. 2024. investigating the
        behavioural intentions of museum visitors towards vr: a systematic literature review. computers in human behavior 155 (june 2024),
        108167. https://doi.org/10.1016/j.chb.2024. 108167 [52]namira rahmi zahara and tamara adriani salim. 2022. preservation of digital
        archives: systematic literature review. recordandlibrary journal8, 2 (dec. 2022), 285–297.
        https://doi.org/10.20473/rlj.v8-i2.2022.285-297 [53]lingzhao.2023. personalizedhealthcaremuseumexhibitionsystemdesignbased on vr
        and deep learning driven multimedia and multimodal sensing. personal andubiquitous computing 27, 3 (june 2023), 973–988.
        https://doi.org/10.1007/ s00779-022-01672-2711

4. RESUMO GERAL:
    based on the analysis of studies, we discuss trends, challenges, and
    opportunities for the design and development of adaptive digital museums and
    archives, such as the limited incorporation of human-computer interaction and
    software engineering principles and the need for greater standard- ization in
    the development of adaptive digital archives. given the interdisciplinary nature
    of digital archives and the fragmented treatment they often receive across the
    digital hu- manities and computer science, this systematic literature review
    examines 21 studies to identify the primary purposes of such plat- forms, the
    technological strategies employed in their development, and the interaction
    modalities made available to users. in order for articles to be selected within
    the scope defined by the review protocol, the inclusion and exclusion criteria
    were established and listed below: i1:the study addresses the development,
    maintenance, or use of a digital collection or digital museum.i2:the study
    describes technical aspects (interaction methods, technologies used) that
    support the understanding of com- putational elements. in this sense, to support
    the discussion of rq1, we chose to divide the purposes of the archives into
    three strands: i) dissemination , related to im- proving visitation; ii)
    preservation , aimed at the maintenance and care of digital works over time;
    iii) availability , related to the facil- itation of access to digital works.
    database search string acm digital library [[title: personaliz*] or [title:
    adapt*] or [title: cus- tomiz*] or [title: user-center*]] and [[all: ”digital
    archive”] or [all: ”digital collection”] or [all: ”digital museum”] or [all:
    ”virtual museum”] or [all: ”cultural heritage”] or [all: ”digital art gallery”]]
    sciencedirect title, abstract, keywords: ”digital archive” or ”digital
    collection” or ”digital museum” or ”virtual museum” or ”cultural heritage” or
    ”digital art gallery” title: per-
    sonalizationorpersonalizedoradaptationoradaptive or customization or customized
    or user-centered scopus title ( personaliz* or adapt* or customiz* or user-
    center* ) and title ( ”digital archive” or ”digital col- lection” or ”digital
    museum” or ”virtual museum” or ”cultural heritage” or ”digital art gallery” )
    ieee xplore (”document title”:personaliz* or ”document ti- tle”:adapt* or
    ”document title”:customiz* or ”doc- ument title”:user-center*) and (”all
    metadata”:”digital archive” or ”all metadata”:”digital collection” or ”all
    metadata”:”digital museum” or ”all metadata”:”virtual museum” or ”all
    metadata”:”cultural heritage” or ”all metadata”:”digital art gallery”) note:each
    string was adapted to each platform’s search syntax. studies in the field of
    computer science emphasize technological aspects in the development of archives,
    neglecting certain unique characteristics of digital works and interactions that
    arise from the digital world – elements that are, in turn, highlighted and
    analyzed in case studies from the humanities.

==================================================

